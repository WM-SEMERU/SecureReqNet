nslookup kubernetes.default fails from within pods


Versions
kubeadm version (use kubeadm version):
kubeadm version: &version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T15:51:21Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}
Environment: Ubuntu 18.04

Kubernetes version (use kubectl version):

Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T15:53:57Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T15:45:25Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}


Cloud provider or hardware configuration: Vagrant
OS (e.g. from /etc/os-release):

NAME="Ubuntu"
VERSION="18.04.1 LTS (Bionic Beaver)"


Kernel (e.g. uname -a): Linux k8s-master 4.15.0-29-generic #31-Ubuntu SMP Tue Jul 17 15:39:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
Others:

What happened?
An nslookup to kubernetes.default fails from withtin a pod. I did try busybox but also others.
# nslookup kubernetes.default
Server:		10.0.2.3
Address:	10.0.2.3#53

** server can't find kubernetes.default: NXDOMAIN

What you expected to happen?
I expected it to succeed. I found this issue when I was debugging why my Kubernetes dashboard didn't work when it was running on a node (different than master).
Anything else we need to know?
sudo ufw status
Status: inactive

I've added the following entries in /etc/resolv.conf
net.bridge.bridge-nf-call-iptables=1
net.ipv4.ip_forward=1

Rest of pods seem to run okay:
kubectl get pods -n kube-system
NAME                                    READY   STATUS             RESTARTS   AGE
calico-node-jjk6s                       1/1     Running            0          5m14s
calico-node-srw9m                       1/1     Running            0          3m4s
coredns-fb8b8dccf-j7cpz                 1/1     Running            0          5m14s
coredns-fb8b8dccf-k952q                 1/1     Running            0          5m14s
etcd-k8s-master                         1/1     Running            0          4m17s
kube-apiserver-k8s-master               1/1     Running            0          4m20s
kube-controller-manager-k8s-master      1/1     Running            0          4m15s
kube-proxy-6ld4f                        1/1     Running            0          3m4s
kube-proxy-ksgpk                        1/1     Running            0          5m14s
kube-scheduler-k8s-master               1/1     Running            0          4m32s
kubernetes-dashboard-5f7b999d65-9mtjj   0/1     CrashLoopBackOff   2          2m16s

dashboard logs:
kubectl logs kubernetes-dashboard-5f7b999d65-9mtjj -n kube-system
2019/03/31 16:14:49 Starting overwatch
2019/03/31 16:14:49 Using in-cluster config to connect to apiserver
2019/03/31 16:14:49 Using service account token for csrf signing
2019/03/31 16:15:19 Error while initializing connection to Kubernetes apiserver. This most likely means that the cluster is misconfigured (e.g., it has invalid apiserver certificates or service account's configuration) or the --apiserver-host param points to a server that does not exist. Reason: Get https://10.96.0.1:443/version: dial tcp 10.96.0.1:443: i/o timeout
Refer to our FAQ and wiki pages for more information: https://github.com/kubernetes/dashboard/wiki/FAQ

Telnet on master and node seems to work:telnet 10.96.0.10 53
Trying 10.96.0.10...
Connected to 10.96.0.10.
Escape character is '^]'.

