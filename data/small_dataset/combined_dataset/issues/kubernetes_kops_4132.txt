Upgrade k8s 1.7.11 to 1.8.4 fails.


Thanks for submitting an issue! Please fill in as much of the template below as
you can.
------------- BUG REPORT TEMPLATE --------------------

What kops version are you running? The command kops version, will display
this information.

Version 1.8.0 (git-5099bc5)

What Kubernetes version are you running? kubectl version will print the
version if a cluster is running or provide the Kubernetes version specified as
a kops flag.

Client Version: version.Info{Major:"1", Minor:"8", GitVersion:"v1.8.3", GitCommit:"f0efb3cb883751c5ffdbe6d515f3cb4fbe7b7acd", GitTreeState:"clean", BuildDate:"2017-11-08T18:39:33Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"8", GitVersion:"v1.8.4", GitCommit:"9befc2b8928a9426501d3bf62f72849d5cbcd5a3", GitTreeState:"clean", BuildDate:"2017-11-20T05:17:43Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"linux/amd64"}
-> after update

What cloud provider are you using?

aws

What commands did you run?  What is the simplest way to reproduce this issue?

kops upgrade cluster cluster-name
kops upgrade cluster cluster-name --yes
kops update cluster cluster-name
kops update cluster cluster-name --yes
kops rolling-update cluster --name cluster-name
kops rolling-update cluster --name cluster-name --yes

What happened after the commands executed?

Master instance is successfully updated, but node instance fails to install k8s.
Entered the instance via ssh and found that nodeup process was stalling with following messages:
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.749968     708 files.go:100] Hash matched for "/var/cache/nodeup/sha1:125993c220d1a9b5b60ad20a867a0e7cda63e64c_https___storage_googleapis_com_kubernetes-release_release_v1_8_4_bin_linux_amd64_kubelet": sha1:125993c220d1a9b5b60ad20a867a0e7cda63e64c
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.750010     708 assetstore.go:202] added asset "kubelet" for &{"/var/cache/nodeup/sha1:125993c220d1a9b5b60ad20a867a0e7cda63e64c_https___storage_googleapis_com_kubernetes-release_release_v1_8_4_bin_linux_amd64_kubelet"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.826981     708 files.go:100] Hash matched for "/var/cache/nodeup/sha1:8e2314db816b9b4465c5f713c1152cb0603db15e_https___storage_googleapis_com_kubernetes-release_release_v1_8_4_bin_linux_amd64_kubectl": sha1:8e2314db816b9b4465c5f713c1152cb0603db15e
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.827019     708 assetstore.go:202] added asset "kubectl" for &{"/var/cache/nodeup/sha1:8e2314db816b9b4465c5f713c1152cb0603db15e_https___storage_googleapis_com_kubernetes-release_release_v1_8_4_bin_linux_amd64_kubectl"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848006     708 files.go:100] Hash matched for "/var/cache/nodeup/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz": sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848030     708 assetstore.go:202] added asset "cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff.tar.gz" for &{"/var/cache/nodeup/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848140     708 assetstore.go:303] added asset "bridge" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/bridge"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848172     708 assetstore.go:303] added asset "cnitool" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/cnitool"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848198     708 assetstore.go:303] added asset "dhcp" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/dhcp"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848224     708 assetstore.go:303] added asset "flannel" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/flannel"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848247     708 assetstore.go:303] added asset "host-local" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/host-local"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848269     708 assetstore.go:303] added asset "ipvlan" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/ipvlan"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848295     708 assetstore.go:303] added asset "loopback" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/loopback"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848325     708 assetstore.go:303] added asset "macvlan" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/macvlan"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848352     708 assetstore.go:303] added asset "noop" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/noop"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848377     708 assetstore.go:303] added asset "ptp" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/ptp"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.848403     708 assetstore.go:303] added asset "tuning" for &{"/var/cache/nodeup/extracted/sha1:1d9788b0f5420e1a219aad2cb8681823fc515e7c_https___storage_googleapis_com_kubernetes-release_network-plugins_cni-0799f5732f2a11b329d9e3d51b9c8f2e3759f2ff_tar_gz/bin/tuning"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.849898     708 files.go:100] Hash matched for "/var/cache/nodeup/sha1:f62360d3351bed837ae3ffcdee65e9d57511695a_https___kubeupv2_s3_amazonaws_com_kops_1_8_0_linux_amd64_utils_tar_gz": sha1:f62360d3351bed837ae3ffcdee65e9d57511695a
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.849918     708 assetstore.go:202] added asset "utils.tar.gz" for &{"/var/cache/nodeup/sha1:f62360d3351bed837ae3ffcdee65e9d57511695a_https___kubeupv2_s3_amazonaws_com_kops_1_8_0_linux_amd64_utils_tar_gz"}
Dec 21 16:38:15 ip-10-200-63-88 nodeup[708]: I1221 16:38:15.849989     708 assetstore.go:303] added asset "socat" for &{"/var/cache/nodeup/extracted/sha1:f62360d3351bed837ae3ffcdee65e9d57511695a_https___kubeupv2_s3_amazonaws_com_kops_1_8_0_linux_amd64_utils_tar_gz/utils/socat"}
Dec 21 16:38:16 ip-10-200-63-88 nodeup[708]: I1221 16:38:16.185802     708 s3context.go:145] unable to get bucket location from region "us-east-1"; scanning all regions: AccessDenied: Access Denied
Dec 21 16:38:16 ip-10-200-63-88 nodeup[708]: status code: 403, request id: 1D55A69EF7C9F929
Dec 21 16:38:16 ip-10-200-63-88 nodeup[708]: W1221 16:38:16.720116     708 main.go:141] got error running nodeup (will retry in 30s): error loading Cluster "s3://bagelcode-kops-state-store/qa.k8s.aws-qa.bagelcode.com/cluster.spec": Unable to list AWS regions: UnauthorizedOperation: You are not authorized to perform this operation.
Dec 21 16:38:16 ip-10-200-63-88 nodeup[708]: status code: 403, request id: 0fcd30ad-c3d6-4d6d-bc9a-0dfd4ec5d100
It seems that the node instance lacks a certain permission.
I manually added the following inline policy to nodes.cluster-name (which is automatically generated by kops) and the node instance succeeded to install k8s:
{
"Version": "2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Action": [
"ec2:Describe*"
],
"Resource": [
"*"
]
}
]
}
The above policy is used by kops 1.7.1, but kops 1.8.0 changes it to ec2:DescribeInstances.

What did you expect to happen?

Update should be done without manual patch.

Please provide your cluster manifest. Execute
kops get --name my.example.com -oyaml to display your cluster manifest.
You may want to remove your cluster name and other sensitive information.

apiVersion: kops/v1alpha2
kind: Cluster
metadata:
creationTimestamp: 2017-02-16T08:10:21Z
name: cluster-name
spec:
api:
dns: {}
authorization:
alwaysAllow: {}
channel: stable
cloudProvider: aws
configBase: s3://kops-state-store/cluster-name
etcdClusters:

etcdMembers:

instanceGroup: master-us-west-2a
name: a
name: main


etcdMembers:

instanceGroup: master-us-west-2a
name: a
name: events
iam:
legacy: true
kubernetesApiAccess:


0.0.0.0/0
kubernetesVersion: 1.8.4
masterInternalName: api.internal.cluster-name
masterPublicName: api.cluster-name
networkCIDR: 10.101.0.0/16
networking:
kubenet: {}
nonMasqueradeCIDR: 100.64.0.0/10
sshAccess:
0.0.0.0/0
subnets:
cidr: 10.101.32.0/19
name: us-west-2a
type: Public
zone: us-west-2a
cidr: 10.101.64.0/19
name: us-west-2b
type: Public
zone: us-west-2b
cidr: 10.101.96.0/19
name: us-west-2c
type: Public
zone: us-west-2c
topology:
dns:
type: Public
masters: public
nodes: public


apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
creationTimestamp: 2017-02-16T08:10:21Z
labels:
kops.k8s.io/cluster: cluster-name
name: master-us-west-2a
spec:
image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2017-12-02
machineType: m3.medium
maxSize: 1
minSize: 1
role: Master
subnets:

us-west-2a


apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
creationTimestamp: 2017-02-16T08:10:22Z
labels:
kops.k8s.io/cluster: cluster-name
name: nodes
spec:
image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2017-12-02
machineType: c4.large
maxSize: 10
minSize: 10
role: Node
subnets:

us-west-2a
us-west-2b
us-west-2c



Please run the commands with most verbose logging by adding the -v 10 flag.
Paste the logs into this report, or in a gist and provide the gist link here.


Anything else do we need to know?


------------- FEATURE REQUEST TEMPLATE --------------------


Describe IN DETAIL the feature/behavior/change you would like to see.


Feel free to provide a design supporting your feature request.


