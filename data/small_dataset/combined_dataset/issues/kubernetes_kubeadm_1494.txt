kube-controller-manager doesn't work properly in ha mode after update to v1.14


Is this a BUG REPORT or FEATURE REQUEST?
BUG REPORT
Versions
kubeadm version (use kubeadm version):
kubeadm version: &version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T15:51:21Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}

Environment:

Kubernetes version (use kubectl version):

Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T15:53:57Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.0", GitCommit:"641856db18352033a0d96dbc99153fa3b27298e5", GitTreeState:"clean", BuildDate:"2019-03-25T15:45:25Z", GoVersion:"go1.12.1", Compiler:"gc", Platform:"linux/amd64"}


Cloud provider or hardware configuration: bare metal
OS (e.g. from /etc/os-release): Ubuntu 18.10
Kernel (e.g. uname -a): Linux k8s-master1 4.18.0-17-generic #18-Ubuntu SMP Wed Mar 13 14:34:40 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
Others: containerd 1.26

What happened?
After upgrade to 1.14 via kubeadm, kube-controller-manager showed following error:
E0403 09:08:30.986462       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system": RBAC: [role.rbac.authorization.k8s.io "extension-apiserver-authentication-reader" not found, role.rbac.authorization.k8s.io "system::leader-locking-kube-controller-manager" not found]

And some of daemonset pods can't schedule
kubectl describe ds -n kube-system calico-node
Desired Number of Nodes Scheduled: 196
Current Number of Nodes Scheduled: 195
Number of Nodes Scheduled with Up-to-date Pods: 195
Number of Nodes Scheduled with Available Pods: 195
Number of Nodes Misscheduled: 0
Pods Status:  195 Running / 0 Waiting / 0 Succeeded / 0 Failed

What you expected to happen?
I expect that daemonset's pods will schedule properly
How to reproduce it (as minimally and precisely as possible)?
Kubernetes HA topology:
https://kubernetes.io/docs/setup/independent/ha-topology/#stacked-etcd-topology
Anything else we need to know?
Related to the issue kubernetes/kubernetes#75937
