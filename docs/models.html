---

title: SecureReqNet Models


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/08_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/08_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-SecureReqNet-Model">Load SecureReqNet Model<a class="anchor-link" href="#Load-SecureReqNet-Model"> </a></h2><p>Currently only alpha is available</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_securereqnet_model" class="doc_header"><code>load_securereqnet_model</code><a href="https://github.com/rmclanton/SecureReqNet/blob/master/securereqnet/models.py#L8" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_securereqnet_model</code>(<strong><code>model</code></strong>)</p>
</blockquote>
<p>Returns a pretrained version of the selected model</p>
<p>Users can select: alpha</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_alpha" class="doc_header"><code>create_alpha</code><a href="https://github.com/rmclanton/SecureReqNet/blob/master/securereqnet/models.py#L27" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_alpha</code>()</p>
</blockquote>
<p>Creates a securereqnet alpha model and compiles it</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="fit_model" class="doc_header"><code>fit_model</code><a href="https://github.com/rmclanton/SecureReqNet/blob/master/securereqnet/models.py#L114" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>fit_model</code>(<strong><code>corpora_train_x</code></strong>, <strong><code>target_train_y</code></strong>, <strong><code>criticality_network</code></strong>, <strong><code>save_model</code></strong>=<em><code>True</code></em>, <strong><code>save_history</code></strong>=<em><code>True</code></em>, <strong><code>file_path</code></strong>=<em><code>''</code></em>, <strong><code>model_name</code></strong>=<em><code>''</code></em>)</p>
</blockquote>
<p>Fits a securereqnet model to the data</p>
<p>Returns model, history</p>
<p>@param save_model (bool): Saves the model to the input path</p>
<p>@param save_history (bool): Saves the history to the path</p>
<p>@param file_path (string): Path to where the model and/or history will be saved to</p>
<p>@param model_name (string): Name to save the model as</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="n">create_alpha</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;functional_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 618, 100, 1)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 612, 1, 32)        22432     
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 1, 1, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 32)                0         
_________________________________________________________________
reshape (Reshape)            (None, 32, 1, 1)          0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 1, 64)         384       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 64)                0         
_________________________________________________________________
reshape_1 (Reshape)          (None, 64, 1, 1)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 62, 1, 128)        512       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 60, 1, 128)        49280     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 58, 1, 64)         24640     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 64)                0         
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 16)                528       
_________________________________________________________________
dropout_2 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 34        
=================================================================
Total params: 100,946
Trainable params: 100,946
Non-trainable params: 0
_________________________________________________________________
None
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">securereqnet.preprocessing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span><span class="n">test_y</span> <span class="o">=</span> <span class="n">process_corpora</span><span class="p">(</span><span class="s2">&quot;../data/small_dataset/&quot;</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Max. Sentence # words: 527
Mix. Sentence # words: 5
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alpha</span><span class="p">,</span> <span class="n">history</span><span class="o">=</span> <span class="n">fit_model</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span><span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">save_history</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.4149 - accuracy: 0.9543
Epoch 00001: val_accuracy improved from -inf to 0.44144, saving model to .hdf5
WARNING:tensorflow:From /home/roger/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/roger/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: .hdf5/assets
14/14 [==============================] - 1s 97ms/step - loss: 0.3926 - accuracy: 0.9571 - val_loss: 3.0079 - val_accuracy: 0.4414
Epoch 2/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0432 - accuracy: 0.9808
Epoch 00002: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0406 - accuracy: 0.9819 - val_loss: 8.2951 - val_accuracy: 0.4414
Epoch 3/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0350 - accuracy: 0.9976
Epoch 00003: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 0.0329 - accuracy: 0.9977 - val_loss: 8.4467 - val_accuracy: 0.4414
Epoch 4/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000
Epoch 00004: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.3995 - val_accuracy: 0.4414
Epoch 5/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0075 - accuracy: 0.9952
Epoch 00005: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 0.9955 - val_loss: 8.3761 - val_accuracy: 0.4414
Epoch 6/2000
14/14 [==============================] - ETA: 0s - loss: 3.7113e-04 - accuracy: 1.0000
Epoch 00006: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 3.7113e-04 - accuracy: 1.0000 - val_loss: 8.3672 - val_accuracy: 0.4414
Epoch 7/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 4.2558e-04 - accuracy: 1.0000
Epoch 00007: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 3.9966e-04 - accuracy: 1.0000 - val_loss: 8.3876 - val_accuracy: 0.4414
Epoch 8/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 9.7478e-05 - accuracy: 1.0000
Epoch 00008: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.3955 - val_accuracy: 0.4414
Epoch 9/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 6.3711e-05 - accuracy: 1.0000
Epoch 00009: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 5.9828e-05 - accuracy: 1.0000 - val_loss: 8.4062 - val_accuracy: 0.4414
Epoch 10/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 5.1667e-04 - accuracy: 1.0000
Epoch 00010: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 4.4797e-04 - accuracy: 1.0000 - val_loss: 8.4208 - val_accuracy: 0.4414
Epoch 11/2000
14/14 [==============================] - ETA: 0s - loss: 1.9780e-04 - accuracy: 1.0000
Epoch 00011: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 1.9780e-04 - accuracy: 1.0000 - val_loss: 8.4314 - val_accuracy: 0.4414
Epoch 12/2000
14/14 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  
Epoch 00012: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.4409 - val_accuracy: 0.4414
Epoch 13/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 8.7697e-05 - accuracy: 1.0000
Epoch 00013: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 3.2839e-04 - accuracy: 1.0000 - val_loss: 8.4509 - val_accuracy: 0.4414
Epoch 14/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 6.0680e-05 - accuracy: 1.0000
Epoch 00014: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 5.2669e-05 - accuracy: 1.0000 - val_loss: 8.4600 - val_accuracy: 0.4414
Epoch 15/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.8564e-05 - accuracy: 1.0000
Epoch 00015: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 2.9227e-05 - accuracy: 1.0000 - val_loss: 8.4637 - val_accuracy: 0.4414
Epoch 16/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 1.6144e-04 - accuracy: 1.0000
Epoch 00016: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 1.4018e-04 - accuracy: 1.0000 - val_loss: 8.4686 - val_accuracy: 0.4414
Epoch 17/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 5.4913e-06 - accuracy: 1.0000
Epoch 00017: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 26ms/step - loss: 5.1693e-06 - accuracy: 1.0000 - val_loss: 8.4712 - val_accuracy: 0.4414
Epoch 18/2000
14/14 [==============================] - ETA: 0s - loss: 3.5860e-04 - accuracy: 1.0000
Epoch 00018: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 3.5860e-04 - accuracy: 1.0000 - val_loss: 8.4765 - val_accuracy: 0.4414
Epoch 19/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000
Epoch 00019: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.4890 - val_accuracy: 0.4414
Epoch 20/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.1939e-05 - accuracy: 1.0000
Epoch 00020: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 2.0602e-05 - accuracy: 1.0000 - val_loss: 8.4952 - val_accuracy: 0.4414
Epoch 21/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000
Epoch 00021: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.5061 - val_accuracy: 0.4414
Epoch 22/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.0370e-05 - accuracy: 1.0000
Epoch 00022: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 6.6147e-05 - accuracy: 1.0000 - val_loss: 8.5119 - val_accuracy: 0.4414
Epoch 23/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0025 - accuracy: 0.9976  
Epoch 00023: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 0.9977 - val_loss: 8.5144 - val_accuracy: 0.4414
Epoch 24/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.2435e-04 - accuracy: 1.0000
Epoch 00024: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 1.1677e-04 - accuracy: 1.0000 - val_loss: 8.5206 - val_accuracy: 0.4414
Epoch 25/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.0533e-07 - accuracy: 1.0000
Epoch 00025: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 6.7458e-07 - accuracy: 1.0000 - val_loss: 8.5232 - val_accuracy: 0.4414
Epoch 26/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 6.5392e-04 - accuracy: 1.0000
Epoch 00026: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 6.1416e-04 - accuracy: 1.0000 - val_loss: 8.5301 - val_accuracy: 0.4414
Epoch 27/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.7175e-04 - accuracy: 1.0000
Epoch 00027: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 2.5519e-04 - accuracy: 1.0000 - val_loss: 8.5411 - val_accuracy: 0.4414
Epoch 28/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 4.7527e-06 - accuracy: 1.0000
Epoch 00028: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 0.9977 - val_loss: 8.5452 - val_accuracy: 0.4414
Epoch 29/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 8.8821e-06 - accuracy: 1.0000
Epoch 00029: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 8.3415e-06 - accuracy: 1.0000 - val_loss: 8.5534 - val_accuracy: 0.4414
Epoch 30/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.2888e-07 - accuracy: 1.0000
Epoch 00030: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 1.2210e-07 - accuracy: 1.0000 - val_loss: 8.5550 - val_accuracy: 0.4414
Epoch 31/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 2.8894e-06 - accuracy: 1.0000
Epoch 00031: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 2.5046e-06 - accuracy: 1.0000 - val_loss: 8.5562 - val_accuracy: 0.4414
Epoch 32/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 9.6941e-06 - accuracy: 1.0000
Epoch 00032: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 1.1184e-05 - accuracy: 1.0000 - val_loss: 8.5576 - val_accuracy: 0.4414
Epoch 33/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 5.4786e-07 - accuracy: 1.0000
Epoch 00033: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 5.1447e-07 - accuracy: 1.0000 - val_loss: 8.5579 - val_accuracy: 0.4414
Epoch 34/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.1579e-05 - accuracy: 1.0000
Epoch 00034: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 1.0873e-05 - accuracy: 1.0000 - val_loss: 8.5593 - val_accuracy: 0.4414
Epoch 35/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.5767e-06 - accuracy: 1.0000
Epoch 00035: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 1.7184e-06 - accuracy: 1.0000 - val_loss: 8.5595 - val_accuracy: 0.4414
Epoch 36/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.4690e-05 - accuracy: 1.0000
Epoch 00036: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 1.3795e-05 - accuracy: 1.0000 - val_loss: 8.5599 - val_accuracy: 0.4414
Epoch 37/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 4.7170e-07 - accuracy: 1.0000
Epoch 00037: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 4.4295e-07 - accuracy: 1.0000 - val_loss: 8.5601 - val_accuracy: 0.4414
Epoch 38/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.0961e-08 - accuracy: 1.0000
Epoch 00038: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 1.0293e-08 - accuracy: 1.0000 - val_loss: 8.5601 - val_accuracy: 0.4414
Epoch 39/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.8431e-04 - accuracy: 1.0000
Epoch 00039: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 1.7308e-04 - accuracy: 1.0000 - val_loss: 8.5633 - val_accuracy: 0.4414
Epoch 40/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0051 - accuracy: 0.9976    
Epoch 00040: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 8.5656 - val_accuracy: 0.4414
Epoch 41/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.2313e-06 - accuracy: 1.0000
Epoch 00041: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 2.0953e-06 - accuracy: 1.0000 - val_loss: 8.5624 - val_accuracy: 0.4414
Epoch 42/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 6.9171e-07 - accuracy: 1.0000
Epoch 00042: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 6.4955e-07 - accuracy: 1.0000 - val_loss: 8.5624 - val_accuracy: 0.4414
Epoch 43/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.9301e-08 - accuracy: 1.0000
Epoch 00043: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 2.7515e-08 - accuracy: 1.0000 - val_loss: 8.5625 - val_accuracy: 0.4414
Epoch 44/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.9437e-06 - accuracy: 1.0000
Epoch 00044: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 7.4595e-06 - accuracy: 1.0000 - val_loss: 8.5627 - val_accuracy: 0.4414
Epoch 45/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.7653e-08 - accuracy: 1.0000
Epoch 00045: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 2.5968e-08 - accuracy: 1.0000 - val_loss: 8.5629 - val_accuracy: 0.4414
Epoch 46/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.8069e-05 - accuracy: 1.0000
Epoch 00046: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 2.6358e-05 - accuracy: 1.0000 - val_loss: 8.5633 - val_accuracy: 0.4414
Epoch 47/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 3.5224e-05 - accuracy: 1.0000
Epoch 00047: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 3.3081e-05 - accuracy: 1.0000 - val_loss: 8.5664 - val_accuracy: 0.4414
Epoch 48/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.0407e-06 - accuracy: 1.0000
Epoch 00048: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 6.6116e-06 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 49/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 9.9266e-06 - accuracy: 1.0000
Epoch 00049: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 8.6046e-06 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 50/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 4.9900e-07 - accuracy: 1.0000
Epoch 00050: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 4.6859e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 51/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.2352e-08 - accuracy: 1.0000
Epoch 00051: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 2.0990e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 52/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 8.1742e-08 - accuracy: 1.0000
Epoch 00052: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 7.6760e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 53/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.0632e-08 - accuracy: 1.0000
Epoch 00053: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 2.0990e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 54/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.9494e-07 - accuracy: 1.0000
Epoch 00054: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 26ms/step - loss: 1.8306e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 55/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.4786e-06 - accuracy: 1.0000
Epoch 00055: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 2.3294e-06 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 56/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.6656e-08 - accuracy: 1.0000
Epoch 00056: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 7.1984e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 57/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 9.3849e-09 - accuracy: 1.0000
Epoch 00057: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 8.8129e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 58/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 1.2489e-04 - accuracy: 1.0000
Epoch 00058: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 1.0826e-04 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 59/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 1.0245e-08 - accuracy: 1.0000
Epoch 00059: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 8.8802e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 60/2000
14/14 [==============================] - ETA: 0s - loss: 2.8987e-05 - accuracy: 1.0000
Epoch 00060: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 2.8987e-05 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 61/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 1.1091e-07 - accuracy: 1.0000
Epoch 00061: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 9.6135e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 62/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 6.5604e-06 - accuracy: 1.0000
Epoch 00062: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 6.1606e-06 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 63/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 3.5013e-07 - accuracy: 1.0000
Epoch 00063: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 3.3175e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 64/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 5.9540e-07 - accuracy: 1.0000
Epoch 00064: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 5.5911e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 65/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.7541e-06 - accuracy: 1.0000
Epoch 00065: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 20ms/step - loss: 7.2815e-06 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 66/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00066: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 67/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 9.0983e-09 - accuracy: 1.0000
Epoch 00067: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 8.5438e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 68/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.6098e-07 - accuracy: 1.0000
Epoch 00068: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 1.5117e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 69/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.8657e-06 - accuracy: 1.0000
Epoch 00069: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 1.8246e-05 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 70/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 6.1396e-08 - accuracy: 1.0000
Epoch 00070: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 5.7654e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 71/2000
14/14 [==============================] - ETA: 0s - loss: 7.4001e-10 - accuracy: 1.0000
Epoch 00071: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 7.4001e-10 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 72/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 3.0070e-06 - accuracy: 1.0000
Epoch 00072: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 2.8237e-06 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 73/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.3182e-08 - accuracy: 1.0000
Epoch 00073: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 1.2378e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 74/2000
14/14 [==============================] - ETA: 0s - loss: 8.6111e-09 - accuracy: 1.0000
Epoch 00074: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 8.6111e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 75/2000
14/14 [==============================] - ETA: 0s - loss: 3.6937e-05 - accuracy: 1.0000
Epoch 00075: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 3.6937e-05 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 76/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.4618e-04 - accuracy: 1.0000
Epoch 00076: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 25ms/step - loss: 2.3118e-04 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 77/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00077: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 78/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.1640e-11 - accuracy: 1.0000
Epoch 00078: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 5.2474e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 79/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 5.7326e-07 - accuracy: 1.0000
Epoch 00079: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 5.3832e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 80/2000
12/14 [========================&gt;.....] - ETA: 0s - loss: 3.1044e-10 - accuracy: 1.0000
Epoch 00080: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 2.6910e-10 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 81/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.9415e-08 - accuracy: 1.0000
Epoch 00081: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 1.8231e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 82/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.0646e-07 - accuracy: 1.0000
Epoch 00082: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 9.9971e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 83/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0022 - accuracy: 0.9976  
Epoch 00083: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 0.9977 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 84/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.7194e-09 - accuracy: 1.0000
Epoch 00084: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 1.6146e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 85/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00085: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 86/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.2208e-04 - accuracy: 1.0000
Epoch 00086: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 24ms/step - loss: 2.0854e-04 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 87/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00087: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 88/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00088: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 89/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.1462e-09 - accuracy: 1.0000
Epoch 00089: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 1.0764e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 90/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00090: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 91/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 6.7414e-08 - accuracy: 1.0000
Epoch 00091: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 6.3306e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 92/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 5.0148e-10 - accuracy: 1.0000
Epoch 00092: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 4.7092e-10 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 93/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 3.2310e-08 - accuracy: 1.0000
Epoch 00093: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 3.0341e-08 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 94/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 7.7900e-07 - accuracy: 1.0000
Epoch 00094: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 7.3152e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 95/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00095: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 96/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00096: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 97/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 1.9895e-07 - accuracy: 1.0000
Epoch 00097: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 21ms/step - loss: 1.8683e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 98/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 8.4957e-07 - accuracy: 1.0000
Epoch 00098: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 7.9779e-07 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 99/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00099: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 100/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 2.0059e-09 - accuracy: 1.0000
Epoch 00100: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 1.8837e-09 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 101/2000
13/14 [==========================&gt;...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000
Epoch 00101: val_accuracy did not improve from 0.44144
14/14 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 8.5667 - val_accuracy: 0.4414
Epoch 00101: early stopping
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Link-to-colab">Link to colab<a class="anchor-link" href="#Link-to-colab"> </a></h2><p><a href="https://colab.research.google.com/drive/1mOXvgvkqCEgrAahyUH9Bw0ZO_nLglNFq">https://colab.research.google.com/drive/1mOXvgvkqCEgrAahyUH9Bw0ZO_nLglNFq</a></p>

</div>
</div>
</div>
</div>
 

