{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *\n",
    "# default_exp record_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_test_x = np.load('../08_test/corpora_test_x.npy')\n",
    "target_test_y = np.load('../08_test/target_test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11544, 618, 100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11544, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(target_test_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples to write to the record\n",
    "n_samples = 2\n",
    "\n",
    "# Slice data to get number of examples\n",
    "x = corpora_test_x[0:n_samples]\n",
    "y = target_test_y[0:n_samples]\n",
    "\n",
    "# Reshape data into 1d array\n",
    "x = np.reshape(x, [n_samples*618*100*1,])\n",
    "y = np.reshape(y, [n_samples*2,])\n",
    "\n",
    "output_filename = \"testdata.tfrecord\"\n",
    "\n",
    "writer = tf.io.TFRecordWriter(output_filename)\n",
    "\n",
    "def float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "# Features to be stored in the tf record\n",
    "feature_dict = {\n",
    "    'x': float_feature(x),\n",
    "    'y': int64_feature(y),\n",
    "    'numberOfSamples': int64_feature([n_samples])\n",
    "}\n",
    "\n",
    "example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "\n",
    "writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/roger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from securereqnet.preprocessing import vectorize_sentences\n",
    "\n",
    "class Record_Generator:\n",
    "    \"\"\"Formats data for securereqnet models. Returns TFRecords. \n",
    "    Call Record_Generator(True) if the data is already in the shape [x,618,100,1]\"\"\"\n",
    "    \n",
    "    def __init__(self, path = \".\", name = \"Record\", processed=False):\n",
    "        self.__processed = processed\n",
    "        self.__path = path\n",
    "        self.__name = name\n",
    "        self.__count = 0\n",
    "        \n",
    "        \n",
    "    def __float_feature(self,value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "    def __int64_feature(self,value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "    \n",
    "    def generate_record(self,x,y = None,path=\"\",name=\"Record\",processed=False):\n",
    "        \"\"\"\n",
    "        Writes a single TFRecord.\n",
    "        @param x, by default a string to be processed. Can also be data processed using WHATEVER SECUREREQNET PREPROCESSING IS CALLED\n",
    "        @param y is used for generating training and evaluation data. \n",
    "        @param path is the directory where the record will be written to.\n",
    "        @param name is the name of the record to be generated.\n",
    "        @param processed should be set to true if the data is vectorized in the shape [1,618,100,1]\n",
    "        \"\"\"\n",
    "        \n",
    "        if path == \"\":\n",
    "            path = self.__path\n",
    "        # Name the record Record_1 Record_2 etc.\n",
    "        self.__count+=1\n",
    "        \n",
    "        output_filename = path + \"/\" +  name + \"_\" + str(self.__count) + \".tfrecord\"\n",
    "        print(\"Generating record at: \" + output_filename)\n",
    "        \n",
    "        if processed == False:\n",
    "            x = vectorize_sentences([x])\n",
    "        # Reshape data into 1d array\n",
    "        x = np.reshape(x, [1*618*100*1,])\n",
    "            \n",
    "        if(y is not None):\n",
    "            y = np.reshape(y, [1*2,])\n",
    "        \n",
    "            \n",
    "        # Define dictionary for the record\n",
    "        feature_dict = {\n",
    "        'x': self.__float_feature(x),\n",
    "        'numberOfSamples': self.__int64_feature([1])\n",
    "        }\n",
    "        \n",
    "        # If it is used for training or testing include a y value in the dictionary\n",
    "        if(y is not None):\n",
    "            feature_dict[\"y\"] = self.__int64_feature(y)\n",
    "            \n",
    "        writer = tf.io.TFRecordWriter(output_filename)\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Record_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating record at: ./Record_1.tfrecord\n"
     ]
    }
   ],
   "source": [
    "x = corpora_test_x[0]\n",
    "r.generate_record(x,processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating record at: ./Record_2.tfrecord\n"
     ]
    }
   ],
   "source": [
    "y = target_test_y[0]\n",
    "r.generate_record(x,y,processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Record_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating record at: ./Record_1.tfrecord\n"
     ]
    }
   ],
   "source": [
    "r.generate_record(\"Security Record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
