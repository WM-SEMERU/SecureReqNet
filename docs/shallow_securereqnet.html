---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/archive/05_shallow_securereqnet.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/archive/05_shallow_securereqnet.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Prediction For Main Issues Data Set</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">text</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">punctuation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">skipgrams</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Limited tf.compat.v2.summary API due to missing TensorBoard installation
Limited tf.summary API due to missing TensorBoard installation
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_colwidth</span> <span class="o">=</span> <span class="mi">200</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.stem.snowball</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span>
<span class="n">englishStemmer</span><span class="o">=</span><span class="n">SnowballStemmer</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">MaxPooling1D</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Multiply</span><span class="p">,</span> <span class="n">Subtract</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.layers</span> <span class="kn">import</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">CSVLogger</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#from IPython.display import SVG</span>
<span class="c1">#from keras.utils.vis_utils import model_to_dot</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datasets.read_data</span> <span class="kn">import</span> <span class="n">Dynamic_Dataset</span><span class="p">,</span><span class="n">Processing_Dataset</span>
<span class="kn">from</span> <span class="nn">vectorize_sentence</span> <span class="kn">import</span> <span class="n">Embeddings</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;datasets/augmented_dataset/&quot;</span>
<span class="n">process_unit</span> <span class="o">=</span> <span class="n">Processing_Dataset</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">ground_truth</span> <span class="o">=</span> <span class="n">process_unit</span><span class="o">.</span><span class="n">get_ground_truth</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Dynamic_Dataset</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="n">process_unit</span><span class="o">.</span><span class="n">get_test_and_training</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>11612
104510
(&#39;(1,0)&#39;, &#39;An elevation of privilege vulnerability in the Android framework (ui framework). Product: Android. Versions: 4.4.4, 5.0.2, 5.1.1, 6.0, 6.0.1, 7.0, 7.1.1, 7.1.2. Android ID: A-35056974.&#39;)
(&#39;(1,0)&#39;, &#39;The currently used Rails version, in the stable branch, is insecure\n\nYou should update the Gemfile.lock to hotfix this.\n\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/&#39;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#for elem in train:</span>
<span class="c1">#    print(elem[0])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">Embeddings</span><span class="p">()</span>
<span class="n">max_words</span> <span class="o">=</span> <span class="mi">5000</span> <span class="c1">#&lt;------- [Parameter]</span>
<span class="n">pre_corpora_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">train</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">&lt;</span> <span class="n">max_words</span><span class="p">]</span>
<span class="n">pre_corpora_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">&lt;</span> <span class="n">max_words</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pre_corpora_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pre_corpora_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>103876
11539
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/word_embeddings-embed_size_100-epochs_100.csv&#39;</span>
<span class="n">embeddings_dict</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">get_embeddings_dict</span><span class="p">(</span><span class="n">embed_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">embeddings</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">embeddings_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_train</span><span class="p">]</span><span class="c1">#vectorization Inputs</span>
<span class="n">corpora_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">embeddings</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">embeddings_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_test</span><span class="p">]</span><span class="c1">#vectorization</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_train</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]),</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">3</span><span class="p">])]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_train</span><span class="p">]</span><span class="c1">#vectorization Output</span>
<span class="n">target_test</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]),</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">3</span><span class="p">])]</span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_test</span><span class="p">]</span><span class="c1">#vectorization Output</span>
<span class="c1">#target_train</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_len_sentences_train</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpora_train</span><span class="p">])</span> <span class="c1">#&lt;------- [Parameter]</span>
<span class="n">max_len_sentences_test</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpora_test</span><span class="p">])</span> <span class="c1">#&lt;------- [Parameter]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_len_sentences</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_len_sentences_train</span><span class="p">,</span><span class="n">max_len_sentences_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max. Sentence # words:&quot;</span><span class="p">,</span><span class="n">max_len_sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Max. Sentence # words: 618
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddigs_cols</span> <span class="o">=</span> <span class="n">embed_size</span>
<span class="n">input_sh</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_len_sentences</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#Selecting filters? </span>
<span class="c1">#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function</span>
<span class="c1">#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional</span>

<span class="n">N_filters</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1"># &lt;-------- [HyperParameter] Powers of 2 Numer of Features</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># &lt;-------- [HyperParameter] Number of Classess</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_sh</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(618, 100, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gram_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">input_sh</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_1_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="n">N_filters</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_sh</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span><span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;channels_last&quot;</span><span class="p">)(</span><span class="n">gram_input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_3_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="n">N_filters</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_sh</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">gram_input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_5_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="n">N_filters</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_sh</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">gram_input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_pool_1_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">max_len_sentences</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_1_gram</span><span class="p">)</span>
<span class="n">max_pool_3_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">max_len_sentences</span><span class="o">-</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_3_gram</span><span class="p">)</span>
<span class="n">max_pool_5_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">max_len_sentences</span><span class="o">-</span><span class="mi">5</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fully_connected_1_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_1_gram</span><span class="p">)</span>
<span class="n">fully_connected_3_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_3_gram</span><span class="p">)</span>
<span class="n">fully_connected_5_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">merged_vector</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fully_connected_1_gram</span><span class="p">,</span> <span class="n">fully_connected_3_gram</span><span class="p">,</span> 
                                    <span class="n">fully_connected_5_gram</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">integration_layer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">merged_vector</span><span class="p">)</span> <span class="c1"># &lt;-------- [HyperParameter]</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">integration_layer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criticality_network</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">gram_input</span><span class="p">],</span><span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">predictions</span><span class="p">])</span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">criticality_network</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;model&#34;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 618, 100, 1) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 618, 1, 128)  12928       input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 616, 1, 128)  38528       input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 614, 1, 128)  64128       input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 1, 1, 128)    0           conv2d[0][0]                     
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 128)          0           max_pooling2d[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 128)          0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 128)          0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 384)          0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dropout (Dropout)               (None, 384)          0           concatenate[0][0]                
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            770         dropout[0][0]                    
==================================================================================================
Total params: 116,354
Trainable params: 116,354
Non-trainable params: 0
__________________________________________________________________________________________________
None
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criticality_network</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
                                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">mkdtemp</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">path</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">file_corpora_train_x</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mkdtemp</span><span class="p">(),</span> <span class="s1">&#39;e-res_temp_corpora_train_x.dat&#39;</span><span class="p">)</span> <span class="c1">#Update per experiment</span>
<span class="n">file_corpora_test_x</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mkdtemp</span><span class="p">(),</span> <span class="s1">&#39;e-res_temp_corpora_test_x.dat&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shape_train_x</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">),</span><span class="n">max_len_sentences</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape_test_x</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">),</span><span class="n">max_len_sentences</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">file_corpora_train_x</span><span class="p">,</span> 
        <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> 
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> 
        <span class="n">shape</span> <span class="o">=</span> <span class="n">shape_train_x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_test_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span> <span class="c1">#Test Corpora (for future evaluation)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">file_corpora_test_x</span><span class="p">,</span> 
        <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> 
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> 
        <span class="n">shape</span> <span class="o">=</span> <span class="n">shape_test_x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target_train</span><span class="p">)</span> <span class="c1">#Train Target</span>
<span class="n">target_test_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target_test</span><span class="p">)</span> <span class="c1">#Test Target (for future evaluation)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_train_x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(103876, 618, 100, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_train_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(103876, 2)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_test_x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(11539, 618, 100, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_test_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(11539, 2)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">)):</span>
    <span class="c1">#print(corpora_train[doc].shape[1])</span>
    <span class="k">for</span> <span class="n">words_rows</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">embed_flatten</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">[</span><span class="n">doc</span><span class="p">][</span><span class="n">words_rows</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="c1">#&lt;--- Capture doc and word</span>
        <span class="k">for</span> <span class="n">embedding_cols</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embed_flatten</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">corpora_train_x</span><span class="p">[</span><span class="n">doc</span><span class="p">,</span><span class="n">words_rows</span><span class="p">,</span><span class="n">embedding_cols</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">embed_flatten</span><span class="p">[</span><span class="n">embedding_cols</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">words_rows</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">embed_flatten</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">[</span><span class="n">doc</span><span class="p">][</span><span class="n">words_rows</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="c1">#&lt;--- Capture doc and word</span>
        <span class="k">for</span> <span class="n">embedding_cols</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embed_flatten</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">corpora_test_x</span><span class="p">[</span><span class="n">doc</span><span class="p">,</span><span class="n">words_rows</span><span class="p">,</span><span class="n">embedding_cols</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">embed_flatten</span><span class="p">[</span><span class="n">embedding_cols</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#csv_logger = CSVLogger(system+&#39;_training.log&#39;)</span>
<span class="n">filepath</span> <span class="o">=</span> <span class="s2">&quot;e-res/best_model.hdf5&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">es</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">mc</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">callbacks_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">es</span><span class="p">,</span><span class="n">mc</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">criticality_network</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">corpora_train_x</span><span class="p">,</span> 
            <span class="n">y</span> <span class="o">=</span> <span class="n">target_train_y</span><span class="p">,</span>
            <span class="c1">#batch_size=64,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="c1">#5 &lt;------ Hyperparameter</span>
            <span class="n">validation_split</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks_list</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 83100 samples, validate on 20776 samples
Epoch 1/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9560
Epoch 00001: val_accuracy improved from -inf to 0.99884, saving model to e-res/best_model.hdf5
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.1308 - accuracy: 0.9560 - val_loss: 0.0035 - val_accuracy: 0.9988
Epoch 2/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9662
Epoch 00002: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 122s 1ms/sample - loss: 0.1000 - accuracy: 0.9662 - val_loss: 0.0052 - val_accuracy: 0.9981
Epoch 3/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9706
Epoch 00003: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0873 - accuracy: 0.9706 - val_loss: 0.0036 - val_accuracy: 0.9987
Epoch 4/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9722
Epoch 00004: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0795 - accuracy: 0.9722 - val_loss: 0.0057 - val_accuracy: 0.9979
Epoch 5/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9754
Epoch 00005: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 128s 2ms/sample - loss: 0.0709 - accuracy: 0.9754 - val_loss: 0.0049 - val_accuracy: 0.9983
Epoch 6/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9773
Epoch 00006: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0644 - accuracy: 0.9773 - val_loss: 0.0064 - val_accuracy: 0.9974
Epoch 7/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9800
Epoch 00007: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0589 - accuracy: 0.9800 - val_loss: 0.0076 - val_accuracy: 0.9971
Epoch 8/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9819 ETA: 1s - loss: 0
Epoch 00008: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0534 - accuracy: 0.9819 - val_loss: 0.0038 - val_accuracy: 0.9985
Epoch 9/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9834
Epoch 00009: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.0040 - val_accuracy: 0.9986
Epoch 10/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9846
Epoch 00010: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0440 - accuracy: 0.9846 - val_loss: 0.0069 - val_accuracy: 0.9977
Epoch 11/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9860
Epoch 00011: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0422 - accuracy: 0.9860 - val_loss: 0.0042 - val_accuracy: 0.9987
Epoch 12/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9871
Epoch 00012: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0378 - accuracy: 0.9871 - val_loss: 0.0057 - val_accuracy: 0.9981
Epoch 13/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9877
Epoch 00013: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.0051 - val_accuracy: 0.9984
Epoch 14/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9886
Epoch 00014: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 125s 2ms/sample - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0064 - val_accuracy: 0.9981
Epoch 15/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9885
Epoch 00015: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0050 - val_accuracy: 0.9986
Epoch 16/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9887
Epoch 00016: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.0097 - val_accuracy: 0.9969
Epoch 17/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9906
Epoch 00017: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0052 - val_accuracy: 0.9986
Epoch 18/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9899
Epoch 00018: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0047 - val_accuracy: 0.9987
Epoch 19/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9910
Epoch 00019: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0147 - val_accuracy: 0.9962
Epoch 20/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9913
Epoch 00020: val_accuracy did not improve from 0.99884
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0060 - val_accuracy: 0.9983
Epoch 21/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9912
Epoch 00021: val_accuracy improved from 0.99884 to 0.99889, saving model to e-res/best_model.hdf5
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.0040 - val_accuracy: 0.9989
Epoch 22/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9916 ETA: 1s - loss:
Epoch 00022: val_accuracy did not improve from 0.99889
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0043 - val_accuracy: 0.9988
Epoch 23/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9926
Epoch 00023: val_accuracy did not improve from 0.99889
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0044 - val_accuracy: 0.9988
Epoch 24/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9925
Epoch 00024: val_accuracy did not improve from 0.99889
83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0068 - val_accuracy: 0.9982
Epoch 25/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9928
Epoch 00025: val_accuracy improved from 0.99889 to 0.99904, saving model to e-res/best_model.hdf5
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0040 - val_accuracy: 0.9990
Epoch 26/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9920
Epoch 00026: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0073 - val_accuracy: 0.9984
Epoch 27/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9928
Epoch 00027: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0047 - val_accuracy: 0.9988
Epoch 28/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9937
Epoch 00028: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0068 - val_accuracy: 0.9986
Epoch 29/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9930
Epoch 00029: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0097 - val_accuracy: 0.9977
Epoch 30/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9937
Epoch 00030: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.0105 - val_accuracy: 0.9977
Epoch 31/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9934
Epoch 00031: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0071 - val_accuracy: 0.9982
Epoch 32/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9933
Epoch 00032: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0077 - val_accuracy: 0.9985
Epoch 33/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9944
Epoch 00033: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 123s 1ms/sample - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0084 - val_accuracy: 0.9983
Epoch 34/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9939
Epoch 00034: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.0113 - val_accuracy: 0.9976
Epoch 35/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9943
Epoch 00035: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0097 - val_accuracy: 0.9980
Epoch 36/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9940
Epoch 00036: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0062 - val_accuracy: 0.9989
Epoch 37/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9946 ETA: 0s - loss: 0.0201 - accu
Epoch 00037: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.0115 - val_accuracy: 0.9979
Epoch 38/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9945
Epoch 00038: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0069 - val_accuracy: 0.9984
Epoch 39/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9946
Epoch 00039: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0110 - val_accuracy: 0.9979
Epoch 40/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9946
Epoch 00040: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0078 - val_accuracy: 0.9983
Epoch 41/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9948
Epoch 00041: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0090 - val_accuracy: 0.9983
Epoch 42/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9949
Epoch 00042: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0073 - val_accuracy: 0.9983
Epoch 43/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947
Epoch 00043: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0044 - val_accuracy: 0.9989
Epoch 44/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9951
Epoch 00044: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.0064 - val_accuracy: 0.9985
Epoch 45/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9955
Epoch 00045: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0137 - val_accuracy: 0.9974
Epoch 46/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9948 ETA: 1s - l
Epoch 00046: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.0095 - val_accuracy: 0.9984
Epoch 47/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9952
Epoch 00047: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0127 - val_accuracy: 0.9976
Epoch 48/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9949
Epoch 00048: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0089 - val_accuracy: 0.9982
Epoch 49/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9952
Epoch 00049: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0092 - val_accuracy: 0.9980
Epoch 50/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956
Epoch 00050: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0094 - val_accuracy: 0.9983
Epoch 51/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9958
Epoch 00051: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0068 - val_accuracy: 0.9988
Epoch 52/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9950
Epoch 00052: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0073 - val_accuracy: 0.9984
Epoch 53/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9956
Epoch 00053: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0072 - val_accuracy: 0.9986
Epoch 54/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9955
Epoch 00054: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0134 - val_accuracy: 0.9976
Epoch 55/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9955
Epoch 00055: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.0103 - val_accuracy: 0.9982
Epoch 56/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9957
Epoch 00056: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0078 - val_accuracy: 0.9987
Epoch 57/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9957
Epoch 00057: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0100 - val_accuracy: 0.9981
Epoch 58/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9956
Epoch 00058: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0054 - val_accuracy: 0.9987
Epoch 59/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9957
Epoch 00059: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0136 - val_accuracy: 0.9976
Epoch 60/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9961
Epoch 00060: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0107 - val_accuracy: 0.9981
Epoch 61/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9959
Epoch 00061: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0162 - val_accuracy: 0.9972
Epoch 62/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9964
Epoch 00062: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0077 - val_accuracy: 0.9988
Epoch 63/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9960
Epoch 00063: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0081 - val_accuracy: 0.9987
Epoch 64/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9962
Epoch 00064: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.0091 - val_accuracy: 0.9985
Epoch 65/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9961
Epoch 00065: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0088 - val_accuracy: 0.9988
Epoch 66/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9964
Epoch 00066: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0103 - val_accuracy: 0.9982
Epoch 67/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9962
Epoch 00067: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0108 - val_accuracy: 0.9985
Epoch 68/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9963
Epoch 00068: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.0097 - val_accuracy: 0.9985
Epoch 69/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9963
Epoch 00069: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9980
Epoch 70/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9960
Epoch 00070: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0095 - val_accuracy: 0.9986
Epoch 71/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9967
Epoch 00071: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.0159 - val_accuracy: 0.9974
Epoch 72/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9966
Epoch 00072: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0148 - val_accuracy: 0.9978
Epoch 73/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9964
Epoch 00073: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0110 - val_accuracy: 0.9985
Epoch 74/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9964
Epoch 00074: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.0106 - val_accuracy: 0.9984
Epoch 75/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9969
Epoch 00075: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9982
Epoch 76/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9962
Epoch 00076: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.0211 - val_accuracy: 0.9969
Epoch 77/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9966
Epoch 00077: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.0124 - val_accuracy: 0.9983
Epoch 78/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9967
Epoch 00078: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0101 - val_accuracy: 0.9988
Epoch 79/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9964
Epoch 00079: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0134 - val_accuracy: 0.9981
Epoch 80/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9968
Epoch 00080: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0128 - val_accuracy: 0.9983
Epoch 81/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9965
Epoch 00081: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 118s 1ms/sample - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0140 - val_accuracy: 0.9982
Epoch 82/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9966
Epoch 00082: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.0109 - val_accuracy: 0.9985
Epoch 83/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9967
Epoch 00083: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.0144 - val_accuracy: 0.9981
Epoch 84/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9967
Epoch 00084: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.0149 - val_accuracy: 0.9981
Epoch 85/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9966
Epoch 00085: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 109s 1ms/sample - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0161 - val_accuracy: 0.9975
Epoch 86/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9970
Epoch 00086: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0161 - val_accuracy: 0.9977
Epoch 87/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9967
Epoch 00087: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0116 - val_accuracy: 0.9985
Epoch 88/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9968
Epoch 00088: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0157 - val_accuracy: 0.9981
Epoch 89/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9970
Epoch 00089: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.0112 - val_accuracy: 0.9985
Epoch 90/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9968
Epoch 00090: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 112s 1ms/sample - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0175 - val_accuracy: 0.9977
Epoch 91/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9970
Epoch 00091: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0127 - val_accuracy: 0.9982
Epoch 92/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9970
Epoch 00092: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0116 - val_accuracy: 0.9981
Epoch 93/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971
Epoch 00093: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0165 - val_accuracy: 0.9978
Epoch 94/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9970
Epoch 00094: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0142 - val_accuracy: 0.9980
Epoch 95/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9970
Epoch 00095: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 111s 1ms/sample - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0174 - val_accuracy: 0.9979
Epoch 96/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9976
Epoch 00096: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0122 - val_accuracy: 0.9983
Epoch 97/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9967
Epoch 00097: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9981
Epoch 98/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9972
Epoch 00098: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 110s 1ms/sample - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0186 - val_accuracy: 0.9977
Epoch 99/2000
83040/83100 [============================&gt;.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971
Epoch 00099: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0229 - val_accuracy: 0.9971
Epoch 100/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9970
Epoch 00100: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.0118 - val_accuracy: 0.9986
Epoch 101/2000
83072/83100 [============================&gt;.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9973
Epoch 00101: val_accuracy did not improve from 0.99904
83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.0211 - val_accuracy: 0.9973
Epoch 00101: early stopping
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_history</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
<span class="n">df_history</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;e-res/history_training.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_history</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>loss</th>
      <th>val_accuracy</th>
      <th>val_loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.955993</td>
      <td>0.130766</td>
      <td>0.998845</td>
      <td>0.003467</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.966173</td>
      <td>0.099961</td>
      <td>0.998123</td>
      <td>0.005184</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.970638</td>
      <td>0.087270</td>
      <td>0.998652</td>
      <td>0.003626</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.972238</td>
      <td>0.079534</td>
      <td>0.997930</td>
      <td>0.005712</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.975439</td>
      <td>0.070949</td>
      <td>0.998267</td>
      <td>0.004923</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;e-res/corpora_test_x.npy&#39;</span><span class="p">,</span><span class="n">corpora_test_x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;e-res/target_test_y.npy&#39;</span><span class="p">,</span><span class="n">target_test_y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
 
<span class="n">epochs2</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span><span class="p">,</span><span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.fixes</span> <span class="kn">import</span> <span class="n">signature</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;e-res/best_model.hdf5&#39;</span>
<span class="n">criticality_network_load</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="c1">#&lt;----- The Model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np_target_test_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;e-res/target_test_y.npy&#39;</span><span class="p">)</span>
<span class="n">np_corpora_test_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;e-res/corpora_test_x.npy&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="n">criticality_network_load</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">np_corpora_test_x</span><span class="p">,</span> <span class="n">np_target_test_y</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>11539/11539 [==============================] - 3s 247us/sample - loss: 0.1313 - accuracy: 0.9736
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 0.13130904127952253
Test accuracy: 0.9735679
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history_predict</span> <span class="o">=</span> <span class="n">criticality_network_load</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np_corpora_test_x</span><span class="p">)</span>
<span class="n">history_predict</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[1.0000000e+00, 9.7539722e-17],
       [9.3283859e-07, 9.9999905e-01],
       [1.0000000e+00, 2.0519539e-29],
       ...,
       [2.1023639e-04, 9.9978977e-01],
       [9.9999917e-01, 7.8283227e-07],
       [5.1913088e-07, 9.9999952e-01]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inferred_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history_predict</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;AB&#39;</span><span class="p">))</span>
<span class="n">target_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np_target_test_y</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;LN&#39;</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">target_data</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">inferred_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>L</th>
      <th>N</th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1.000000e+00</td>
      <td>9.753972e-17</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>9.328386e-07</td>
      <td>9.999990e-01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>1.000000e+00</td>
      <td>2.051954e-29</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1</td>
      <td>1.231208e-04</td>
      <td>9.998769e-01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>1.000000e+00</td>
      <td>3.948549e-15</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_true</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;L&#39;</span><span class="p">])</span>
<span class="n">y_score</span><span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">])</span>
<span class="n">average_precision</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average precision-recall score: </span><span class="si">{0:0.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">average_precision</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Average precision-recall score: 1.00
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">step_kwargs</span> <span class="o">=</span> <span class="p">({</span><span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="s1">&#39;post&#39;</span><span class="p">}</span>
               <span class="k">if</span> <span class="s1">&#39;step&#39;</span> <span class="ow">in</span> <span class="n">signature</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
               <span class="k">else</span> <span class="p">{})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
         <span class="n">where</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">step_kwargs</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;2-class Precision-Recall curve: AP=</span><span class="si">{0:0.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">average_precision</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.text.Text at 0x7fb5b4192208&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;AUC: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">auc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC: 0.995
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

