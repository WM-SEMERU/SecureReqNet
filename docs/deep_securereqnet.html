---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/archive/06_deep_securereqnet.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/archive/06_deep_securereqnet.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Prediction For Main Issues Data Set</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">text</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">punctuation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">skipgrams</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Limited tf.compat.v2.summary API due to missing TensorBoard installation
Limited tf.summary API due to missing TensorBoard installation
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_colwidth</span> <span class="o">=</span> <span class="mi">200</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.stem.snowball</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span>
<span class="n">englishStemmer</span><span class="o">=</span><span class="n">SnowballStemmer</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">MaxPooling1D</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Multiply</span><span class="p">,</span> <span class="n">Subtract</span><span class="p">,</span> <span class="n">Reshape</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.layers</span> <span class="kn">import</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">CSVLogger</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#from IPython.display import SVG</span>
<span class="c1">#from keras.utils.vis_utils import model_to_dot</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datasets.read_data</span> <span class="kn">import</span> <span class="n">Dynamic_Dataset</span><span class="p">,</span><span class="n">Processing_Dataset</span>
<span class="kn">from</span> <span class="nn">vectorize_sentence</span> <span class="kn">import</span> <span class="n">Embeddings</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;datasets/augmented_dataset/&quot;</span>
<span class="n">process_unit</span> <span class="o">=</span> <span class="n">Processing_Dataset</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">ground_truth</span> <span class="o">=</span> <span class="n">process_unit</span><span class="o">.</span><span class="n">get_ground_truth</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Dynamic_Dataset</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="n">process_unit</span><span class="o">.</span><span class="n">get_test_and_training</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>11612
104510
(&#39;(1,0)&#39;, &#39;OSRAM SYLVANIA Osram Lightify Home before 2016-07-26 allows remote attackers to execute arbitrary commands via TCP port 4000.&#39;)
(&#39;(1,0)&#39;, &#39;The currently used Rails version, in the stable branch, is insecure\n\nYou should update the Gemfile.lock to hotfix this.\n\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/&#39;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#for elem in test:</span>
<span class="c1">#    print(elem[0])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">Embeddings</span><span class="p">()</span>
<span class="n">max_words</span> <span class="o">=</span> <span class="mi">5000</span> <span class="c1">#&lt;------- [Parameter]</span>
<span class="n">pre_corpora_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">train</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">&lt;</span> <span class="n">max_words</span><span class="p">]</span>
<span class="n">pre_corpora_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">&lt;</span> <span class="n">max_words</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pre_corpora_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pre_corpora_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>103862
11553
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/word_embeddings-embed_size_100-epochs_100.csv&#39;</span>
<span class="n">embeddings_dict</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">get_embeddings_dict</span><span class="p">(</span><span class="n">embed_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">embeddings</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">embeddings_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_train</span><span class="p">]</span><span class="c1">#vectorization Inputs</span>
<span class="n">corpora_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">embeddings</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">embeddings_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_test</span><span class="p">]</span><span class="c1">#vectorization</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_train</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]),</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">3</span><span class="p">])]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_train</span><span class="p">]</span><span class="c1">#vectorization Output</span>
<span class="n">target_test</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]),</span><span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">3</span><span class="p">])]</span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">pre_corpora_test</span><span class="p">]</span><span class="c1">#vectorization Output</span>
<span class="c1">#target_train</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_len_sentences_train</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpora_train</span><span class="p">])</span> <span class="c1">#&lt;------- [Parameter]</span>
<span class="n">max_len_sentences_test</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpora_test</span><span class="p">])</span> <span class="c1">#&lt;------- [Parameter]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_len_sentences</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_len_sentences_train</span><span class="p">,</span><span class="n">max_len_sentences_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max. Sentence # words:&quot;</span><span class="p">,</span><span class="n">max_len_sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Max. Sentence # words: 618
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embeddigs_cols</span> <span class="o">=</span> <span class="n">embed_size</span>
<span class="n">input_sh</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_len_sentences</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#Selecting filters? </span>
<span class="c1">#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function</span>
<span class="c1">#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional</span>

<span class="n">N_filters</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># &lt;-------- [HyperParameter] Powers of 2 Numer of Features</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># &lt;-------- [HyperParameter] Number of Classess</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_sh</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(618, 100, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gram_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">input_sh</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_1_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="n">N_filters</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_sh</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span><span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;channels_last&quot;</span><span class="p">)(</span><span class="n">gram_input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_3_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="n">N_filters</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_sh</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">gram_input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_5_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="n">N_filters</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_sh</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">gram_input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">conv_filter_1_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conv_filter_3_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conv_filter_5_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(None, 618, 1, 512)
(None, 616, 1, 512)
(None, 614, 1, 512)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_pool_1_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">max_len_sentences</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_1_gram</span><span class="p">)</span>
<span class="n">max_pool_3_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">max_len_sentences</span><span class="o">-</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_3_gram</span><span class="p">)</span>
<span class="n">max_pool_5_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">max_len_sentences</span><span class="o">-</span><span class="mi">5</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">max_pool_1_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_pool_3_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_pool_5_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(None, 1, 1, 512)
(None, 1, 1, 512)
(None, 1, 1, 512)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fully_connected_1_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_1_gram</span><span class="p">)</span>
<span class="n">fully_connected_3_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_3_gram</span><span class="p">)</span>
<span class="n">fully_connected_5_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_1_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_3_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_5_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(None, 512)
(None, 512)
(None, 512)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fully_connected_1_gram</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="n">N_filters</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">fully_connected_1_gram</span><span class="p">)</span>
<span class="n">fully_connected_3_gram</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="n">N_filters</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">fully_connected_3_gram</span><span class="p">)</span>
<span class="n">fully_connected_5_gram</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="n">N_filters</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="n">fully_connected_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_1_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_3_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_5_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(None, 512, 1, 1)
(None, 512, 1, 1)
(None, 512, 1, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 1st Convolutional Layer (1-gram)</span>
<span class="n">conv_filter_1_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">fully_connected_1_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_1_gram</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([None, 512, 1, 128])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_3_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">fully_connected_3_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_3_gram</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([None, 510, 1, 128])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_5_gram</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
                       <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">fully_connected_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv_filter_5_gram</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([None, 508, 1, 128])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_pool_1_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">N_filters</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_1_gram</span><span class="p">)</span>
<span class="n">max_pool_3_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">N_filters</span><span class="o">-</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_3_gram</span><span class="p">)</span>
<span class="n">max_pool_5_gram</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">((</span><span class="n">N_filters</span><span class="o">-</span><span class="mi">5</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">conv_filter_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">max_pool_1_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_pool_3_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_pool_5_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(None, 1, 1, 128)
(None, 1, 1, 128)
(None, 1, 1, 128)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fully_connected_1_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_1_gram</span><span class="p">)</span>
<span class="n">fully_connected_3_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_3_gram</span><span class="p">)</span>
<span class="n">fully_connected_5_gram</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool_5_gram</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_1_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_3_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fully_connected_5_gram</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(None, 128)
(None, 128)
(None, 128)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">merged_vector</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">fully_connected_1_gram</span><span class="p">,</span> <span class="n">fully_connected_3_gram</span><span class="p">,</span> 
                                    <span class="n">fully_connected_5_gram</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">integration_layer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">merged_vector</span><span class="p">)</span> <span class="c1"># &lt;-------- [HyperParameter]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">deep_dense_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">N_filters</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">integration_layer</span><span class="p">)</span>
<span class="n">deep_dense_layer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">deep_dense_layer</span><span class="p">)</span> <span class="c1"># &lt;-------- [HyperParameter]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">deep_dense_layer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criticality_network</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">gram_input</span><span class="p">],</span><span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">predictions</span><span class="p">])</span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">criticality_network</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;model&#34;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 618, 100, 1) 0                                            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 618, 1, 512)  51712       input_2[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 616, 1, 512)  154112      input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 614, 1, 512)  256512      input_2[0][0]                    
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 512)          0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 1, 1, 512)    0           flatten_9[0][0]                  
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 512)          0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 512)          0           max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 1, 1, 512)    0           reshape_1[0][0]                  
__________________________________________________________________________________________________
reshape_3 (Reshape)             (None, 1, 1, 512)    0           flatten_10[0][0]                 
__________________________________________________________________________________________________
reshape_4 (Reshape)             (None, 1, 1, 512)    0           flatten_11[0][0]                 
__________________________________________________________________________________________________
reshape_5 (Reshape)             (None, 1, 512, 1)    0           reshape_2[0][0]                  
__________________________________________________________________________________________________
reshape_6 (Reshape)             (None, 1, 512, 1)    0           reshape_3[0][0]                  
__________________________________________________________________________________________________
reshape_7 (Reshape)             (None, 1, 512, 1)    0           reshape_4[0][0]                  
__________________________________________________________________________________________________
reshape_8 (Reshape)             (None, 512, 1, 1)    0           reshape_5[0][0]                  
__________________________________________________________________________________________________
reshape_9 (Reshape)             (None, 512, 1, 1)    0           reshape_6[0][0]                  
__________________________________________________________________________________________________
reshape_10 (Reshape)            (None, 512, 1, 1)    0           reshape_7[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 512, 1, 128)  256         reshape_8[0][0]                  
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 510, 1, 128)  512         reshape_9[0][0]                  
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 508, 1, 128)  768         reshape_10[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_16[0][0]                  
__________________________________________________________________________________________________
max_pooling2d_9 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 128)          0           max_pooling2d_7[0][0]            
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 128)          0           max_pooling2d_8[0][0]            
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 128)          0           max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 384)          0           flatten_12[0][0]                 
                                                                 flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dropout (Dropout)               (None, 384)          0           concatenate[0][0]                
__________________________________________________________________________________________________
dense (Dense)                   (None, 512)          197120      dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            1026        dropout_1[0][0]                  
==================================================================================================
Total params: 662,018
Trainable params: 662,018
Non-trainable params: 0
__________________________________________________________________________________________________
None
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criticality_network</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
                                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">mkdtemp</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">path</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">file_corpora_train_x</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mkdtemp</span><span class="p">(),</span> <span class="s1">&#39;f-res_temp_corpora_train_x.dat&#39;</span><span class="p">)</span> <span class="c1">#Update per experiment</span>
<span class="n">file_corpora_test_x</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">mkdtemp</span><span class="p">(),</span> <span class="s1">&#39;f-res_temp_corpora_test_x.dat&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shape_train_x</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">),</span><span class="n">max_len_sentences</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape_test_x</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">),</span><span class="n">max_len_sentences</span><span class="p">,</span><span class="n">embeddigs_cols</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">file_corpora_train_x</span><span class="p">,</span> 
        <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> 
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> 
        <span class="n">shape</span> <span class="o">=</span> <span class="n">shape_train_x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_test_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span> <span class="c1">#Test Corpora (for future evaluation)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">file_corpora_test_x</span><span class="p">,</span> 
        <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> 
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w+&#39;</span><span class="p">,</span> 
        <span class="n">shape</span> <span class="o">=</span> <span class="n">shape_test_x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target_train</span><span class="p">)</span> <span class="c1">#Train Target</span>
<span class="n">target_test_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target_test</span><span class="p">)</span> <span class="c1">#Test Target (for future evaluation)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_train_x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(103862, 618, 100, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_train_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(103862, 2)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpora_test_x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(11553, 618, 100, 1)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_test_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(11553, 2)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">)):</span>
    <span class="c1">#print(corpora_train[doc].shape[1])</span>
    <span class="k">for</span> <span class="n">words_rows</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">embed_flatten</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpora_train</span><span class="p">[</span><span class="n">doc</span><span class="p">][</span><span class="n">words_rows</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="c1">#&lt;--- Capture doc and word</span>
        <span class="k">for</span> <span class="n">embedding_cols</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embed_flatten</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">corpora_train_x</span><span class="p">[</span><span class="n">doc</span><span class="p">,</span><span class="n">words_rows</span><span class="p">,</span><span class="n">embedding_cols</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">embed_flatten</span><span class="p">[</span><span class="n">embedding_cols</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">words_rows</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">embed_flatten</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpora_test</span><span class="p">[</span><span class="n">doc</span><span class="p">][</span><span class="n">words_rows</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="c1">#&lt;--- Capture doc and word</span>
        <span class="k">for</span> <span class="n">embedding_cols</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embed_flatten</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">corpora_test_x</span><span class="p">[</span><span class="n">doc</span><span class="p">,</span><span class="n">words_rows</span><span class="p">,</span><span class="n">embedding_cols</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">embed_flatten</span><span class="p">[</span><span class="n">embedding_cols</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#csv_logger = CSVLogger(system+&#39;_training.log&#39;)</span>
<span class="n">filepath</span> <span class="o">=</span> <span class="s2">&quot;f-res/best_model.hdf5&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">es</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">mc</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">callbacks_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">es</span><span class="p">,</span><span class="n">mc</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">criticality_network</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">corpora_train_x</span><span class="p">,</span> 
            <span class="n">y</span> <span class="o">=</span> <span class="n">target_train_y</span><span class="p">,</span>
            <span class="c1">#batch_size=64,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="c1">#5 &lt;------ Hyperparameter</span>
            <span class="n">validation_split</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks_list</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 83089 samples, validate on 20773 samples
Epoch 1/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9472
Epoch 00001: val_accuracy improved from -inf to 0.99649, saving model to f-res/best_model.hdf5
83089/83089 [==============================] - 330s 4ms/sample - loss: 0.1510 - accuracy: 0.9472 - val_loss: 0.0075 - val_accuracy: 0.9965
Epoch 2/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9617
Epoch 00002: val_accuracy did not improve from 0.99649
83089/83089 [==============================] - 338s 4ms/sample - loss: 0.1126 - accuracy: 0.9617 - val_loss: 0.0109 - val_accuracy: 0.9955
Epoch 3/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9652
Epoch 00003: val_accuracy improved from 0.99649 to 0.99653, saving model to f-res/best_model.hdf5
83089/83089 [==============================] - 346s 4ms/sample - loss: 0.1008 - accuracy: 0.9652 - val_loss: 0.0075 - val_accuracy: 0.9965
Epoch 4/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9688
Epoch 00004: val_accuracy improved from 0.99653 to 0.99832, saving model to f-res/best_model.hdf5
83089/83089 [==============================] - 339s 4ms/sample - loss: 0.0906 - accuracy: 0.9688 - val_loss: 0.0048 - val_accuracy: 0.9983
Epoch 5/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0816 - accuracy: 0.9717
Epoch 00005: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 339s 4ms/sample - loss: 0.0816 - accuracy: 0.9717 - val_loss: 0.0103 - val_accuracy: 0.9957
Epoch 6/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9740
Epoch 00006: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 338s 4ms/sample - loss: 0.0738 - accuracy: 0.9740 - val_loss: 0.0062 - val_accuracy: 0.9978
Epoch 7/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9768
Epoch 00007: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 343s 4ms/sample - loss: 0.0659 - accuracy: 0.9768 - val_loss: 0.0080 - val_accuracy: 0.9968
Epoch 8/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9799
Epoch 00008: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 328s 4ms/sample - loss: 0.0572 - accuracy: 0.9799 - val_loss: 0.0067 - val_accuracy: 0.9976
Epoch 9/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9813
Epoch 00009: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0548 - accuracy: 0.9813 - val_loss: 0.0059 - val_accuracy: 0.9976
Epoch 10/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9828
Epoch 00010: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0481 - accuracy: 0.9828 - val_loss: 0.0080 - val_accuracy: 0.9973
Epoch 11/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9841
Epoch 00011: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 308s 4ms/sample - loss: 0.0460 - accuracy: 0.9841 - val_loss: 0.0107 - val_accuracy: 0.9965
Epoch 12/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9860
Epoch 00012: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0402 - accuracy: 0.9860 - val_loss: 0.0088 - val_accuracy: 0.9967
Epoch 13/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9880
Epoch 00013: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.0115 - val_accuracy: 0.9966
Epoch 14/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9882
Epoch 00014: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0090 - val_accuracy: 0.9965
Epoch 15/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9888
Epoch 00015: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 308s 4ms/sample - loss: 0.0315 - accuracy: 0.9888 - val_loss: 0.0101 - val_accuracy: 0.9978
Epoch 16/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9898
Epoch 00016: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 315s 4ms/sample - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.0119 - val_accuracy: 0.9968
Epoch 17/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9904
Epoch 00017: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 369s 4ms/sample - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.0118 - val_accuracy: 0.9970
Epoch 18/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9916
Epoch 00018: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 370s 4ms/sample - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.0130 - val_accuracy: 0.9972
Epoch 19/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9920
Epoch 00019: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 372s 4ms/sample - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0131 - val_accuracy: 0.9962
Epoch 20/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9921
Epoch 00020: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 381s 5ms/sample - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0138 - val_accuracy: 0.9975
Epoch 21/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9927
Epoch 00021: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 373s 4ms/sample - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.0101 - val_accuracy: 0.9977
Epoch 22/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9930
Epoch 00022: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 373s 4ms/sample - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0160 - val_accuracy: 0.9957
Epoch 23/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9929
Epoch 00023: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 382s 5ms/sample - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0114 - val_accuracy: 0.9972
Epoch 24/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9936
Epoch 00024: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 375s 5ms/sample - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0156 - val_accuracy: 0.9967
Epoch 25/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9939
Epoch 00025: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 373s 4ms/sample - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0186 - val_accuracy: 0.9958
Epoch 26/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9940
Epoch 00026: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 372s 4ms/sample - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0124 - val_accuracy: 0.9969
Epoch 27/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9939
Epoch 00027: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 384s 5ms/sample - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0118 - val_accuracy: 0.9963
Epoch 28/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9949
Epoch 00028: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 377s 5ms/sample - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0086 - val_accuracy: 0.9976
Epoch 29/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9944
Epoch 00029: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 374s 5ms/sample - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0226 - val_accuracy: 0.9947
Epoch 30/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9942
Epoch 00030: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 376s 5ms/sample - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0185 - val_accuracy: 0.9963
Epoch 31/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9948
Epoch 00031: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 382s 5ms/sample - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0162 - val_accuracy: 0.9963
Epoch 32/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9950
Epoch 00032: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 375s 5ms/sample - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0152 - val_accuracy: 0.9971
Epoch 33/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9953
Epoch 00033: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 377s 5ms/sample - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0151 - val_accuracy: 0.9974
Epoch 34/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9954
Epoch 00034: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 384s 5ms/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0173 - val_accuracy: 0.9967
Epoch 35/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9955
Epoch 00035: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 375s 5ms/sample - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0184 - val_accuracy: 0.9964
Epoch 36/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9954
Epoch 00036: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 375s 5ms/sample - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0183 - val_accuracy: 0.9966
Epoch 37/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9957
Epoch 00037: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 376s 5ms/sample - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0158 - val_accuracy: 0.9965
Epoch 38/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9961
Epoch 00038: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 384s 5ms/sample - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0130 - val_accuracy: 0.9966
Epoch 39/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9957
Epoch 00039: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 376s 5ms/sample - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0206 - val_accuracy: 0.9960
Epoch 40/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9963
Epoch 00040: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 377s 5ms/sample - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0157 - val_accuracy: 0.9969
Epoch 41/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9957
Epoch 00041: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 378s 5ms/sample - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0113 - val_accuracy: 0.9980
Epoch 42/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9958
Epoch 00042: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 382s 5ms/sample - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0203 - val_accuracy: 0.9960
Epoch 43/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9957
Epoch 00043: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 375s 5ms/sample - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0172 - val_accuracy: 0.9968
Epoch 44/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9962
Epoch 00044: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 377s 5ms/sample - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.0267 - val_accuracy: 0.9948
Epoch 45/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9960
Epoch 00045: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 381s 5ms/sample - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0157 - val_accuracy: 0.9971
Epoch 46/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9962
Epoch 00046: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 379s 5ms/sample - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.0190 - val_accuracy: 0.9957
Epoch 47/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9959
Epoch 00047: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 375s 5ms/sample - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0145 - val_accuracy: 0.9963
Epoch 48/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9964
Epoch 00048: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 378s 5ms/sample - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0243 - val_accuracy: 0.9950
Epoch 49/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9967
Epoch 00049: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 383s 5ms/sample - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0203 - val_accuracy: 0.9963
Epoch 50/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9962
Epoch 00050: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 376s 5ms/sample - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0140 - val_accuracy: 0.9974
Epoch 51/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9960
Epoch 00051: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 377s 5ms/sample - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0114 - val_accuracy: 0.9968
Epoch 52/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9964
Epoch 00052: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 376s 5ms/sample - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0157 - val_accuracy: 0.9965
Epoch 53/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9965
Epoch 00053: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 385s 5ms/sample - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0164 - val_accuracy: 0.9965
Epoch 54/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9972
Epoch 00054: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 378s 5ms/sample - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0213 - val_accuracy: 0.9964
Epoch 55/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9967
Epoch 00055: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 376s 5ms/sample - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0254 - val_accuracy: 0.9961
Epoch 56/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9967
Epoch 00056: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 382s 5ms/sample - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0238 - val_accuracy: 0.9969
Epoch 57/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9967
Epoch 00057: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 384s 5ms/sample - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0182 - val_accuracy: 0.9967
Epoch 58/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9968
Epoch 00058: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 382s 5ms/sample - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0152 - val_accuracy: 0.9965
Epoch 59/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9970
Epoch 00059: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 373s 4ms/sample - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0218 - val_accuracy: 0.9961
Epoch 60/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9970
Epoch 00060: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9955
Epoch 61/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9966
Epoch 00061: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0272 - val_accuracy: 0.9954
Epoch 62/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9970
Epoch 00062: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0219 - val_accuracy: 0.9959
Epoch 63/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9970
Epoch 00063: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0221 - val_accuracy: 0.9958
Epoch 64/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9970
Epoch 00064: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0300 - val_accuracy: 0.9942
Epoch 65/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9968
Epoch 00065: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0244 - val_accuracy: 0.9961
Epoch 66/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9971
Epoch 00066: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0260 - val_accuracy: 0.9950
Epoch 67/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9974
Epoch 00067: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0260 - val_accuracy: 0.9952
Epoch 68/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9971
Epoch 00068: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.0231 - val_accuracy: 0.9963
Epoch 69/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9970
Epoch 00069: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 312s 4ms/sample - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0287 - val_accuracy: 0.9935
Epoch 70/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9967
Epoch 00070: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0188 - val_accuracy: 0.9957
Epoch 71/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9976
Epoch 00071: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0182 - val_accuracy: 0.9960
Epoch 72/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9971
Epoch 00072: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 304s 4ms/sample - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0226 - val_accuracy: 0.9950
Epoch 73/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9971
Epoch 00073: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 312s 4ms/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0213 - val_accuracy: 0.9951
Epoch 74/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9970
Epoch 00074: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.0200 - val_accuracy: 0.9956
Epoch 75/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9974
Epoch 00075: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0270 - val_accuracy: 0.9936
Epoch 76/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9974
Epoch 00076: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0295 - val_accuracy: 0.9921
Epoch 77/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9981
Epoch 00077: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0279 - val_accuracy: 0.9944
Epoch 78/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9969
Epoch 00078: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0318 - val_accuracy: 0.9923
Epoch 79/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9972
Epoch 00079: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0283 - val_accuracy: 0.9938
Epoch 80/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9974
Epoch 00080: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0202 - val_accuracy: 0.9954
Epoch 81/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9971
Epoch 00081: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0284 - val_accuracy: 0.9933
Epoch 82/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9975
Epoch 00082: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0346 - val_accuracy: 0.9923
Epoch 83/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9973
Epoch 00083: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0180 - val_accuracy: 0.9968
Epoch 84/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9975
Epoch 00084: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.0227 - val_accuracy: 0.9960
Epoch 85/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9978
Epoch 00085: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0395 - val_accuracy: 0.9939
Epoch 86/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9975
Epoch 00086: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.0206 - val_accuracy: 0.9966
Epoch 87/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9974
Epoch 00087: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0286 - val_accuracy: 0.9936
Epoch 88/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9976
Epoch 00088: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0271 - val_accuracy: 0.9946
Epoch 89/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9973
Epoch 00089: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 311s 4ms/sample - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.0188 - val_accuracy: 0.9965
Epoch 90/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9977
Epoch 00090: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0256 - val_accuracy: 0.9951
Epoch 91/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9977
Epoch 00091: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.0234 - val_accuracy: 0.9954
Epoch 92/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9974
Epoch 00092: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0219 - val_accuracy: 0.9961
Epoch 93/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9973
Epoch 00093: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 305s 4ms/sample - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0227 - val_accuracy: 0.9958
Epoch 94/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9974
Epoch 00094: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0301 - val_accuracy: 0.9935
Epoch 95/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9977
Epoch 00095: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.0247 - val_accuracy: 0.9948
Epoch 96/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9975
Epoch 00096: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.0151 - val_accuracy: 0.9968
Epoch 97/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9976
Epoch 00097: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 308s 4ms/sample - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0242 - val_accuracy: 0.9954
Epoch 98/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9976
Epoch 00098: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 313s 4ms/sample - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0254 - val_accuracy: 0.9958
Epoch 99/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9973
Epoch 00099: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0222 - val_accuracy: 0.9953
Epoch 100/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9975
Epoch 00100: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0228 - val_accuracy: 0.9948
Epoch 101/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9977
Epoch 00101: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0287 - val_accuracy: 0.9940
Epoch 102/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9973
Epoch 00102: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 314s 4ms/sample - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0257 - val_accuracy: 0.9958
Epoch 103/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9978
Epoch 00103: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 307s 4ms/sample - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0216 - val_accuracy: 0.9958
Epoch 104/2000
83072/83089 [============================&gt;.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9974
Epoch 00104: val_accuracy did not improve from 0.99832
83089/83089 [==============================] - 306s 4ms/sample - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0205 - val_accuracy: 0.9954
Epoch 00104: early stopping
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_history</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
<span class="n">df_history</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;f-res/history_training.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_history</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>loss</th>
      <th>val_accuracy</th>
      <th>val_loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.947249</td>
      <td>0.150975</td>
      <td>0.996486</td>
      <td>0.007508</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.961680</td>
      <td>0.112626</td>
      <td>0.995475</td>
      <td>0.010928</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.965158</td>
      <td>0.100765</td>
      <td>0.996534</td>
      <td>0.007520</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.968841</td>
      <td>0.090637</td>
      <td>0.998315</td>
      <td>0.004767</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.971741</td>
      <td>0.081611</td>
      <td>0.995667</td>
      <td>0.010286</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;f-res/corpora_test_x.npy&#39;</span><span class="p">,</span><span class="n">corpora_test_x</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;f-res/target_test_y.npy&#39;</span><span class="p">,</span><span class="n">target_test_y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
 
<span class="n">epochs2</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs2</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span><span class="p">,</span><span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.fixes</span> <span class="kn">import</span> <span class="n">signature</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;f-res/best_model.hdf5&#39;</span>
<span class="n">criticality_network_load</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="c1">#&lt;----- The Model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="n">criticality_network_load</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">corpora_test_x</span><span class="p">,</span> <span class="n">target_test_y</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>11553/11553 [==============================] - 11s 942us/sample - loss: 0.0897 - accuracy: 0.9691
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 0.0896831521055043
Test accuracy: 0.9690989
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history_predict</span> <span class="o">=</span> <span class="n">criticality_network_load</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">corpora_test_x</span><span class="p">)</span>
<span class="n">history_predict</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[1.0000000e+00, 7.9988111e-10],
       [7.7354908e-03, 9.9226451e-01],
       [1.0000000e+00, 3.0692110e-10],
       ...,
       [4.3467302e-03, 9.9565327e-01],
       [1.0000000e+00, 1.5595104e-08],
       [9.1771345e-04, 9.9908233e-01]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inferred_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history_predict</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;AB&#39;</span><span class="p">))</span>
<span class="n">target_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">target_test_y</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;LN&#39;</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">target_data</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">inferred_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_true</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;L&#39;</span><span class="p">])</span>
<span class="n">y_score</span><span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">])</span>
<span class="n">average_precision</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average precision-recall score: </span><span class="si">{0:0.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">average_precision</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Average precision-recall score: 0.99
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;AUC: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">auc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC: 0.993
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

