{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "req-predict-[100embeds]-deep-alex-adapted-003.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrTo4BQ4OOGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#danaderp May6'19\n",
        "#Prediction For Main Issues Data Set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZMeVB6MOOGV",
        "colab_type": "code",
        "colab": {},
        "outputId": "025ad61d-6553-4ab2-905f-83ffc4ec5119"
      },
      "source": [
        "import csv\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from nltk.corpus import gutenberg\n",
        "from string import punctuation\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Limited tf.compat.v2.summary API due to missing TensorBoard installation\n",
            "Limited tf.summary API due to missing TensorBoard installation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NgvYcAdOOGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.display.max_colwidth = 200\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ChykyJeOOGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "englishStemmer=SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqRro97tOOGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Lambda\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTtHifCYOOGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize model structure\n",
        "#from IPython.display import SVG\n",
        "#from keras.utils.vis_utils import model_to_dot\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HZ1Qrr-OOGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datasets.read_data import Dynamic_Dataset,Processing_Dataset\n",
        "from vectorize_sentence import Embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyhXGpF1OOG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"datasets/augmented_dataset/\"\n",
        "process_unit = Processing_Dataset(path)\n",
        "ground_truth = process_unit.get_ground_truth()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNeKFhfBOOHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Dynamic_Dataset(ground_truth, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9lr53ZvOOHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test, train = process_unit.get_test_and_training(ground_truth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfiZCU5dOOHK",
        "colab_type": "code",
        "colab": {},
        "outputId": "73945d9b-9f8a-4164-ffda-11be311a50c6"
      },
      "source": [
        "print(len(test))\n",
        "print(len(train))\n",
        "print(test[0])\n",
        "print(train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11612\n",
            "104510\n",
            "('(1,0)', 'Heap-based buffer overflow in the yy_get_next_buffer function in Flex before 2.6.1 might allow context-dependent attackers to cause a denial of service or possibly execute arbitrary code via vectors involving num_to_read.')\n",
            "('(1,0)', 'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTf7PwOEOOHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train/Test split verification\n",
        "#for elem in test:\n",
        "#    print(elem[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj0OdxI3OOHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocesing Corpora\n",
        "embeddings = Embeddings()\n",
        "max_words = 5000 #<------- [Parameter]\n",
        "pre_corpora_train = [doc for doc in train if len(doc[1])< max_words]\n",
        "pre_corpora_test = [doc for doc in test if len(doc[1])< max_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn3ytaVyOOHW",
        "colab_type": "code",
        "colab": {},
        "outputId": "57d9348d-2168-4d6c-9cc1-b43a291d0f52"
      },
      "source": [
        "print(len(pre_corpora_train))\n",
        "print(len(pre_corpora_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103873\n",
            "11542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NudXNc8yOOHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_path = 'datasets/word_embeddings-embed_size_100-epochs_100.csv'\n",
        "embeddings_dict = embeddings.get_embeddings_dict(embed_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9xlJ8emOOHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpora_train = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_train]#vectorization Inputs\n",
        "corpora_test = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_test]#vectorization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gT0tz2uOOHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train = [[int(list(doc[0])[1]),int(list(doc[0])[3])] for doc in pre_corpora_train]#vectorization Output\n",
        "target_test = [[int(list(doc[0])[1]),int(list(doc[0])[3])]for doc in pre_corpora_test]#vectorization Output\n",
        "#target_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4rWBpFFOOHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_sentences_train = max([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
        "max_len_sentences_test = max([len(doc) for doc in corpora_test]) #<------- [Parameter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f10TVFuOOHy",
        "colab_type": "code",
        "colab": {},
        "outputId": "4cb77488-564e-40e8-b1dc-856df3c128b6"
      },
      "source": [
        "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
        "print(\"Max. Sentence # words:\",max_len_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max. Sentence # words: 618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ubgoNTpOOH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_len_sentences_train = min([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
        "min_len_sentences_test = min([len(doc) for doc in corpora_test]) #<------- [Parameter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjLpeniyOOIE",
        "colab_type": "code",
        "colab": {},
        "outputId": "94809ae3-4c2a-434a-9177-eed25805ba8e"
      },
      "source": [
        "min_len_sentences = max(min_len_sentences_train,min_len_sentences_test)\n",
        "print(\"Mix. Sentence # words:\",min_len_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mix. Sentence # words: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxgHMIIQOOIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = np.size(corpora_train[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDDNvoaIOOIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BaseLine Architecture <-------\n",
        "embeddigs_cols = embed_size\n",
        "input_sh = (max_len_sentences,embeddigs_cols,1)\n",
        "#Selecting filters? \n",
        "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
        "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
        "\n",
        "N_filters = 128 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
        "K = 2 # <-------- [HyperParameter] Number of Classess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzSDPXVuOOIc",
        "colab_type": "code",
        "colab": {},
        "outputId": "2f5b73e0-b6ea-445a-e108-d77bbd4f242b"
      },
      "source": [
        "input_sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(618, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df4xzLXpOOIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#baseline_model = Sequential()\n",
        "gram_input = Input(shape = input_sh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iMgsol2OOIw",
        "colab_type": "code",
        "colab": {},
        "outputId": "bac86290-387f-4730-92e3-4acc25bce978"
      },
      "source": [
        "# 1st Convolutional Layer Convolutional Layer (7-gram)\n",
        "conv_1_layer = Conv2D(filters=32, input_shape=input_sh, activation='relu', \n",
        "                      kernel_size=(7,embeddigs_cols), padding='valid')(gram_input)\n",
        "conv_1_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 612, 1, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxBoIEmyOOI3",
        "colab_type": "code",
        "colab": {},
        "outputId": "2fb65962-4bae-49a7-83c8-7f0a917da6d8"
      },
      "source": [
        "# Max Pooling \n",
        "max_1_pooling = MaxPooling2D(pool_size=((max_len_sentences-7+1),1), strides=None, padding='valid')(conv_1_layer)\n",
        "max_1_pooling.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 1, 1, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0aEHAOJOOI_",
        "colab_type": "code",
        "colab": {},
        "outputId": "20cc6e17-d1ab-4a45-ae25-d0f23b2479f3"
      },
      "source": [
        "# Fully Connected layer\n",
        "fully_connected_1_gram = Flatten()(max_1_pooling)\n",
        "fully_connected_1_gram.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f33p2t8-OOJI",
        "colab_type": "code",
        "colab": {},
        "outputId": "e5041e91-f7be-413a-c190-adfe00b73ae2"
      },
      "source": [
        "fully_connected_1_gram = Reshape((32, 1, 1))(fully_connected_1_gram)\n",
        "fully_connected_1_gram.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 32, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbXzVUdpOOJQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "a875f506-405a-4d3e-dba7-0635b10cd440"
      },
      "source": [
        "# 2nd Convolutional Layer (5-gram)\n",
        "conv_2_layer = Conv2D(filters=64, kernel_size=(5,1), activation='relu', \n",
        "                      padding='valid')(fully_connected_1_gram)\n",
        "conv_2_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 28, 1, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byd_5_ypOOJX",
        "colab_type": "code",
        "colab": {},
        "outputId": "5e57035c-0175-4b69-dda1-fe26c60131f4"
      },
      "source": [
        "max_2_pooling = MaxPooling2D(pool_size=((32-5+1),1), strides=None, padding='valid')(conv_2_layer)\n",
        "max_2_pooling.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 1, 1, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpQSB4LOOJg",
        "colab_type": "code",
        "colab": {},
        "outputId": "9bac622c-f46c-4a38-aee4-2abf7ff147fe"
      },
      "source": [
        "# Fully Connected layer\n",
        "fully_connected_2_gram = Flatten()(max_2_pooling)\n",
        "fully_connected_2_gram.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUZHYIBfOOJo",
        "colab_type": "code",
        "colab": {},
        "outputId": "0cd84d6f-ab2d-45c5-b673-5fd5c5d595ac"
      },
      "source": [
        "fully_connected_2_gram = Reshape((64, 1, 1))(fully_connected_2_gram)\n",
        "fully_connected_2_gram.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 64, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDa3R5iFOOJw",
        "colab_type": "code",
        "colab": {},
        "outputId": "768974d7-0308-4930-c59a-ad1f127a083c"
      },
      "source": [
        "# 3rd Convolutional Layer (3-gram)\n",
        "conv_3_layer =  Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
        "                      padding='valid')(fully_connected_2_gram)\n",
        "conv_3_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 62, 1, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2HC4Us1OOJ5",
        "colab_type": "code",
        "colab": {},
        "outputId": "801e4748-df36-46c0-cce1-730d4d320cd0"
      },
      "source": [
        "# 4th Convolutional Layer (3-gram)\n",
        "conv_4_layer = Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
        "                     padding='valid')(conv_3_layer)\n",
        "conv_4_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 60, 1, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuM6X6vCOOKC",
        "colab_type": "code",
        "colab": {},
        "outputId": "e66b0a3d-fc21-4d23-b61f-82cb0edd441d"
      },
      "source": [
        "# 5th Convolutional Layer (3-gram)\n",
        "conv_5_layer = Conv2D(filters=64, kernel_size=(3,1), activation='relu', \n",
        "                     padding='valid')(conv_4_layer)\n",
        "conv_5_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 58, 1, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC8kxxUzOOKJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d8f9de9-6817-45e2-bf9a-6a2f1fdbd382"
      },
      "source": [
        "# Max Pooling\n",
        "max_5_pooling = MaxPooling2D(pool_size=(58,1), strides=None, padding='valid')(conv_5_layer)\n",
        "max_5_pooling.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 1, 1, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZNXKauBOOKR",
        "colab_type": "code",
        "colab": {},
        "outputId": "21e004c7-483f-4faa-afe2-c8ba4c47e3db"
      },
      "source": [
        "# Fully Connected layer\n",
        "fully_connected = Flatten()(max_5_pooling)\n",
        "fully_connected.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD15DHThOOKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1st Fully Connected Layer\n",
        "deep_dense_1_layer = Dense(32, activation='relu')(fully_connected)\n",
        "deep_dense_1_layer = Dropout(0.2)(deep_dense_1_layer) # <-------- [HyperParameter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DNh4yMkOOKi",
        "colab_type": "code",
        "colab": {},
        "outputId": "cfeb2986-25f0-47e2-c48e-3910aa1e8681"
      },
      "source": [
        "deep_dense_1_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o49vu3PCOOKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2nd Fully Connected Layer\n",
        "deep_dense_2_layer = Dense(32, activation='relu')(deep_dense_1_layer)\n",
        "deep_dense_2_layer = Dropout(0.2)(deep_dense_2_layer) # <-------- [HyperParameter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkIpxSUsOOKy",
        "colab_type": "code",
        "colab": {},
        "outputId": "4d786c41-ac9f-4efe-a709-78c223a626af"
      },
      "source": [
        "deep_dense_2_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfan74NJOOK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3rd Fully Connected Layer\n",
        "deep_dense_3_layer = Dense(16, activation='relu')(deep_dense_2_layer)\n",
        "deep_dense_3_layer = Dropout(0.2)(deep_dense_3_layer) # <-------- [HyperParameter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MhOeye9OOLC",
        "colab_type": "code",
        "colab": {},
        "outputId": "062e590e-a033-42b0-e3ac-c9b3cdf137c8"
      },
      "source": [
        "deep_dense_3_layer.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO0kpUCNOOLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = Dense(K, activation='softmax')(deep_dense_3_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XffRe5yaOOLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criticality Model\n",
        "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBjj9O0JOOLb",
        "colab_type": "code",
        "colab": {},
        "outputId": "8efdb206-a556-4379-d8d3-7aafe7c35d0b"
      },
      "source": [
        "print(criticality_network.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 618, 100, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 612, 1, 32)        22432     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 32, 1, 1)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 1, 64)         384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 64, 1, 1)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 62, 1, 128)        512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 60, 1, 128)        49280     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 58, 1, 64)         24640     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 100,946\n",
            "Trainable params: 100,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svE0_XsvOOLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Seting up the Model\n",
        "criticality_network.compile(optimizer='adam',loss='binary_crossentropy',\n",
        "                                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR52foaDOOLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data set organization\n",
        "from tempfile import mkdtemp\n",
        "import os.path as path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux9iVckGOOLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Memoization \n",
        "file_corpora_train_x = path.join(mkdtemp(), 'alex-res-adapted-003_temp_corpora_train_x.dat') #Update per experiment\n",
        "file_corpora_test_x = path.join(mkdtemp(), 'alex-res-adapted-003_temp_corpora_test_x.dat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSrotxjxOOL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shaping\n",
        "shape_train_x = (len(corpora_train),max_len_sentences,embeddigs_cols,1)\n",
        "shape_test_x = (len(corpora_test),max_len_sentences,embeddigs_cols,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZCMo5bVOOMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data sets\n",
        "corpora_train_x = np.memmap(\n",
        "        filename = file_corpora_train_x, \n",
        "        dtype='float32', \n",
        "        mode='w+', \n",
        "        shape = shape_train_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r04D4SDaOOML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpora_test_x = np.memmap( #Test Corpora (for future evaluation)\n",
        "        filename = file_corpora_test_x, \n",
        "        dtype='float32', \n",
        "        mode='w+', \n",
        "        shape = shape_test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jehqIM6uOOMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train_y = np.array(target_train) #Train Target\n",
        "target_test_y = np.array(target_test) #Test Target (for future evaluation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCUNA9KyOOMl",
        "colab_type": "code",
        "colab": {},
        "outputId": "4acedad4-4d23-486d-f340-e31f3522aa8c"
      },
      "source": [
        "corpora_train_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103873, 618, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG1X3wXbOOMr",
        "colab_type": "code",
        "colab": {},
        "outputId": "28120b22-c98f-4e5e-c573-2d3be14d8e92"
      },
      "source": [
        "target_train_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103873, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlV-Ut11OOMy",
        "colab_type": "code",
        "colab": {},
        "outputId": "b435f45a-c5cf-4d8a-9c70-dee9cdc3f1fe"
      },
      "source": [
        "corpora_test_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11542, 618, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDYfwjxCOOM6",
        "colab_type": "code",
        "colab": {},
        "outputId": "c3c5944d-1ce0-4de1-ed8f-612fba8eac07"
      },
      "source": [
        "target_test_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11542, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-PRa_qYOONJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping Train Inputs\n",
        "for doc in range(len(corpora_train)):\n",
        "    #print(corpora_train[doc].shape[1])\n",
        "    for words_rows in range(corpora_train[doc].shape[0]):\n",
        "        embed_flatten = np.array(corpora_train[doc][words_rows]).flatten() #<--- Capture doc and word\n",
        "        for embedding_cols in range(embed_flatten.shape[0]):\n",
        "            corpora_train_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TelPsiM9OONS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping Test Inputs (for future evaluation)\n",
        "for doc in range(len(corpora_test)):\n",
        "    for words_rows in range(corpora_test[doc].shape[0]):\n",
        "        embed_flatten = np.array(corpora_test[doc][words_rows]).flatten() #<--- Capture doc and word\n",
        "        for embedding_cols in range(embed_flatten.shape[0]):\n",
        "            corpora_test_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8YpVF83OONa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CheckPoints\n",
        "#csv_logger = CSVLogger(system+'_training.log')\n",
        "filepath = \"alex-adapted-res-003/best_model.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8SRWN8kOONi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "callbacks_list = [es,mc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snE1ppqjOONo",
        "colab_type": "code",
        "colab": {},
        "outputId": "746f11e3-b6dd-4d28-97b9-216868e09a18"
      },
      "source": [
        "#Model Fitting\n",
        "history = criticality_network.fit(\n",
        "            x = corpora_train_x, \n",
        "            y = target_train_y,\n",
        "            #batch_size=64,\n",
        "            epochs=2000, #5 <------ Hyperparameter\n",
        "            validation_split = 0.2,\n",
        "            callbacks=callbacks_list\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 83098 samples, validate on 20775 samples\n",
            "Epoch 1/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9188\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99528, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 164s 2ms/sample - loss: 0.2264 - accuracy: 0.9188 - val_loss: 0.0146 - val_accuracy: 0.9953\n",
            "Epoch 2/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.9535\n",
            "Epoch 00002: val_accuracy did not improve from 0.99528\n",
            "83098/83098 [==============================] - 163s 2ms/sample - loss: 0.1386 - accuracy: 0.9535 - val_loss: 0.0358 - val_accuracy: 0.9884\n",
            "Epoch 3/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.9583\n",
            "Epoch 00003: val_accuracy improved from 0.99528 to 0.99721, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 162s 2ms/sample - loss: 0.1249 - accuracy: 0.9583 - val_loss: 0.0070 - val_accuracy: 0.9972\n",
            "Epoch 4/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9605\n",
            "Epoch 00004: val_accuracy improved from 0.99721 to 0.99755, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 162s 2ms/sample - loss: 0.1147 - accuracy: 0.9605 - val_loss: 0.0054 - val_accuracy: 0.9975\n",
            "Epoch 5/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9630\n",
            "Epoch 00005: val_accuracy did not improve from 0.99755\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.1060 - accuracy: 0.9631 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
            "Epoch 6/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9653\n",
            "Epoch 00006: val_accuracy did not improve from 0.99755\n",
            "83098/83098 [==============================] - 161s 2ms/sample - loss: 0.1013 - accuracy: 0.9653 - val_loss: 0.0128 - val_accuracy: 0.9957\n",
            "Epoch 7/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9667\n",
            "Epoch 00007: val_accuracy improved from 0.99755 to 0.99779, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "Epoch 8/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9681\n",
            "Epoch 00008: val_accuracy did not improve from 0.99779\n",
            "83098/83098 [==============================] - 164s 2ms/sample - loss: 0.0899 - accuracy: 0.9681 - val_loss: 0.0082 - val_accuracy: 0.9972\n",
            "Epoch 9/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9697\n",
            "Epoch 00009: val_accuracy did not improve from 0.99779\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0852 - accuracy: 0.9698 - val_loss: 0.0128 - val_accuracy: 0.9966\n",
            "Epoch 10/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9706\n",
            "Epoch 00010: val_accuracy did not improve from 0.99779\n",
            "83098/83098 [==============================] - 158s 2ms/sample - loss: 0.0808 - accuracy: 0.9706 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
            "Epoch 11/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9728\n",
            "Epoch 00011: val_accuracy improved from 0.99779 to 0.99783, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0757 - accuracy: 0.9728 - val_loss: 0.0060 - val_accuracy: 0.9978\n",
            "Epoch 12/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9739\n",
            "Epoch 00012: val_accuracy did not improve from 0.99783\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0712 - accuracy: 0.9739 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
            "Epoch 13/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9757\n",
            "Epoch 00013: val_accuracy did not improve from 0.99783\n",
            "83098/83098 [==============================] - 158s 2ms/sample - loss: 0.0684 - accuracy: 0.9757 - val_loss: 0.0076 - val_accuracy: 0.9973\n",
            "Epoch 14/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 0.9762\n",
            "Epoch 00014: val_accuracy improved from 0.99783 to 0.99793, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0639 - accuracy: 0.9762 - val_loss: 0.0059 - val_accuracy: 0.9979\n",
            "Epoch 15/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9771\n",
            "Epoch 00015: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0627 - accuracy: 0.9771 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "Epoch 16/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9782\n",
            "Epoch 00016: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 158s 2ms/sample - loss: 0.0590 - accuracy: 0.9782 - val_loss: 0.0090 - val_accuracy: 0.9976\n",
            "Epoch 17/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9798\n",
            "Epoch 00017: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 161s 2ms/sample - loss: 0.0562 - accuracy: 0.9798 - val_loss: 0.0078 - val_accuracy: 0.9974\n",
            "Epoch 18/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9801\n",
            "Epoch 00018: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
            "Epoch 19/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0516 - accuracy: 0.9811\n",
            "Epoch 00019: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
            "Epoch 20/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9816\n",
            "Epoch 00020: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 161s 2ms/sample - loss: 0.0501 - accuracy: 0.9816 - val_loss: 0.0101 - val_accuracy: 0.9969\n",
            "Epoch 21/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9822\n",
            "Epoch 00021: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0476 - accuracy: 0.9822 - val_loss: 0.0267 - val_accuracy: 0.9958\n",
            "Epoch 22/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9832\n",
            "Epoch 00022: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0100 - val_accuracy: 0.9971\n",
            "Epoch 23/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9842\n",
            "Epoch 00023: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 160s 2ms/sample - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
            "Epoch 24/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.98 - ETA: 0s - loss: 0.0432 - accuracy: 0.9851\n",
            "Epoch 00024: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0432 - accuracy: 0.9851 - val_loss: 0.0117 - val_accuracy: 0.9967\n",
            "Epoch 25/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9861\n",
            "Epoch 00025: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 158s 2ms/sample - loss: 0.0394 - accuracy: 0.9861 - val_loss: 0.0127 - val_accuracy: 0.9972\n",
            "Epoch 26/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9862\n",
            "Epoch 00026: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 159s 2ms/sample - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.0157 - val_accuracy: 0.9958\n",
            "Epoch 27/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9871\n",
            "Epoch 00027: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.0123 - val_accuracy: 0.9960\n",
            "Epoch 28/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9873\n",
            "Epoch 00028: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0372 - accuracy: 0.9872 - val_loss: 0.0119 - val_accuracy: 0.9965\n",
            "Epoch 29/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9871\n",
            "Epoch 00029: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0355 - accuracy: 0.9871 - val_loss: 0.0116 - val_accuracy: 0.9970\n",
            "Epoch 30/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9871\n",
            "Epoch 00030: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0360 - accuracy: 0.9871 - val_loss: 0.0105 - val_accuracy: 0.9974\n",
            "Epoch 31/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9878\n",
            "Epoch 00031: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.0181 - val_accuracy: 0.9963\n",
            "Epoch 32/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9883\n",
            "Epoch 00032: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.0157 - val_accuracy: 0.9961\n",
            "Epoch 33/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9893\n",
            "Epoch 00033: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.0167 - val_accuracy: 0.9957\n",
            "Epoch 34/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9889\n",
            "Epoch 00034: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 159s 2ms/sample - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.0161 - val_accuracy: 0.9971\n",
            "Epoch 35/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9894\n",
            "Epoch 00035: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 160s 2ms/sample - loss: 0.0296 - accuracy: 0.9894 - val_loss: 0.0155 - val_accuracy: 0.9974\n",
            "Epoch 36/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9899\n",
            "Epoch 00036: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.0165 - val_accuracy: 0.9967\n",
            "Epoch 37/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9900\n",
            "Epoch 00037: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.0189 - val_accuracy: 0.9967\n",
            "Epoch 38/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9902\n",
            "Epoch 00038: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.0202 - val_accuracy: 0.9954\n",
            "Epoch 39/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9903\n",
            "Epoch 00039: val_accuracy did not improve from 0.99793\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.0175 - val_accuracy: 0.9972\n",
            "Epoch 40/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9910\n",
            "Epoch 00040: val_accuracy improved from 0.99793 to 0.99798, saving model to alex-adapted-res-003/best_model.hdf5\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
            "Epoch 41/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9910\n",
            "Epoch 00041: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.0188 - val_accuracy: 0.9969\n",
            "Epoch 42/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9910\n",
            "Epoch 00042: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0249 - accuracy: 0.9910 - val_loss: 0.0186 - val_accuracy: 0.9969\n",
            "Epoch 43/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9916\n",
            "Epoch 00043: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 160s 2ms/sample - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0165 - val_accuracy: 0.9968\n",
            "Epoch 44/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9919\n",
            "Epoch 00044: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0176 - val_accuracy: 0.9968\n",
            "Epoch 45/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9923\n",
            "Epoch 00045: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0146 - val_accuracy: 0.9974\n",
            "Epoch 46/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9926\n",
            "Epoch 00046: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.0145 - val_accuracy: 0.9967\n",
            "Epoch 47/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9927\n",
            "Epoch 00047: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0239 - val_accuracy: 0.9962\n",
            "Epoch 48/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9919\n",
            "Epoch 00048: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 158s 2ms/sample - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.0171 - val_accuracy: 0.9964\n",
            "Epoch 49/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9925\n",
            "Epoch 00049: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.0188 - val_accuracy: 0.9959\n",
            "Epoch 50/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9926\n",
            "Epoch 00050: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.0201 - val_accuracy: 0.9966\n",
            "Epoch 51/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9932 ETA: 0s - loss: 0\n",
            "Epoch 00051: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.0175 - val_accuracy: 0.9965\n",
            "Epoch 52/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9926\n",
            "Epoch 00052: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 161s 2ms/sample - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.0155 - val_accuracy: 0.9971\n",
            "Epoch 53/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9937\n",
            "Epoch 00053: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0167 - val_accuracy: 0.9974\n",
            "Epoch 54/2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9934\n",
            "Epoch 00054: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.0281 - val_accuracy: 0.9960\n",
            "Epoch 55/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9937\n",
            "Epoch 00055: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 158s 2ms/sample - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0200 - val_accuracy: 0.9967\n",
            "Epoch 56/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9942\n",
            "Epoch 00056: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0194 - val_accuracy: 0.9962\n",
            "Epoch 57/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9935\n",
            "Epoch 00057: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0281 - val_accuracy: 0.9960\n",
            "Epoch 58/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9936\n",
            "Epoch 00058: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0222 - val_accuracy: 0.9969\n",
            "Epoch 59/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9937\n",
            "Epoch 00059: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0315 - val_accuracy: 0.9958\n",
            "Epoch 60/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9942\n",
            "Epoch 00060: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0240 - val_accuracy: 0.9962\n",
            "Epoch 61/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9942 ETA: \n",
            "Epoch 00061: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 161s 2ms/sample - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0213 - val_accuracy: 0.9972\n",
            "Epoch 62/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9947\n",
            "Epoch 00062: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 159s 2ms/sample - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9962\n",
            "Epoch 63/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9945\n",
            "Epoch 00063: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0294 - val_accuracy: 0.9960\n",
            "Epoch 64/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9939\n",
            "Epoch 00064: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.0160 - val_accuracy: 0.9973\n",
            "Epoch 65/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9939\n",
            "Epoch 00065: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.0140 - val_accuracy: 0.9977\n",
            "Epoch 66/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9950\n",
            "Epoch 00066: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0196 - val_accuracy: 0.9976\n",
            "Epoch 67/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9949\n",
            "Epoch 00067: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0160 - val_accuracy: 0.9969\n",
            "Epoch 68/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9947\n",
            "Epoch 00068: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0224 - val_accuracy: 0.9948\n",
            "Epoch 69/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9948\n",
            "Epoch 00069: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0192 - val_accuracy: 0.9967\n",
            "Epoch 70/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9952\n",
            "Epoch 00070: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 161s 2ms/sample - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0185 - val_accuracy: 0.9964\n",
            "Epoch 71/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9948\n",
            "Epoch 00071: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0274 - val_accuracy: 0.9953\n",
            "Epoch 72/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9951\n",
            "Epoch 00072: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.0239 - val_accuracy: 0.9961\n",
            "Epoch 73/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9951\n",
            "Epoch 00073: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0261 - val_accuracy: 0.9954\n",
            "Epoch 74/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9945\n",
            "Epoch 00074: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.0261 - val_accuracy: 0.9960\n",
            "Epoch 75/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9949\n",
            "Epoch 00075: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0188 - val_accuracy: 0.9970\n",
            "Epoch 76/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9949\n",
            "Epoch 00076: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0278 - val_accuracy: 0.9967\n",
            "Epoch 77/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9958\n",
            "Epoch 00077: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0191 - val_accuracy: 0.9967\n",
            "Epoch 78/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9952\n",
            "Epoch 00078: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0187 - val_accuracy: 0.9968\n",
            "Epoch 79/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9956\n",
            "Epoch 00079: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 162s 2ms/sample - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0278 - val_accuracy: 0.9961\n",
            "Epoch 80/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9960\n",
            "Epoch 00080: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 149s 2ms/sample - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0262 - val_accuracy: 0.9960\n",
            "Epoch 81/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9958\n",
            "Epoch 00081: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0187 - val_accuracy: 0.9970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 82/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9955\n",
            "Epoch 00082: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0198 - val_accuracy: 0.9971\n",
            "Epoch 83/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9959\n",
            "Epoch 00083: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0240 - val_accuracy: 0.9967\n",
            "Epoch 84/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953\n",
            "Epoch 00084: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0254 - val_accuracy: 0.9965\n",
            "Epoch 85/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9956\n",
            "Epoch 00085: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0243 - val_accuracy: 0.9967\n",
            "Epoch 86/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9960\n",
            "Epoch 00086: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0226 - val_accuracy: 0.9970\n",
            "Epoch 87/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9962\n",
            "Epoch 00087: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0249 - val_accuracy: 0.9963\n",
            "Epoch 88/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
            "Epoch 00088: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 159s 2ms/sample - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0206 - val_accuracy: 0.9971\n",
            "Epoch 89/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9957 ETA: 0s - loss: 0.0139 - accuracy\n",
            "Epoch 00089: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0201 - val_accuracy: 0.9971\n",
            "Epoch 90/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
            "Epoch 00090: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 149s 2ms/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0257 - val_accuracy: 0.9966\n",
            "Epoch 91/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9963\n",
            "Epoch 00091: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0298 - val_accuracy: 0.9960\n",
            "Epoch 92/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962\n",
            "Epoch 00092: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0219 - val_accuracy: 0.9961\n",
            "Epoch 93/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9962\n",
            "Epoch 00093: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 157s 2ms/sample - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0291 - val_accuracy: 0.9956\n",
            "Epoch 94/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9964\n",
            "Epoch 00094: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 156s 2ms/sample - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0252 - val_accuracy: 0.9968\n",
            "Epoch 95/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9959\n",
            "Epoch 00095: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 150s 2ms/sample - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0247 - val_accuracy: 0.9962\n",
            "Epoch 96/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9963\n",
            "Epoch 00096: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 154s 2ms/sample - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0221 - val_accuracy: 0.9972\n",
            "Epoch 97/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9963\n",
            "Epoch 00097: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 160s 2ms/sample - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0392 - val_accuracy: 0.9961\n",
            "Epoch 98/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
            "Epoch 00098: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0226 - val_accuracy: 0.9971\n",
            "Epoch 99/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9965\n",
            "Epoch 00099: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 159s 2ms/sample - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0277 - val_accuracy: 0.9964\n",
            "Epoch 100/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9959\n",
            "Epoch 00100: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 152s 2ms/sample - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0161 - val_accuracy: 0.9967\n",
            "Epoch 101/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9967\n",
            "Epoch 00101: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0232 - val_accuracy: 0.9973\n",
            "Epoch 102/2000\n",
            "83040/83098 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9970\n",
            "Epoch 00102: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 151s 2ms/sample - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9969\n",
            "Epoch 103/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9960\n",
            "Epoch 00103: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 155s 2ms/sample - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0386 - val_accuracy: 0.9954\n",
            "Epoch 104/2000\n",
            "83072/83098 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9967\n",
            "Epoch 00104: val_accuracy did not improve from 0.99798\n",
            "83098/83098 [==============================] - 153s 2ms/sample - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0304 - val_accuracy: 0.9956\n",
            "Epoch 00104: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FDMvNCNOONv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Training History\n",
        "df_history = pd.DataFrame.from_dict(history.history)\n",
        "df_history.to_csv('alex-adapted-res-003/history_training.csv', encoding='utf-8',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHF-BxnqOOQB",
        "colab_type": "code",
        "colab": {},
        "outputId": "9629433a-5ebc-4526-8c56-8a7c57412def"
      },
      "source": [
        "criticality_network.save(filepath)\n",
        "df_history.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.918819</td>\n",
              "      <td>0.226405</td>\n",
              "      <td>0.995283</td>\n",
              "      <td>0.014607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.953489</td>\n",
              "      <td>0.138605</td>\n",
              "      <td>0.988351</td>\n",
              "      <td>0.035808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.958266</td>\n",
              "      <td>0.124916</td>\n",
              "      <td>0.997208</td>\n",
              "      <td>0.006957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.960517</td>\n",
              "      <td>0.114711</td>\n",
              "      <td>0.997545</td>\n",
              "      <td>0.005447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.963056</td>\n",
              "      <td>0.106046</td>\n",
              "      <td>0.997304</td>\n",
              "      <td>0.006381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy      loss  val_accuracy  val_loss\n",
              "0  0.918819  0.226405      0.995283  0.014607\n",
              "1  0.953489  0.138605      0.988351  0.035808\n",
              "2  0.958266  0.124916      0.997208  0.006957\n",
              "3  0.960517  0.114711      0.997545  0.005447\n",
              "4  0.963056  0.106046      0.997304  0.006381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMFtQHeZOOQG",
        "colab_type": "code",
        "colab": {},
        "outputId": "18f12f8c-1196-4a0b-f87d-c6bc7206fbf7"
      },
      "source": [
        "#Saving Test Data\n",
        "np.save('alex-adapted-res-003/corpora_test_x.npy',corpora_test_x)\n",
        "np.save('alex-adapted-res-003/target_test_y.npy',target_test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "713295600 requested and 105657312 written",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-7152ad104ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Saving Test Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alex-adapted-res-003/corpora_test_x.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpora_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alex-adapted-res-003/target_test_y.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 536\u001b[0;31m                            pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    537\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             for chunk in numpy.nditer(\n",
            "\u001b[0;31mOSError\u001b[0m: 713295600 requested and 105657312 written"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8YlOsrKOOQL",
        "colab_type": "code",
        "colab": {},
        "outputId": "0c19a3b9-0ae5-432e-e83a-0d60c67ee856"
      },
      "source": [
        "#Evaluation\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epochs2 = range(len(acc))\n",
        " \n",
        "plt.plot(epochs2, acc, 'b', label='Training')\n",
        "plt.plot(epochs2, val_acc, 'r', label='Validation')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        " \n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs2, loss, 'b', label='Training')\n",
        "plt.plot(epochs2, val_loss, 'r', label='Validation')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7soAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f18d4688860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncM45F5X/B9ga40QlhOayAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f18d46384e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO4kzSzBOOQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score,precision_recall_curve\n",
        "from sklearn.utils.fixes import signature\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_qdEsiYOOQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNd3jEUjOOQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'e-res/best_model.hdf5'\n",
        "criticality_network_load = load_model(path) #<----- The Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwGoD68TOOQv",
        "colab_type": "code",
        "colab": {},
        "outputId": "77228891-4c6f-4ccd-e38a-5a6960cccbc9"
      },
      "source": [
        "score = criticality_network_load.evaluate(corpora_test_x, target_test_y, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11542/11542 [==============================] - 4s 354us/sample - loss: 0.0272 - accuracy: 0.9936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djYJOiblOOQ4",
        "colab_type": "code",
        "colab": {},
        "outputId": "15b8ca56-75ba-438a-a602-f0e793aebbcd"
      },
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.027205977374802823\n",
            "Test accuracy: 0.9935886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bu501HjOORC",
        "colab_type": "code",
        "colab": {},
        "outputId": "d1a2f44e-9140-4360-ee7f-a2716dddc6c4"
      },
      "source": [
        "history_predict = criticality_network_load.predict(x=corpora_test_x)\n",
        "history_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 2.3389704e-18],\n",
              "       [3.0761971e-10, 1.0000000e+00],\n",
              "       [1.0000000e+00, 4.9040064e-17],\n",
              "       ...,\n",
              "       [2.7979095e-07, 9.9999976e-01],\n",
              "       [1.0000000e+00, 6.4942689e-19],\n",
              "       [5.9354993e-10, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGw5SVLMOORJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inferred_data = pd.DataFrame(history_predict,columns=list('AB'))\n",
        "target_data = pd.DataFrame(target_test_y,columns=list('LN'))\n",
        "data = target_data.join(inferred_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjcAObtgOORO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = list(data['L'])\n",
        "y_score= list(data['A'])\n",
        "average_precision = average_precision_score(y_true, y_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpZbNu3NOORT",
        "colab_type": "code",
        "colab": {},
        "outputId": "cd547f7e-79a6-4122-8de6-8b514e67d42d"
      },
      "source": [
        "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average precision-recall score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3R61BgOORa",
        "colab_type": "code",
        "colab": {},
        "outputId": "82e6cf79-8de3-4490-d365-dc1d6f6c9a0d"
      },
      "source": [
        "#ROC Curve (all our samples are balanced)\n",
        "auc = roc_auc_score(y_true, y_score)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uql4nW4aOORg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}