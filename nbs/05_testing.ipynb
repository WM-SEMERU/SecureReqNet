{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.read_data import Dynamic_Dataset, Processing_Dataset\n",
    "from securereqnet.utils import Dynamic_Dataset, Processing_Dataset, Embeddings\n",
    "#all_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing for Processing_Dataset and Dynamic_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if ground truth text document is parsed correctly\n",
    "# method tested: get_ground_truth()\n",
    "def test_get_gt():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    expected = {'gitlab_79.txt':'(1,0)'}\n",
    "    assert(ground_truth == expected)\n",
    "\n",
    "#util\n",
    "test_get_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if an error is correctly raised if ground truth text\n",
    "# contains a duplicate\n",
    "# method tested: get_ground_truth()\n",
    "def test_get_gt_dup_error():\n",
    "    path = \"../test/test_gt_dup/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    try:\n",
    "        ground_truth = process_unit.get_ground_truth()\n",
    "        assert(False)\n",
    "    except KeyError:\n",
    "        assert(True)\n",
    "\n",
    "#util\n",
    "test_get_gt_dup_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are able to retrieve the data as labeled\n",
    "# method tested: __getitem__\n",
    "def test_dd_get():\n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    expected = ('(1,0)', b'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n",
    "    assert(dataset[0]==expected)\n",
    "    expected = ('(1,0)', b\"'This is a useful security improvement, that I recommend gets integrated into gitlab. It protects users, in the event that their passwords get stolen from other sites, etc. I found a good gem for this: http://rubydoc.info/github/mdp/rotp/master/frames, however, given that it appears Gitlab uses Devise for auth, we should probably use this plugin: https://github.com/wmlele/devise-otp\\n\\nI intend to submit a Merge Request for this, so I'll outline my design for the system here (in case anyone has feedback/wants to help):\\n\\n### OTP Strategy\\nI'm going with time-based (TOTP). Its requires no storage implications, per-user (other than a 32bit secret key). Time-based keys are very common, Google uses this strategy to protect GMail/Apps customers.\\n\\n### Database Augmentation\\n**NOTE:** Given the existence of devise-otp, this may no longer be necessary.\\n\\nI will add new table, with a foreign key reference to a `user_id` column,  and `totp_secret` column. The existence of a row implies that this feature is enabled for a user. This table could be enhanced further down the road to support other types of otp strategies, if need be. This would also make future data migrations, in the event of further enhancement, easier to manage.\\n\\n### UI Augmentation\\n#### User Account Settings\\nWe'll add a simple checkbox that a user must toggle to enable this feature. Once the checkbox is toggled, a modal will appear, displaying a QR code that the user will then scan with their mobile device, to start generating OTP codes. There will also be a box for the user to provide a newly generated OTP code to verify the service is working properly, for their account. Users will also need the ability to also reset the secret, in case they lose their phone etc.\\n\\n#### Admin Settings\\nWe'll need to allow admins to toggle if this feature is enabled, for a given user account. Assumed use case would be to contact an admin to disable OTP codes so you can log back in, re-enable it, and setup a new secret for yourself.\\n\\n#### Sign In\\nOnce the user has provided a proper username/password pair, if the flag is enabled, they will be redirected to a page that asks them to enter an OTP code, before they can proceed into the protected areas of the site.\\n\\n------\\n\\n**QUESTION: What would be the best course of action to manage the scenario where a user has lost their phone, and can no longer regenerate OTP codes to access their account? How can we let them back in to reset their OTP secret?** So far, my assumption is that the user would contact their gitlab administrators and they would disable OTP for them. However, one potential issue with this is that the attacker, who may have the user's password, may also have access to their e-mail. This would allow them to ask the administrator to disable OTP, and gain access to their data. Likely the verification protocol for admins should be org-specific, and not in scope of this work. Unsure how gitlab cloud staff wants to manage this, for their users. \\n\\n**UPDATE:** Its worth noting that using devise-otp provides a list of emergency HTOP recovery tokens that can be used, if we expose that functionality.\")\n",
    "    assert(dataset[1]==expected)\n",
    "#util\n",
    "test_dd_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if slicing works on Dynamic_Dataset\n",
    "def test_dd_slice():\n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    assert(len(dataset)==4)\n",
    "    sliced = dataset[1:]\n",
    "    assert(len(sliced)==3)\n",
    "    assert(sliced[0] == dataset[1])\n",
    "#util\n",
    "test_dd_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are only indexing items according to ground truth txt\n",
    "# method tested: __getitem__\n",
    "def test_dd_get_error():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    try:\n",
    "        dataset[1]\n",
    "        assert(False)\n",
    "    except IndexError as e:\n",
    "        assert(True)\n",
    "#util\n",
    "test_dd_get_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are able to retrieve just the id of the data at specific index\n",
    "# method tested: get_id()\n",
    "def test_dd_get_id():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    expected = 'gitlab_79.txt'\n",
    "    assert(dataset.get_id(0) == expected)\n",
    "#util\n",
    "test_dd_get_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are only indexing items according to ground_truth\n",
    "# method tested: get_id()\n",
    "def test_dd_get_id_error():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    try:\n",
    "        dataset.get_id(1)\n",
    "        assert(False)\n",
    "    except IndexError as e:\n",
    "        assert(True)\n",
    "#util\n",
    "test_dd_get_id_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests is length method is properly implemented\n",
    "# method tested: len()\n",
    "def test_dd_len():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    assert(len(dataset)==1)\n",
    "    \n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    \n",
    "    assert(len(dataset)==4)\n",
    "#util\n",
    "test_dd_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if iteration is properly implemented\n",
    "# method tested: __iter__\n",
    "def test_dd_iter():\n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    expected = []\n",
    "    # assuming that len and indexing are implemented correctly\n",
    "    for i in range(len(dataset)):\n",
    "        expected.append(dataset[i])\n",
    "    actual = []\n",
    "    for data in dataset:\n",
    "        actual.append(data)\n",
    "    assert(expected == actual)\n",
    "#util\n",
    "test_dd_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if Dyanmic_Dataset is immutable\n",
    "# method tested: __set_item__\n",
    "def test_dd_set_item_error():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    try:\n",
    "        dataset[0] = \"asdf\"\n",
    "        assert(False)\n",
    "    except ValueError as e:\n",
    "        assert(True)\n",
    "#util\n",
    "test_dd_set_item_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if an error is correctly raised if malformed\n",
    "# data is detected in document\n",
    "# method tested: get_test_and_training\n",
    "def test_get_test_training_value_error():\n",
    "    path = \"../test/test_gt_bad/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    try:\n",
    "        ground_truth = process_unit.get_ground_truth()\n",
    "        process_unit.get_test_and_training(ground_truth)\n",
    "        assert(False)\n",
    "    except ValueError:\n",
    "        assert(True)\n",
    "#util\n",
    "test_get_test_training_value_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we can get contents of an issue\n",
    "# method tested: get_issue(filename)\n",
    "\n",
    "def test_get_issue_bad():\n",
    "    path = \"../test/test_gt_bad/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    try:\n",
    "        process_unit.get_issue(\"test\")\n",
    "        assert(False)\n",
    "    except FileNotFoundError:\n",
    "        assert(True)\n",
    "#util\n",
    "test_get_issue_bad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we can get contents of an issue\n",
    "# method tested: get_issue(filename)\n",
    "\n",
    "def test_get_issue():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    try:\n",
    "        process_unit.get_issue(\"full_ground_truth.txt\")\n",
    "        assert(True)\n",
    "    except FileNotFoundError:\n",
    "        assert(False)\n",
    "#util\n",
    "test_get_issue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if an error is correctly raised if malformed\n",
    "# data is detected in document\n",
    "# method tested: get_test_and_training\n",
    "def test_get_train_test_split():\n",
    "    path = \"../data/augmented_dataset/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    ratio = 0.1\n",
    "    train, test = process_unit.get_test_and_training(ground_truth, test_ratio = ratio, isZip = True)\n",
    "    actual_ratio = len(train)/(len(test)+len(train))\n",
    "\n",
    "    assert(actual_ratio>=ratio-.02 and actual_ratio<=ratio+0.02)\n",
    "    ratio = 0.5\n",
    "    train, test = process_unit.get_test_and_training(ground_truth, test_ratio = ratio, isZip = True)\n",
    "    actual_ratio = len(train)/(len(test)+len(train))\n",
    "\n",
    "    assert(actual_ratio>=ratio-.02 and actual_ratio<=ratio+0.02)\n",
    "#util\n",
    "test_get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test vectorizing \n",
    "import numpy as np\n",
    "\n",
    "# set up for testing\n",
    "embeddings = Embeddings()\n",
    "embed_path = '../test/test_embeddings/test_embeddings.csv'\n",
    "embeddings_dict = embeddings.get_embeddings_dict(embed_path)\n",
    "\n",
    "user_vector = [-4.6527834,\n",
    "                1.1271917,\n",
    "                -5.386773,\n",
    "                -2.9345105,\n",
    "                12.707992,\n",
    "                -3.5409136,\n",
    "                2.0961823,\n",
    "                -0.42728585,\n",
    "                -1.3112166,\n",
    "                0.34084892,\n",
    "                -6.431007,\n",
    "                0.106831096,\n",
    "                1.8986382,\n",
    "                -2.3929365,\n",
    "                2.5768406,\n",
    "                2.744601,\n",
    "                -1.8507555,\n",
    "                0.09059698,\n",
    "                -0.2394328,\n",
    "                0.66318494]\n",
    "\n",
    "use_vector = [-1.38487,\n",
    "                4.447382,\n",
    "                -0.97873485,\n",
    "                2.3377173,\n",
    "                4.7804713,\n",
    "                -2.8270018,\n",
    "                0.26988912,\n",
    "                2.7355337,\n",
    "                0.5191395,\n",
    "                1.0389539,\n",
    "                -1.2465893,\n",
    "                0.13766454,\n",
    "                1.3388132,\n",
    "                -3.7388134,\n",
    "                1.8178437,\n",
    "                -1.1611614,\n",
    "                3.4868627,\n",
    "                -0.4555853,\n",
    "                1.4885712,\n",
    "                20.297823]\n",
    "\n",
    "version_vector = [-7.0424953,\n",
    "                7.978198,\n",
    "                -1.5168871,\n",
    "                -6.562944,\n",
    "                19.298594,\n",
    "                1.7695183,\n",
    "                2.5408025,\n",
    "                -3.7058382,\n",
    "                -0.82634467,\n",
    "                -4.577317,\n",
    "                -2.4452372,\n",
    "                -5.119848,\n",
    "                1.5269793,\n",
    "                1.1844287,\n",
    "                0.2566476,\n",
    "                -4.926136,\n",
    "                -3.5850575,\n",
    "                -3.8257978,\n",
    "                2.7975578,\n",
    "                6.4273405]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can map the word user to its vector from the dictionary\n",
    "def test_vectorize_one_word_user():\n",
    "    sentence = \"user\"\n",
    "    corresponding_vector = np.array([user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_one_word_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can clean the word users then map to user vector from the dictionary\n",
    "def test_vectorize_one_word_users_cleaned_to_user():\n",
    "    sentence = \"users\"\n",
    "    corresponding_vector = np.array([user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_one_word_users_cleaned_to_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can clean the word use then map to use vector from the dictionary\n",
    "def test_vectorize_one_word_use():\n",
    "    sentence = \"use\"\n",
    "    corresponding_vector = np.array([use_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_one_word_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can clean the word uses then map to use vector from the dictionary\n",
    "def test_vectorize_one_word_uses_cleaned_to_use():\n",
    "    sentence = \"uses\"\n",
    "    corresponding_vector = np.array([use_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_one_word_uses_cleaned_to_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can clean the word used then map to use vector from the dictionary\n",
    "def test_vectorize_one_word_used_cleaned_to_use():\n",
    "    sentence = \"used\"\n",
    "    corresponding_vector = np.array([use_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_one_word_used_cleaned_to_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can map to version vector from the dictionary\n",
    "def test_vectorize_one_word_version():\n",
    "    sentence = \"version\"\n",
    "    corresponding_vector = np.array([version_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_one_word_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can clean the word versions then map to version vector from the dictionary\n",
    "def test_vectorize_one_word_versions_cleaned_to_version():\n",
    "    sentence = \"versions\"\n",
    "    corresponding_vector = np.array([version_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_one_word_versions_cleaned_to_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests if we can clean the word versioned then map to version vector from the dictionary\n",
    "def test_vectorize_one_word_versioned_cleaned_to_version():\n",
    "    sentence = \"versioned\"\n",
    "    corresponding_vector = np.array([version_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_one_word_versioned_cleaned_to_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test empty case for vectorization - should be an empty vector\n",
    "def test_vectorize_no_words():\n",
    "    sentence = \"\"\n",
    "    corresponding_vector = np.array([])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_no_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test vectorizing non dictionary words - should return empty vector\n",
    "def test_vectorize_non_dict_words():\n",
    "    sentence = \"donuts are tasty\"\n",
    "    corresponding_vector = np.array([])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_non_dict_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test vectorizing on two words, vector will have last matched word in sentence first\n",
    "def test_vectorize_two_words_clean():\n",
    "    sentence = \"user use\"\n",
    "    corresponding_vector = np.array([use_vector, user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_two_words_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test vectorizing on three words\n",
    "def test_vectorize_three_words_clean():\n",
    "    sentence = \"user use version\"\n",
    "    corresponding_vector = np.array([version_vector, use_vector, user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_three_words_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test vectorizing on two words mixed with words not in our mapping\n",
    "def test_vectorize_two_words_mixed():\n",
    "    sentence = \"user is provided this new version of the product to do things\"\n",
    "    corresponding_vector = np.array([version_vector, user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_vectorize_two_words_mixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test vectorizing on two words mixed with words not in our mapping and cleaning users to use\n",
    "def test_vectorize_two_words_mixed_with_cleaning():\n",
    "    sentence = \"users will use our product to do things\"\n",
    "    corresponding_vector = np.array([use_vector, user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_two_words_mixed_with_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test duplicated words\n",
    "def test_vectorize_one_word_duplicated_three_times():\n",
    "    sentence = \"users user user\"\n",
    "    corresponding_vector = np.array([user_vector, user_vector, user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "\n",
    "test_vectorize_one_word_duplicated_three_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three words, users will clean to user and map to user\n",
    "def test_three_words_mixed_with_cleaning():\n",
    "    sentence = \"users will use this version of our product\"\n",
    "    corresponding_vector = np.array([version_vector, use_vector, user_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_three_words_mixed_with_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiple words, with duplicate words, cleaning, and non dictionary words\n",
    "def test_multi_words_with_dupes_with_cleaning():\n",
    "    sentence = \"Our product features several versions that the user can choose from. \\\n",
    "                Depending on which version they choose to use, the user will receive different features.\"\n",
    "    corresponding_vector = np.array([user_vector, use_vector, version_vector, user_vector, version_vector])\n",
    "    vectorized = embeddings.vectorize(sentence, embeddings_dict)\n",
    "    assert np.allclose(vectorized, corresponding_vector)\n",
    "    \n",
    "test_multi_words_with_dupes_with_cleaning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
