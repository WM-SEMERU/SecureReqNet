API server crash on malformed PATCH request


Is this a BUG REPORT
Kubernetes version (use kubectl version):
kubectl version
Client Version: version.Info{Major:"1", Minor:"5", GitVersion:"v1.5.1", GitCommit:"82450d03cb057bab0950214ef122b67c83fb11df", GitTreeState:"clean", BuildDate:"2016-12-14T00:57:05Z", GoVersion:"go1.7.4", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"", Minor:"", GitVersion:"v1.6.0-alpha.0", GitCommit:"42fe4ab0270e44c750d77c682e2fcab394aeb392", GitTreeState:"dirty", BuildDate:"1970-01-01T00:00:00Z", GoVersion:"go1.7", Compiler:"gc", Platform:"linux/amd64"}

Environment:

Cloud provider or hardware configuration: minikube (also happens in clusters on AWS running 1.5.2).
OS (e.g. from /etc/os-release):
Kernel (e.g. uname -a):
Install tools:
Others:

What happened:
API server panics on malformed PATCH request.
Observed a panic: "slice bounds out of range" (runtime error: slice bounds out of range)
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/util/runtime/runtime.go:70
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/util/runtime/runtime.go:63
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/util/runtime/runtime.go:49
/usr/local/go/src/runtime/asm_amd64.s:479
/usr/local/go/src/runtime/panic.go:458
/usr/local/go/src/runtime/panic.go:34
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/evanphx/json-patch/patch.go:265
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/evanphx/json-patch/patch.go:415
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/evanphx/json-patch/patch.go:556
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/evanphx/json-patch/patch.go:537
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:1089
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:566
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/api/rest/update.go:177
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/registry/generic/registry/store.go:365
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/storage/etcd/etcd_helper.go:465
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/storage/cacher.go:475
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/registry/generic/registry/store.go:441
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:645
/usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:960
/usr/local/go/src/runtime/asm_amd64.s:2086
E0120 14:35:19.924157    1882 apiserver.go:201] recover from panic situation: - runtime error: slice bounds out of range
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/emicklei/go-restful/container.go:206
    /usr/local/go/src/runtime/asm_amd64.s:479
    /usr/local/go/src/runtime/panic.go:458
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:976
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:651
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/resthandler.go:503
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/metrics/metrics.go:101
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/emicklei/go-restful/container.go:272
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/github.com/emicklei/go-restful/container.go:120
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/go/src/net/http/server.go:2022
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/filters/authorization.go:44
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/filters/impersonation.go:44
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/auth/handlers/handlers.go:73
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/api/requestcontext.go:107
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/genericapiserver/filters/panics.go:75
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/apiserver/filters/requestinfo.go:45
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/api/requestcontext.go:107
    /usr/local/go/src/net/http/server.go:1726
    /usr/local/google/home/mrick/go/src/k8s.io/minikube/_gopath/src/k8s.io/minikube/vendor/k8s.io/kubernetes/pkg/genericapiserver/filters/timeout.go:78
    /usr/local/go/src/runtime/asm_amd64.s:2086

What you expected to happen:
It should respond with 400 instead of panicking.
How to reproduce it (as minimally and precisely as possible):
# create minikube cluster
$ minikube start --kubernetes-version v1.6.0-alpha.0
# create a pod
kubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 --port=8080
# get the pod name and make a malformed PATCH request.
$ curl -X PATCH -H "Content-Type: application/json-patch+json" \
  https://192.168.99.100:8443/api/v1/namespaces/default/pods/hello-minikube-3015430129-rexoi \
  -d '[{"op":"add","pointer":"/metadata/labels/foo","value":"hi"}]' -k
Anything else do we need to know:
