{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Dynamic_Dataset\" class=\"doc_header\"><code>class</code> <code>Dynamic_Dataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Dynamic_Dataset</code>(**`ground_truth`**, **`path`**, **`isZip`**)\n",
       "\n",
       "This class efficiently 'stores' a dataset. Only a list of filenames and\n",
       "mappings to their ground truth values are stored in memory. The file\n",
       "contents are only brought into memory when requested.\n",
       "\n",
       "This class supports indexing, slicing, and iteration.\n",
       "\n",
       "A user can treat an instance of this class exactly as they would a list.\n",
       "Indexing an instance of this class will return a tuple consisting of\n",
       "the ground truth value and the file content of the filename at that index.\n",
       "\n",
       "A user can request the filename at an index with get_id(index)\n",
       "\n",
       "Example:\n",
       "\n",
       "        dataset = Dynamic_Dataset(ground_truth)\n",
       "\n",
       "        print(dataset.get_id(0))\n",
       "                -> gitlab_79.txt\n",
       "\n",
       "        print(dataset[0])\n",
       "                -> ('(1,0)', 'The currently used Rails version, in the stable ...\n",
       "\n",
       "        for x in dataset[2:4]:\n",
       "                print(x)\n",
       "                        -> ('(1,0)', \"'In my attempt to add 2 factor authentication ...\n",
       "                        -> ('(1,0)', 'We just had an admin accidentally push to a ..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from utils.read_data import Dynamic_Dataset, Processing_Dataset\n",
    "%run 09_utils.ipynb\n",
    "from utils.vectorize_sentence import Embeddings\n",
    "#all_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing for Processing_Dataset and Dynamic_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if ground truth text document is parsed correctly\n",
    "# method tested: get_ground_truth()\n",
    "def test_get_gt():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    expected = {'gitlab_79.txt':'(1,0)'}\n",
    "    assert(ground_truth == expected)\n",
    "\n",
    "#util\n",
    "test_get_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if an error is correctly raised if ground truth text\n",
    "# contains a duplicate\n",
    "# method tested: get_ground_truth()\n",
    "def test_get_gt_dup_error():\n",
    "    path = \"../test/test_gt_dup/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    try:\n",
    "        ground_truth = process_unit.get_ground_truth()\n",
    "        assert(False)\n",
    "    except KeyError:\n",
    "        assert(True)\n",
    "\n",
    "#util\n",
    "test_get_gt_dup_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are able to retrieve the data as labeled\n",
    "# method tested: __getitem__\n",
    "def test_dd_get():\n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    expected = ('(1,0)', b'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n",
    "    assert(dataset[0]==expected)\n",
    "    expected = ('(1,0)', b\"'This is a useful security improvement, that I recommend gets integrated into gitlab. It protects users, in the event that their passwords get stolen from other sites, etc. I found a good gem for this: http://rubydoc.info/github/mdp/rotp/master/frames, however, given that it appears Gitlab uses Devise for auth, we should probably use this plugin: https://github.com/wmlele/devise-otp\\n\\nI intend to submit a Merge Request for this, so I'll outline my design for the system here (in case anyone has feedback/wants to help):\\n\\n### OTP Strategy\\nI'm going with time-based (TOTP). Its requires no storage implications, per-user (other than a 32bit secret key). Time-based keys are very common, Google uses this strategy to protect GMail/Apps customers.\\n\\n### Database Augmentation\\n**NOTE:** Given the existence of devise-otp, this may no longer be necessary.\\n\\nI will add new table, with a foreign key reference to a `user_id` column,  and `totp_secret` column. The existence of a row implies that this feature is enabled for a user. This table could be enhanced further down the road to support other types of otp strategies, if need be. This would also make future data migrations, in the event of further enhancement, easier to manage.\\n\\n### UI Augmentation\\n#### User Account Settings\\nWe'll add a simple checkbox that a user must toggle to enable this feature. Once the checkbox is toggled, a modal will appear, displaying a QR code that the user will then scan with their mobile device, to start generating OTP codes. There will also be a box for the user to provide a newly generated OTP code to verify the service is working properly, for their account. Users will also need the ability to also reset the secret, in case they lose their phone etc.\\n\\n#### Admin Settings\\nWe'll need to allow admins to toggle if this feature is enabled, for a given user account. Assumed use case would be to contact an admin to disable OTP codes so you can log back in, re-enable it, and setup a new secret for yourself.\\n\\n#### Sign In\\nOnce the user has provided a proper username/password pair, if the flag is enabled, they will be redirected to a page that asks them to enter an OTP code, before they can proceed into the protected areas of the site.\\n\\n------\\n\\n**QUESTION: What would be the best course of action to manage the scenario where a user has lost their phone, and can no longer regenerate OTP codes to access their account? How can we let them back in to reset their OTP secret?** So far, my assumption is that the user would contact their gitlab administrators and they would disable OTP for them. However, one potential issue with this is that the attacker, who may have the user's password, may also have access to their e-mail. This would allow them to ask the administrator to disable OTP, and gain access to their data. Likely the verification protocol for admins should be org-specific, and not in scope of this work. Unsure how gitlab cloud staff wants to manage this, for their users. \\n\\n**UPDATE:** Its worth noting that using devise-otp provides a list of emergency HTOP recovery tokens that can be used, if we expose that functionality.\")\n",
    "    assert(dataset[1]==expected)\n",
    "#util\n",
    "test_dd_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'path' and 'isZip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-87fa379cc7c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtest_dd_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-87fa379cc7c8>\u001b[0m in \u001b[0;36mtest_dd_slice\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDynamic_Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"../test/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msliced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Fall2020\\SWE\\SecureReqNet\\nbs\\utils\\read_data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     74\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                                 \u001b[0mnew_gt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__ground_truth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mDynamic_Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_gt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                         \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'path' and 'isZip'"
     ]
    }
   ],
   "source": [
    "# Tests if slicing works on Dynamic_Dataset\n",
    "def test_dd_slice():\n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    assert(len(dataset)==3)\n",
    "    sliced = dataset[1:]\n",
    "    assert(len(sliced)==2)\n",
    "    assert(sliced[0] == dataset[0])\n",
    "#util\n",
    "test_dd_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are only indexing items according to ground truth txt\n",
    "# method tested: __getitem__\n",
    "def test_dd_get_error():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    try:\n",
    "        dataset[1]\n",
    "        assert(False)\n",
    "    except IndexError as e:\n",
    "        assert(True)\n",
    "#util\n",
    "test_dd_get_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are able to retrieve just the id of the data at specific index\n",
    "# method tested: get_id()\n",
    "def test_dd_get_id():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    expected = 'gitlab_79.txt'\n",
    "    assert(dataset.get_id(0) == expected)\n",
    "#util\n",
    "test_dd_get_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if we are only indexing items according to ground_truth\n",
    "# method tested: get_id()\n",
    "def test_dd_get_id_error():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    try:\n",
    "        dataset.get_id(1)\n",
    "        assert(False)\n",
    "    except IndexError as e:\n",
    "        assert(True)\n",
    "#util\n",
    "test_dd_get_id_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests is length method is properly implemented\n",
    "# method tested: len()\n",
    "def test_dd_len():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    assert(len(dataset)==1)\n",
    "    \n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    \n",
    "    assert(len(dataset)==3)\n",
    "#util\n",
    "test_dd_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if iteration is properly implemented\n",
    "# method tested: __iter__\n",
    "def test_dd_iter():\n",
    "    path = \"../test/test_gt_multiple/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    expected = []\n",
    "    # assuming that len and indexing are implemented correctly\n",
    "    for i in range(len(dataset)):\n",
    "        expected.append(dataset[i])\n",
    "    actual = []\n",
    "    for data in dataset:\n",
    "        actual.append(data)\n",
    "    assert(expected == actual)\n",
    "#util\n",
    "test_dd_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if Dyanmic_Dataset is immutable\n",
    "# method tested: __set_item__\n",
    "def test_dd_set_item_error():\n",
    "    path = \"../test/test_gt_good/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    dataset = Dynamic_Dataset(ground_truth, \"../test/\", True)\n",
    "    try:\n",
    "        dataset[0] = \"asdf\"\n",
    "        assert(False)\n",
    "    except ValueError as e:\n",
    "        assert(True)\n",
    "#util\n",
    "test_dd_set_item_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests if an error is correctly raised if malformed\n",
    "# data is detected in document\n",
    "# method tested: get_test_and_training\n",
    "def test_get_test_training_value_error():\n",
    "    path = \"../test/test_gt_bad/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    try:\n",
    "        ground_truth = process_unit.get_ground_truth()\n",
    "        process_unit.get_test_and_training(ground_truth)\n",
    "        assert(False)\n",
    "    except ValueError:\n",
    "        assert(True)\n",
    "#util\n",
    "test_get_test_training_value_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'combined_dataset/issues/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-a17f8260303d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprocess_unit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcessing_Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprocess_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_issue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtest_get_issue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-a17f8260303d>\u001b[0m in \u001b[0;36mtest_get_issue\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../test/test_gt_bad/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprocess_unit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcessing_Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprocess_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_issue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtest_get_issue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Fall2020\\SWE\\SecureReqNet\\nbs\\utils\\read_data.py\u001b[0m in \u001b[0;36mget_issue\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_issue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'combined_dataset/issues/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'combined_dataset/issues/test'"
     ]
    }
   ],
   "source": [
    "# Tests if we can get contents of an issue\n",
    "# method tested: get_issue(filename)\n",
    "\n",
    "## TODO remake once refactoring team fixes this method\n",
    "def test_get_issue():\n",
    "    path = \"../test/test_gt_bad/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    process_unit.get_issue(\"test\")\n",
    "#util\n",
    "test_get_issue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11110898478614487\n",
      "0.9999655540628983\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-8aefd99b785c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_ratio\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m.02\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mactual_ratio\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtest_get_train_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-8aefd99b785c>\u001b[0m in \u001b[0;36mtest_get_train_test_split\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mactual_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_ratio\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m.02\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mactual_ratio\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtest_get_train_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tests if an error is correctly raised if malformed\n",
    "# data is detected in document\n",
    "# method tested: get_test_and_training\n",
    "def test_get_train_test_split():\n",
    "    path = \"../data/augmented_dataset/\"\n",
    "    process_unit = Processing_Dataset(path)\n",
    "    ground_truth = process_unit.get_ground_truth()\n",
    "    ratio = 0.1\n",
    "    train, test = process_unit.get_test_and_training(ground_truth, test_ratio = ratio, isZip = True)\n",
    "    actual_ratio = len(train)/len(test)\n",
    "\n",
    "    assert(actual_ratio>=ratio-.02 and actual_ratio<=ratio+0.2)\n",
    "    ratio = 0.5\n",
    "    train, test = process_unit.get_test_and_training(ground_truth, test_ratio = ratio, isZip = True)\n",
    "    actual_ratio = len(train)/len(test)\n",
    "\n",
    "    assert(actual_ratio>=ratio-.02 and actual_ratio<=ratio+0.2)\n",
    "#util\n",
    "test_get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
