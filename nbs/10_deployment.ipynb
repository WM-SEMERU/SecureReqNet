{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *\n",
    "# default_exp deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import flask\n",
    "from flask import Flask\n",
    "import requests\n",
    "import json\n",
    "from flask import request, jsonify\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "from securereqnet.preprocessing import vectorize_sentences\n",
    "import numpy as np\n",
    "from waitress import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment ðŸš€\n",
    "This endpoint is designed to work in tandem with TFX serving to present the model in an easily consumable REST API where users pass in sentences and receive True/False with respect to whether the issue is security related or not.  The endpoint requires a port and hostname to be set up on, and is ready to deploy using waitress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# takes a list of sentences, vectorizes them and sends the result to the uri of the TFX serving endpoint\n",
    "def __get_predictions(sentences, endpoint_uri):\n",
    "    payload = {\n",
    "            \"instances\": vectorize_sentences(sentences).tolist()\n",
    "        }\n",
    "        \n",
    "    r = requests.post(endpoint_uri, json = payload)\n",
    "    model_preds = json.loads(r.content.decode('utf-8'))\n",
    "\n",
    "    \n",
    "    preds = []\n",
    "\n",
    "    # decode predictions\n",
    "    for pred in model_preds['predictions']:\n",
    "        preds.append(__decode(pred))\n",
    "\n",
    "    output = {\n",
    "        \"predictions\": preds\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# decodes the tensor output from the TFX endpoint to True/False values\n",
    "def __decode(input):\n",
    "    return float(input[0])>float(input[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask Backend\n",
    "Defines a factory for our app.  Serving is packaged nicely inside a serve method, and is ready to deploy with waitress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factory method for our application.  It returns an instance of our Flask application.  Default configuration has the TFX serving predict API on http://localhost:8503/v1/models/alpha:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def create_app(test_config=None):\n",
    "    \"\"\"\n",
    "    Returns a Flask web application with the default configuration pinging a TFX serving instance\n",
    "    on http://localhost:8503/v1/models/alpha:predict\n",
    "    \"\"\"\n",
    "    app = Flask(__name__, instance_relative_config=True)\n",
    "    app.config.from_mapping(\n",
    "        TFX_ENDPOINT='http://localhost:8503/v1/models/alpha:predict'\n",
    "    )\n",
    "\n",
    "    if test_config:\n",
    "        app.config.from_mapping(test_config)\n",
    "\n",
    "    # default route, we probably will get rid of this\n",
    "    @app.route('/', methods=['GET'])\n",
    "    def home():\n",
    "        return '<h1>SecureReqNet</h1><p>Flask backend</p>'\n",
    "\n",
    "    # alpha model\n",
    "    @app.route('/models/alpha', methods=['POST'])\n",
    "    def alpha():\n",
    "        content = request.get_json()\n",
    "        sentences = content['instances']\n",
    "        return __get_predictions(sentences, app.config['TFX_ENDPOINT'])\n",
    "\n",
    "    return app\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using waitress, starts up a production server on the input host and port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def serve(host, port):\n",
    "    \"\"\"\n",
    "    Serves a waitress production server on the given host and post\n",
    "    \"\"\"\n",
    "    serve(create_app(), host = host, port = port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_deployment\n",
    "# The following are test cases for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest.mock\n",
    "from unittest import mock\n",
    "from unittest.mock import patch\n",
    "from unittest.mock import Mock\n",
    "from securereqnet.deployment import create_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test client\n",
    "app = create_app({'TESTING': True, \"TFX_ENDPOINT\": \"MockMockMock\"})\n",
    "test_client = app.test_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tests to see if our app successfully deploys with a homepage\n",
    "# Succeeds if the response code for default path is 200\n",
    "def test_app_homepage():\n",
    "    response = test_client.get('/')\n",
    "    assert response.status_code==200\n",
    "\n",
    "test_app_homepage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test test test test']\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# This test checks if we are able to successfully post a sentence to the server and get a response back\n",
    "# Mock the backend request to TFX serving\n",
    "# Succeeds if data returns successfully in correct form\n",
    "@patch('securereqnet.deployment.__get_predictions')\n",
    "def test_get_prediction_single(mock_predictions):\n",
    "    test_payload = {\"instances\": [\"test test test test\"]}\n",
    "    expected_pred = {\"predictions\": [True]}\n",
    "    mock_predictions.return_value = expected_pred\n",
    "    response = test_client.post('/models/alpha', json=test_payload)\n",
    "    r_data = json.loads(response.data.decode('utf-8'))\n",
    "    assert r_data == expected_pred\n",
    "\n",
    "test_get_prediction_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test test test test', 'more testing', 'super duper testing']\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# This test checks if we are able to successfully post multiple sentences to the server and get a response back\n",
    "# Mock the backend request to TFX serving\n",
    "# Succeeds if data returns successfully in correct form\n",
    "@patch('securereqnet.deployment.__get_predictions')\n",
    "def test_get_prediction_multi(mock_predictions):\n",
    "    test_payload = {\"instances\": [\"test test test test\", \"more testing\", \"super duper testing\"]}\n",
    "    expected_pred = {\"predictions\": [True, False, True]}\n",
    "    mock_predictions.return_value = expected_pred\n",
    "    response = test_client.post('/models/alpha', json=test_payload)\n",
    "    r_data = json.loads(response.data.decode('utf-8'))\n",
    "    assert r_data == expected_pred\n",
    "\n",
    "test_get_prediction_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# This test checks if we are able to successfully post a blank to the server and get a response back\n",
    "# Mock the backend request to TFX serving\n",
    "# Succeeds if data returns with a blank result and no error\n",
    "@patch('securereqnet.deployment.__get_predictions')\n",
    "def test_get_prediction_blank(mock_predictions):\n",
    "    test_payload = {\"instances\": []}\n",
    "    expected_pred = {\"predictions\": []}\n",
    "    mock_predictions.return_value = expected_pred\n",
    "    response = test_client.post('/models/alpha', json=test_payload)\n",
    "    r_data = json.loads(response.data.decode('utf-8'))\n",
    "    assert r_data == expected_pred\n",
    "\n",
    "test_get_prediction_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for backend services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'inp' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-27d47d8d9614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mexpected_pred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtest_get_predictions_blank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\unittest\\mock.py\u001b[0m in \u001b[0;36mpatched\u001b[1;34m(*args, **keywargs)\u001b[0m\n\u001b[0;32m   1323\u001b[0m                                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m                                         keywargs) as (newargs, newkeywargs):\n\u001b[1;32m-> 1325\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnewkeywargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \u001b[0mpatched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatchings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-27d47d8d9614>\u001b[0m in \u001b[0;36mtest_get_predictions_blank\u001b[1;34m(mock_post)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtest_payload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mexpected_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"predictions\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__get_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_payload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mexpected_pred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8cc019dc5e1f>\u001b[0m in \u001b[0;36m__get_predictions\u001b[1;34m(sentences, endpoint_uri)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m__get_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint_uri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     payload = {\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[1;34m\"instances\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvectorize_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         }\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jason\\desktop\\fall2020\\swe\\securereqnet\\securereqnet\\preprocessing.py\u001b[0m in \u001b[0;36mvectorize_sentences\u001b[1;34m(sentences)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwords_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed_flatten\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# print(inp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'inp' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# checks if we can send a blank input and get a blank output with no error\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_blank(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": []}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = []\n",
    "    expected_pred = {\"predictions\": []}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# checks to see if we can post a single value which will decode as false\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_single_false(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[0, 1]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [False]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_single_false()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# checks to see if we can send a single value which will decode as true\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_single_true(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[1, 0]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [True]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_single_true()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# checks to see if we can test a nonbinary prediction on a single input and get true\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_single_true_nonbinary(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[0.9, 0.2]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [True]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_single_true_nonbinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# checks to see if we can test a nonbinary prediction on a single input and get false\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_single_false_nonbinary(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[0.2, 0.9]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [False]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_single_false_nonbinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# tests if we can get multiple true predictions from strings\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_multi_true(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[1, 0], [1, 0], [1, 0]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\", \"test test test test\", \"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [True, True, True]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_multi_true()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# tests if we can get multiple false predictions from strings\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_multi_false(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[0, 1], [0, 1], [0, 1]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\", \"test test test test\", \"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [False, False, False]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_multi_false()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#collapse_input\n",
    "# tests if we can get multiple mixed predictions from strings\n",
    "@patch('requests.post')\n",
    "def test_get_predictions_multi_mixed(mock_post):\n",
    "    mock = Mock()\n",
    "    mock.content.decode = Mock(return_value=\"{\\\"predictions\\\": [[0, 1], [1, 0], [0, 1], [1, 0]]}\")\n",
    "    mock_post.return_value = mock\n",
    "    test_payload = [\"test test test test\", \"test test test test\", \"test test test test\", \"test test test test\"]\n",
    "    expected_pred = {\"predictions\": [False, True, False, True]}\n",
    "    response = __get_predictions(test_payload, \"\")\n",
    "    assert expected_pred==response\n",
    "    \n",
    "test_get_predictions_multi_mixed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
