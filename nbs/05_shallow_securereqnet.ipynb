{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "req-predict-[100embeds]-shallow-E.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "863o769UPm7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#danaderp May6'19\n",
        "#Prediction For Main Issues Data Set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvPNND47Pm7V",
        "colab_type": "code",
        "colab": {},
        "outputId": "510e3a36-79e1-42dd-9247-2a45e7217d0b"
      },
      "source": [
        "import csv\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from nltk.corpus import gutenberg\n",
        "from string import punctuation\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Limited tf.compat.v2.summary API due to missing TensorBoard installation\n",
            "Limited tf.summary API due to missing TensorBoard installation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el64GldHPm7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.display.max_colwidth = 200\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJL-n6UWPm7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "englishStemmer=SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cKxzKWGPm7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Lambda\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baaCGyvePm7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize model structure\n",
        "#from IPython.display import SVG\n",
        "#from keras.utils.vis_utils import model_to_dot\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0ZX9ERPm7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datasets.read_data import Dynamic_Dataset,Processing_Dataset\n",
        "from vectorize_sentence import Embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb_CkYrkPm73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"datasets/augmented_dataset/\"\n",
        "process_unit = Processing_Dataset(path)\n",
        "ground_truth = process_unit.get_ground_truth()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihX76G8sPm77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Dynamic_Dataset(ground_truth, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqeQHRAtPm7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test, train = process_unit.get_test_and_training(ground_truth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBhrvDTjPm8D",
        "colab_type": "code",
        "colab": {},
        "outputId": "a19326e9-6a4c-4375-9ee6-7ef3064c22be"
      },
      "source": [
        "print(len(test))\n",
        "print(len(train))\n",
        "print(test[0])\n",
        "print(train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11612\n",
            "104510\n",
            "('(1,0)', 'An elevation of privilege vulnerability in the Android framework (ui framework). Product: Android. Versions: 4.4.4, 5.0.2, 5.1.1, 6.0, 6.0.1, 7.0, 7.1.1, 7.1.2. Android ID: A-35056974.')\n",
            "('(1,0)', 'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcAxQa-wPm8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train/Test split verification\n",
        "#for elem in train:\n",
        "#    print(elem[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohgOIp23Pm8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocesing Corpora\n",
        "embeddings = Embeddings()\n",
        "max_words = 5000 #<------- [Parameter]\n",
        "pre_corpora_train = [doc for doc in train if len(doc[1])< max_words]\n",
        "pre_corpora_test = [doc for doc in test if len(doc[1])< max_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvf9hzHrPm8P",
        "colab_type": "code",
        "colab": {},
        "outputId": "f57b7fd4-c618-43e2-ee62-7e1e0f06e6a7"
      },
      "source": [
        "print(len(pre_corpora_train))\n",
        "print(len(pre_corpora_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103876\n",
            "11539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p5Elrc5Pm8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMqq97FbPm8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_path = 'datasets/word_embeddings-embed_size_100-epochs_100.csv'\n",
        "embeddings_dict = embeddings.get_embeddings_dict(embed_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhDbXYBMPm8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpora_train = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_train]#vectorization Inputs\n",
        "corpora_test = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_test]#vectorization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT25r1nmPm8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train = [[int(list(doc[0])[1]),int(list(doc[0])[3])] for doc in pre_corpora_train]#vectorization Output\n",
        "target_test = [[int(list(doc[0])[1]),int(list(doc[0])[3])]for doc in pre_corpora_test]#vectorization Output\n",
        "#target_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQmXecG8Pm8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_sentences_train = max([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
        "max_len_sentences_test = max([len(doc) for doc in corpora_test]) #<------- [Parameter]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AClpSwpJPm8w",
        "colab_type": "code",
        "colab": {},
        "outputId": "f1d6a486-1bd1-4781-82f8-b07511975428"
      },
      "source": [
        "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
        "print(\"Max. Sentence # words:\",max_len_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max. Sentence # words: 618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bImQa9-BPm80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = np.size(corpora_train[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOg5eMk1Pm83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BaseLine Architecture <-------\n",
        "embeddigs_cols = embed_size\n",
        "input_sh = (max_len_sentences,embeddigs_cols,1)\n",
        "#Selecting filters? \n",
        "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
        "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
        "\n",
        "N_filters = 128 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
        "K = 2 # <-------- [HyperParameter] Number of Classess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZBpV1cuPm87",
        "colab_type": "code",
        "colab": {},
        "outputId": "108f35f7-cbcb-4063-f699-4d99cfc570e1"
      },
      "source": [
        "input_sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(618, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL_tU5dNPm8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#baseline_model = Sequential()\n",
        "gram_input = Input(shape = input_sh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-vNdvAqPm9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1st Convolutional Layer (1-gram)\n",
        "conv_filter_1_gram = Conv2D(filters= N_filters, input_shape=input_sh, activation='relu', \n",
        "                       kernel_size=(1,embeddigs_cols), padding='valid',data_format=\"channels_last\")(gram_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFaL7koePm9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2sd Convolutional Layer (3-gram)\n",
        "conv_filter_3_gram = Conv2D(filters= N_filters, input_shape=input_sh, activation='relu', \n",
        "                       kernel_size=(3,embeddigs_cols), padding='valid')(gram_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmFo4reIPm9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3rd Convolutional Layer (5-gram)\n",
        "conv_filter_5_gram = Conv2D(filters= N_filters, input_shape=input_sh, activation='relu', \n",
        "                       kernel_size=(5,embeddigs_cols), padding='valid')(gram_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsKO6wgFPm9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Max Pooling Layer\n",
        "max_pool_1_gram = MaxPooling2D(pool_size=((max_len_sentences-1+1), 1), strides=None, padding='valid')(conv_filter_1_gram)\n",
        "max_pool_3_gram = MaxPooling2D(pool_size=((max_len_sentences-3+1), 1), strides=None, padding='valid')(conv_filter_3_gram)\n",
        "max_pool_5_gram = MaxPooling2D(pool_size=((max_len_sentences-5+1), 1), strides=None, padding='valid')(conv_filter_5_gram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuENTszvPm9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fully Connected layer\n",
        "fully_connected_1_gram = Flatten()(max_pool_1_gram)\n",
        "fully_connected_3_gram = Flatten()(max_pool_3_gram)\n",
        "fully_connected_5_gram = Flatten()(max_pool_5_gram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHxwwDUePm9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_vector = layers.concatenate([fully_connected_1_gram, fully_connected_3_gram, \n",
        "                                    fully_connected_5_gram], axis=-1)\n",
        "\n",
        "integration_layer = Dropout(0.2)(merged_vector) # <-------- [HyperParameter]\n",
        "\n",
        "predictions = Dense(K, activation='softmax')(integration_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuFN3FO1Pm9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criticality Model\n",
        "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMOROrYKPm9i",
        "colab_type": "code",
        "colab": {},
        "outputId": "afb80ad4-989b-4994-d687-57a4c49d4a54"
      },
      "source": [
        "print(criticality_network.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 618, 100, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 618, 1, 128)  12928       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 616, 1, 128)  38528       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 614, 1, 128)  64128       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 1, 1, 128)    0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 128)          0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 128)          0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 384)          0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 384)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            770         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 116,354\n",
            "Trainable params: 116,354\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcc7O-QDPm9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Seting up the Model\n",
        "criticality_network.compile(optimizer='adam',loss='binary_crossentropy',\n",
        "                                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6SUJFbdPm9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data set organization\n",
        "from tempfile import mkdtemp\n",
        "import os.path as path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py2MlvXgPm9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Memoization \n",
        "file_corpora_train_x = path.join(mkdtemp(), 'e-res_temp_corpora_train_x.dat') #Update per experiment\n",
        "file_corpora_test_x = path.join(mkdtemp(), 'e-res_temp_corpora_test_x.dat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuAoRHjCPm90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shaping\n",
        "shape_train_x = (len(corpora_train),max_len_sentences,embeddigs_cols,1)\n",
        "shape_test_x = (len(corpora_test),max_len_sentences,embeddigs_cols,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSbNNi1zPm94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data sets\n",
        "corpora_train_x = np.memmap(\n",
        "        filename = file_corpora_train_x, \n",
        "        dtype='float32', \n",
        "        mode='w+', \n",
        "        shape = shape_train_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7L2DGgCPm99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpora_test_x = np.memmap( #Test Corpora (for future evaluation)\n",
        "        filename = file_corpora_test_x, \n",
        "        dtype='float32', \n",
        "        mode='w+', \n",
        "        shape = shape_test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opntveuSPm-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_train_y = np.array(target_train) #Train Target\n",
        "target_test_y = np.array(target_test) #Test Target (for future evaluation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rg1OiV9Pm-H",
        "colab_type": "code",
        "colab": {},
        "outputId": "46560dd1-44c4-4353-c84b-95c32fc43ab1"
      },
      "source": [
        "corpora_train_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103876, 618, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTuhwQkPPm-L",
        "colab_type": "code",
        "colab": {},
        "outputId": "20ec1b66-53f0-4eb1-8567-2188491c00ab"
      },
      "source": [
        "target_train_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103876, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btV5EUi_Pm-P",
        "colab_type": "code",
        "colab": {},
        "outputId": "33145933-bc34-429f-c5ba-7b69e117e4db"
      },
      "source": [
        "corpora_test_x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11539, 618, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC0fSdtYPm-U",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a95b5cb-154b-4e17-aab0-66ec701a90db"
      },
      "source": [
        "target_test_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11539, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRV3TaefPm-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping Train Inputs\n",
        "for doc in range(len(corpora_train)):\n",
        "    #print(corpora_train[doc].shape[1])\n",
        "    for words_rows in range(corpora_train[doc].shape[0]):\n",
        "        embed_flatten = np.array(corpora_train[doc][words_rows]).flatten() #<--- Capture doc and word\n",
        "        for embedding_cols in range(embed_flatten.shape[0]):\n",
        "            corpora_train_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlzkpP85Pm-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping Test Inputs (for future evaluation)\n",
        "for doc in range(len(corpora_test)):\n",
        "    for words_rows in range(corpora_test[doc].shape[0]):\n",
        "        embed_flatten = np.array(corpora_test[doc][words_rows]).flatten() #<--- Capture doc and word\n",
        "        for embedding_cols in range(embed_flatten.shape[0]):\n",
        "            corpora_test_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7-M9gqDPm-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CheckPoints\n",
        "#csv_logger = CSVLogger(system+'_training.log')\n",
        "filepath = \"e-res/best_model.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vadUpvpRPm-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "callbacks_list = [es,mc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbsRPHMJPm-n",
        "colab_type": "code",
        "colab": {},
        "outputId": "e46108c6-0a13-480d-90d3-f732ab389543"
      },
      "source": [
        "#Model Fitting\n",
        "history = criticality_network.fit(\n",
        "            x = corpora_train_x, \n",
        "            y = target_train_y,\n",
        "            #batch_size=64,\n",
        "            epochs=2000, #5 <------ Hyperparameter\n",
        "            validation_split = 0.2,\n",
        "            callbacks=callbacks_list\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 83100 samples, validate on 20776 samples\n",
            "Epoch 1/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9560\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99884, saving model to e-res/best_model.hdf5\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.1308 - accuracy: 0.9560 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
            "Epoch 2/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9662\n",
            "Epoch 00002: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 122s 1ms/sample - loss: 0.1000 - accuracy: 0.9662 - val_loss: 0.0052 - val_accuracy: 0.9981\n",
            "Epoch 3/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9706\n",
            "Epoch 00003: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0873 - accuracy: 0.9706 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 4/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9722\n",
            "Epoch 00004: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0795 - accuracy: 0.9722 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
            "Epoch 5/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9754\n",
            "Epoch 00005: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 128s 2ms/sample - loss: 0.0709 - accuracy: 0.9754 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
            "Epoch 6/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9773\n",
            "Epoch 00006: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0644 - accuracy: 0.9773 - val_loss: 0.0064 - val_accuracy: 0.9974\n",
            "Epoch 7/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9800\n",
            "Epoch 00007: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0589 - accuracy: 0.9800 - val_loss: 0.0076 - val_accuracy: 0.9971\n",
            "Epoch 8/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9819 ETA: 1s - loss: 0\n",
            "Epoch 00008: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0534 - accuracy: 0.9819 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
            "Epoch 9/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9834\n",
            "Epoch 00009: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.0040 - val_accuracy: 0.9986\n",
            "Epoch 10/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9846\n",
            "Epoch 00010: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0440 - accuracy: 0.9846 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
            "Epoch 11/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9860\n",
            "Epoch 00011: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0422 - accuracy: 0.9860 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 12/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9871\n",
            "Epoch 00012: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0378 - accuracy: 0.9871 - val_loss: 0.0057 - val_accuracy: 0.9981\n",
            "Epoch 13/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9877\n",
            "Epoch 00013: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 14/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9886\n",
            "Epoch 00014: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 125s 2ms/sample - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
            "Epoch 15/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9885\n",
            "Epoch 00015: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
            "Epoch 16/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9887\n",
            "Epoch 00016: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.0097 - val_accuracy: 0.9969\n",
            "Epoch 17/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9906\n",
            "Epoch 00017: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
            "Epoch 18/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9899\n",
            "Epoch 00018: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 19/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9910\n",
            "Epoch 00019: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0147 - val_accuracy: 0.9962\n",
            "Epoch 20/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9913\n",
            "Epoch 00020: val_accuracy did not improve from 0.99884\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
            "Epoch 21/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9912\n",
            "Epoch 00021: val_accuracy improved from 0.99884 to 0.99889, saving model to e-res/best_model.hdf5\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
            "Epoch 22/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9916 ETA: 1s - loss:\n",
            "Epoch 00022: val_accuracy did not improve from 0.99889\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
            "Epoch 23/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9926\n",
            "Epoch 00023: val_accuracy did not improve from 0.99889\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
            "Epoch 24/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9925\n",
            "Epoch 00024: val_accuracy did not improve from 0.99889\n",
            "83100/83100 [==============================] - 122s 1ms/sample - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
            "Epoch 25/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9928\n",
            "Epoch 00025: val_accuracy improved from 0.99889 to 0.99904, saving model to e-res/best_model.hdf5\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
            "Epoch 26/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9920\n",
            "Epoch 00026: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
            "Epoch 27/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9928\n",
            "Epoch 00027: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0047 - val_accuracy: 0.9988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9937\n",
            "Epoch 00028: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0068 - val_accuracy: 0.9986\n",
            "Epoch 29/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9930\n",
            "Epoch 00029: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
            "Epoch 30/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9937\n",
            "Epoch 00030: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.0105 - val_accuracy: 0.9977\n",
            "Epoch 31/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9934\n",
            "Epoch 00031: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 32/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9933\n",
            "Epoch 00032: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0077 - val_accuracy: 0.9985\n",
            "Epoch 33/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9944\n",
            "Epoch 00033: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 123s 1ms/sample - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
            "Epoch 34/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9939\n",
            "Epoch 00034: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.0113 - val_accuracy: 0.9976\n",
            "Epoch 35/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9943\n",
            "Epoch 00035: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 36/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9940\n",
            "Epoch 00036: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 37/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9946 ETA: 0s - loss: 0.0201 - accu\n",
            "Epoch 00037: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.0115 - val_accuracy: 0.9979\n",
            "Epoch 38/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9945\n",
            "Epoch 00038: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
            "Epoch 39/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9946\n",
            "Epoch 00039: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0110 - val_accuracy: 0.9979\n",
            "Epoch 40/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9946\n",
            "Epoch 00040: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
            "Epoch 41/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9948\n",
            "Epoch 00041: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0090 - val_accuracy: 0.9983\n",
            "Epoch 42/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9949\n",
            "Epoch 00042: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
            "Epoch 43/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947\n",
            "Epoch 00043: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
            "Epoch 44/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9951\n",
            "Epoch 00044: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 45/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9955\n",
            "Epoch 00045: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0137 - val_accuracy: 0.9974\n",
            "Epoch 46/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9948 ETA: 1s - l\n",
            "Epoch 00046: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.0095 - val_accuracy: 0.9984\n",
            "Epoch 47/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9952\n",
            "Epoch 00047: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
            "Epoch 48/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9949\n",
            "Epoch 00048: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0089 - val_accuracy: 0.9982\n",
            "Epoch 49/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9952\n",
            "Epoch 00049: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 117s 1ms/sample - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
            "Epoch 50/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956\n",
            "Epoch 00050: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
            "Epoch 51/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9958\n",
            "Epoch 00051: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0068 - val_accuracy: 0.9988\n",
            "Epoch 52/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9950\n",
            "Epoch 00052: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
            "Epoch 53/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9956\n",
            "Epoch 00053: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0072 - val_accuracy: 0.9986\n",
            "Epoch 54/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9955\n",
            "Epoch 00054: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0134 - val_accuracy: 0.9976\n",
            "Epoch 55/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9955\n",
            "Epoch 00055: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.0103 - val_accuracy: 0.9982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 56/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9957\n",
            "Epoch 00056: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
            "Epoch 57/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9957\n",
            "Epoch 00057: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0100 - val_accuracy: 0.9981\n",
            "Epoch 58/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9956\n",
            "Epoch 00058: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 59/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9957\n",
            "Epoch 00059: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0136 - val_accuracy: 0.9976\n",
            "Epoch 60/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9961\n",
            "Epoch 00060: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0107 - val_accuracy: 0.9981\n",
            "Epoch 61/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9959\n",
            "Epoch 00061: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0162 - val_accuracy: 0.9972\n",
            "Epoch 62/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9964\n",
            "Epoch 00062: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0077 - val_accuracy: 0.9988\n",
            "Epoch 63/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9960\n",
            "Epoch 00063: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0081 - val_accuracy: 0.9987\n",
            "Epoch 64/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9962\n",
            "Epoch 00064: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.0091 - val_accuracy: 0.9985\n",
            "Epoch 65/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9961\n",
            "Epoch 00065: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0088 - val_accuracy: 0.9988\n",
            "Epoch 66/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9964\n",
            "Epoch 00066: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0103 - val_accuracy: 0.9982\n",
            "Epoch 67/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9962\n",
            "Epoch 00067: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0108 - val_accuracy: 0.9985\n",
            "Epoch 68/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9963\n",
            "Epoch 00068: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.0097 - val_accuracy: 0.9985\n",
            "Epoch 69/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9963\n",
            "Epoch 00069: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9980\n",
            "Epoch 70/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9960\n",
            "Epoch 00070: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0095 - val_accuracy: 0.9986\n",
            "Epoch 71/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9967\n",
            "Epoch 00071: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.0159 - val_accuracy: 0.9974\n",
            "Epoch 72/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9966\n",
            "Epoch 00072: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 120s 1ms/sample - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0148 - val_accuracy: 0.9978\n",
            "Epoch 73/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9964\n",
            "Epoch 00073: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0110 - val_accuracy: 0.9985\n",
            "Epoch 74/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9964\n",
            "Epoch 00074: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.0106 - val_accuracy: 0.9984\n",
            "Epoch 75/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9969\n",
            "Epoch 00075: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9982\n",
            "Epoch 76/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9962\n",
            "Epoch 00076: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.0211 - val_accuracy: 0.9969\n",
            "Epoch 77/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9966\n",
            "Epoch 00077: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.0124 - val_accuracy: 0.9983\n",
            "Epoch 78/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9967\n",
            "Epoch 00078: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0101 - val_accuracy: 0.9988\n",
            "Epoch 79/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9964\n",
            "Epoch 00079: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0134 - val_accuracy: 0.9981\n",
            "Epoch 80/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9968\n",
            "Epoch 00080: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0128 - val_accuracy: 0.9983\n",
            "Epoch 81/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9965\n",
            "Epoch 00081: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 118s 1ms/sample - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0140 - val_accuracy: 0.9982\n",
            "Epoch 82/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9966\n",
            "Epoch 00082: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.0109 - val_accuracy: 0.9985\n",
            "Epoch 83/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9967\n",
            "Epoch 00083: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.0144 - val_accuracy: 0.9981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 84/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9967\n",
            "Epoch 00084: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.0149 - val_accuracy: 0.9981\n",
            "Epoch 85/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9966\n",
            "Epoch 00085: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 109s 1ms/sample - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0161 - val_accuracy: 0.9975\n",
            "Epoch 86/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9970\n",
            "Epoch 00086: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0161 - val_accuracy: 0.9977\n",
            "Epoch 87/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9967\n",
            "Epoch 00087: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 116s 1ms/sample - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0116 - val_accuracy: 0.9985\n",
            "Epoch 88/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9968\n",
            "Epoch 00088: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0157 - val_accuracy: 0.9981\n",
            "Epoch 89/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9970\n",
            "Epoch 00089: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.0112 - val_accuracy: 0.9985\n",
            "Epoch 90/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9968\n",
            "Epoch 00090: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 112s 1ms/sample - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0175 - val_accuracy: 0.9977\n",
            "Epoch 91/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9970\n",
            "Epoch 00091: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 121s 1ms/sample - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0127 - val_accuracy: 0.9982\n",
            "Epoch 92/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9970\n",
            "Epoch 00092: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0116 - val_accuracy: 0.9981\n",
            "Epoch 93/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971\n",
            "Epoch 00093: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 113s 1ms/sample - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0165 - val_accuracy: 0.9978\n",
            "Epoch 94/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9970\n",
            "Epoch 00094: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0142 - val_accuracy: 0.9980\n",
            "Epoch 95/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9970\n",
            "Epoch 00095: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 111s 1ms/sample - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0174 - val_accuracy: 0.9979\n",
            "Epoch 96/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9976\n",
            "Epoch 00096: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0122 - val_accuracy: 0.9983\n",
            "Epoch 97/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9967\n",
            "Epoch 00097: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9981\n",
            "Epoch 98/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9972\n",
            "Epoch 00098: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 110s 1ms/sample - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0186 - val_accuracy: 0.9977\n",
            "Epoch 99/2000\n",
            "83040/83100 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971\n",
            "Epoch 00099: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 114s 1ms/sample - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0229 - val_accuracy: 0.9971\n",
            "Epoch 100/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9970\n",
            "Epoch 00100: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.0118 - val_accuracy: 0.9986\n",
            "Epoch 101/2000\n",
            "83072/83100 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9973\n",
            "Epoch 00101: val_accuracy did not improve from 0.99904\n",
            "83100/83100 [==============================] - 115s 1ms/sample - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.0211 - val_accuracy: 0.9973\n",
            "Epoch 00101: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qizorKf5Pm-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Training History\n",
        "df_history = pd.DataFrame.from_dict(history.history)\n",
        "df_history.to_csv('e-res/history_training.csv', encoding='utf-8',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCCoefs0Pm-z",
        "colab_type": "code",
        "colab": {},
        "outputId": "b0befbdc-6adf-487a-c039-89b2c4d741fc"
      },
      "source": [
        "df_history.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.955993</td>\n",
              "      <td>0.130766</td>\n",
              "      <td>0.998845</td>\n",
              "      <td>0.003467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.966173</td>\n",
              "      <td>0.099961</td>\n",
              "      <td>0.998123</td>\n",
              "      <td>0.005184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.970638</td>\n",
              "      <td>0.087270</td>\n",
              "      <td>0.998652</td>\n",
              "      <td>0.003626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.972238</td>\n",
              "      <td>0.079534</td>\n",
              "      <td>0.997930</td>\n",
              "      <td>0.005712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.975439</td>\n",
              "      <td>0.070949</td>\n",
              "      <td>0.998267</td>\n",
              "      <td>0.004923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy      loss  val_accuracy  val_loss\n",
              "0  0.955993  0.130766      0.998845  0.003467\n",
              "1  0.966173  0.099961      0.998123  0.005184\n",
              "2  0.970638  0.087270      0.998652  0.003626\n",
              "3  0.972238  0.079534      0.997930  0.005712\n",
              "4  0.975439  0.070949      0.998267  0.004923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwORCfknPm-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Test Data\n",
        "np.save('e-res/corpora_test_x.npy',corpora_test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RyXz2laPm--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('e-res/target_test_y.npy',target_test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhpZ6gR-Pm_D",
        "colab_type": "code",
        "colab": {},
        "outputId": "79523326-7e8d-4f1a-91c9-5b80f74d9ee0"
      },
      "source": [
        "#Evaluation\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        " \n",
        "epochs2 = range(len(acc))\n",
        " \n",
        "plt.plot(epochs2, acc, 'b', label='Training')\n",
        "plt.plot(epochs2, val_acc, 'r', label='Validation')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        " \n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs2, loss, 'b', label='Training')\n",
        "plt.plot(epochs2, val_loss, 'r', label='Validation')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYFFXW+PHvYcg5g5JFFDCQRl4lKIgimFCXXcWMAUEM\nuOqaA6667E/XV1EMqKC+EkVAVsEIAkYYEJAgQUAZ4pBzGOb8/jjVTE+kB6anJ5zP8/Qz0xVPVXfX\nqXvr1i1RVZxzzrmjKRbrAJxzzhUMnjCcc85FxBOGc865iHjCcM45FxFPGM455yLiCcM551xEPGG4\niIlInIjsFpH6uTltLInIySKS623LReQCEVkd9n6piHSMZNpjWNc7IvLosc7vXKSKxzoAFz0isjvs\nbVngAHA4eH+Hqo7IyfJU9TBQPrenLQpU9dTcWI6I3AZcr6qdwpZ9W24s27mj8YRRiKnqkQN2cAZ7\nm6p+ndX0IlJcVZPzIjbnjsa/j/mPV0kVYSLyrIiMEZFRIrILuF5EzhGRn0Rku4isF5HBIlIimL64\niKiINAzefxiMnyIiu0TkRxFplNNpg/HdRWSZiOwQkVdF5HsRuTmLuCOJ8Q4RWSEi20RkcNi8cSLy\nvyKyRURWAt2y2T+PicjodMOGiMhLwf+3iciSYHt+D87+s1pWooh0Cv4vKyL/F8S2CGiTbtrHRWRl\nsNxFInJ5MPwM4DWgY1Ddtzls3z4dNn/fYNu3iMhEETkhkn2Tk/0cikdEvhaRrSKyQUT+EbaeJ4J9\nslNEEkTkxMyq/0Tku9DnHOzPGcF6tgKPi0gTEZkWrGNzsN8qhc3fINjGpGD8KyJSOoi5Wdh0J4jI\nXhGpltX2ugioqr+KwAtYDVyQbtizwEHgMuzkoQxwFvA/WOnzJGAZcFcwfXFAgYbB+w+BzUA8UAIY\nA3x4DNPWBHYBPYJxfwcOATdnsS2RxPgJUAloCGwNbTtwF7AIqAtUA2bYzyDT9ZwE7AbKhS17ExAf\nvL8smEaA84F9wJnBuAuA1WHLSgQ6Bf+/CHwLVAEaAIvTTfs34ITgM7k2iKFWMO424Nt0cX4IPB38\n3zWIsSVQGngdmBrJvsnhfq4EbATuBUoBFYG2wbhHgPlAk2AbWgJVgZPT72vgu9DnHGxbMtAPiMO+\nj6cAXYCSwffke+DFsO1ZGOzPcsH07YNxQ4HnwtZzPzAh1r/Dgv6KeQD+yqMPOuuEMfUo8z0AfBT8\nn1kSeDNs2suBhccw7S3AzLBxAqwni4QRYYxnh40fDzwQ/D8Dq5oLjbs4/UEs3bJ/Aq4N/u8OLM1m\n2k+B/sH/2SWMP8M/C+DO8GkzWe5C4JLg/6MljPeB58PGVcSuW9U92r7J4X6+AZidxXS/h+JNNzyS\nhLHyKDH0DK0X6AhsAOIyma49sAqQ4P084Krc/l0VtZdXSbk14W9EpKmIfBZUMewEngGqZzP/hrD/\n95L9he6spj0xPA61X3hiVguJMMaI1gX8kU28ACOBXsH/1wbvQ3FcKiI/B9Ul27Gz++z2VcgJ2cUg\nIjeLyPygWmU70DTC5YJt35HlqepOYBtQJ2yaiD6zo+znelhiyEx2444m/fextoiMFZG1QQzvpYth\ntVoDizRU9XustNJBRE4H6gOfHWNMLuAJw6VvUvoWdkZ7sqpWBJ7EzvijaT12BgyAiAhpD3DpHU+M\n67EDTcjRmv2OBS4QkTpYldnIIMYywDjgX1h1UWXgywjj2JBVDCJyEvAGVi1TLVjub2HLPVoT4HVY\nNVdoeRWwqq+1EcSVXnb7eQ3QOIv5shq3J4ipbNiw2ummSb99/8Za950RxHBzuhgaiEhcFnF8AFyP\nlYbGquqBLKZzEfKE4dKrAOwA9gQXDe/Ig3V+CrQWkctEpDhWL14jSjGOBQaISJ3gAuhD2U2sqhuw\napP3sOqo5cGoUli9ehJwWEQuxeraI43hURGpLHafyl1h48pjB80kLHfejpUwQjYCdcMvPqczCrhV\nRM4UkVJYQpupqlmW2LKR3X6eBNQXkbtEpJSIVBSRtsG4d4BnRaSxmJYiUhVLlBuwxhVxItKHsOSW\nTQx7gB0iUg+rFgv5EdgCPC/WkKCMiLQPG/9/WBXWtVjycMfJE4ZL737gJuwi9FvYxemoUtWNwNXA\nS9gBoDHwC3ZmmdsxvgF8A/wKzMZKCUczErsmcaQ6SlW3A/cBE7ALxz2xxBeJp7CSzmpgCmEHM1Vd\nALwKzAqmORX4OWzer4DlwEYRCa9aCs3/OVZ1NCGYvz5wXYRxpZflflbVHcCFwF+wJLYMOC8Y/QIw\nEdvPO7EL0KWDqsbbgUexBhAnp9u2zDwFtMUS1yTg47AYkoFLgWZYaeNP7HMIjV+Nfc4HVPWHHG67\ny0TogpBz+UZQxbAO6KmqM2Mdjyu4ROQD7EL607GOpTDwG/dcviAi3bAWSfuwZpmHsLNs545JcD2o\nB3BGrGMpLLxKyuUXHYCVWN39RcCVfpHSHSsR+Rd2L8jzqvpnrOMpLLxKyjnnXES8hOGccy4iheoa\nRvXq1bVhw4axDsM55wqMOXPmbFbV7JqxH1GoEkbDhg1JSEiIdRjOOVdgiMjRejs4wquknHPORSRq\nCUNEhonIJhFZmMV4CboxXiEiC0Skddi4bmJPKFshIg9HK0bnnHORi2YJ4z2yedYA1vNnk+DVB7sD\nN3TT1pBgfHOgl4g0j2KczjnnIhC1hKGqM7AuE7LSA/hAzU9AZbEHvbQFVqjqSlU9CIwOpnXOORdD\nsbyGUYe0XRknBsOyGp4pEekTPNErISkpKSqBOuecKwQXvVV1qKrGq2p8jRoRtQxzzjl3DGLZrHYt\naZ8JUDcYViKL4c4552IoliWMScCNQWups4Edqroe63K6iYg0EpGSwDXBtC6WJk6EhZk2eCv4Dmd4\nYJtzLhPRbFY7CnvAyakikigit4pIXxHpG0wyGetsbgXwNvZc41Af93cBXwBLsCdlLYpWnCQnQ58+\n8PXXUVtFvrN0KXTuDP/zP9C9O1x3HfTuba9bb4Uff0w7/ZgxcOWV0L49zJ6ddtysWfDdd5CSEv24\np0yByy6Dbdtyb5mTJkGlSnD77bBnT+4tN9ycOfaKpS1b4L774PXXYe5cOHQo4zQrVsA//mF/86PP\nP4dXXgHv/y52Yv1Q8dx8tWnTRnNs+3bVM85QLV9edfbs1OF79qgOGKA6fHjOl6mqmpKiumaN6vz5\nqlOnqq5alXGaL79Uvf121S1bIlvm/v2qCxZkPm7KFNV//EP13HNV69TJeroZM1SrVlWtUUP1ootU\n4+NVTzpJtX59e1WsqFqmjC1PVfWXX+z92WerNmqkWrmy6pw5qlu3qvburWo/X9UGDVQfe8y2OVIp\nKaqHDkU27fLlFhuoXn995OvIzogRqnFxtl0iqk2bqs6blzvLVrXt+9//tXWE4l671satXav6zjuq\nkydnP/+bb6r27au6a1fa4c88o9qqlermzZHF8uSTqZ8VqJYtq9qrl61/61bVhx5SLVnSxtWurfrr\nr5kv5/DhtLGEx/Thh6rLlkUWT069/LJ9RqA6aFDk86WkHPs6s/puRvqdjaa5c1X/+99cWRSQoBEe\nY2N+kM/N1zElDFX78TZsqFq9uuqSJaorV6q2aJH64/rww5wv8847M/5AFy5MHb9unR24wQ5Y8+fb\n8AMH7ED24IP2pQj56SfV5s1t+u+/T7uujz6y4SVKqLZtaz+sp57KGNPo0XZQOPVU1d9/zzzujRtV\nW7a0ZQ0daomgbl3VDRtUV6+291WqqJ5wgh0IH33U4u3WTbVYMUs6RzuIHT6sOnasbU+pUjbv4MFZ\nJ5u9e+3zqFpV9Y47bFs/+ih1/NattrwDB9LOl5Kiunix7cf0r9ABqFMn1Z07Vb/+2rapZMnUZBlu\n2jTbN5Has8cSBKhecYXqI4/YssuVS/vdKlEi9bMPt3mzao8eqdO1bm3fmcOHVe+9N3X4rbcePZaD\nB23bune3z3D0aNU+fexzhNQD8c0328nNiSfavp41y050nn3WklP16vYZh7Yp9DkfOKB60002vEUL\n1eTkzOPYu1f1xhtVzzzT9vtf/qL6+OOqP/yQ9TzJyXbiFlrn3/5m/48dm/X2hn5Dbdva/v5//y/n\nB/mJE+27ed11qomJNmzHDjspK1UqZ0krEjt32slrJFJS7CS3RAnVP/447lV7wjgWy5er1qxpB8eq\nVe1MesIE+2IXL25nYikpquPHq7Zpo3r11fbjzcyqVXYw/etfVceNswNQrVp2Brtrly3n4otVS5dW\n/eAD+zGXLat69932Yw3/EZ97rh0kixWz2CpUUL3hhrTr69zZEt6+ffY+Pl61ffuM2yei2rHj0Us0\n27aptmtn6y9dOm3Ja+VKSxotW6ZNaKqqP/9sB8Xu3bPeN199ZV92UG3WTLV/f9VTTrH35cqpfvdd\nxnluvdXGT55sB7/4eNVq1ewAOn68nRGDLXfWLJvn119Vu3RJm7TTvy65xA5iIZs2qZ52mu3nnTtT\nh3/xhU1/6qk2TUhKih2Y3nvPEqqqfb6vvaZ68sm2v//5z9R98fvv9r3p1MkOODNn2vfijDOs9Bgy\nY4aVEkuUsBLKp5/avqlf3+YHO4g+8ID9P3166rx792b8XMaPt+k++STt8P37bdy999pnF/L773YS\nEypxgGqHDqr9+lkp8oEHLLY6dVQnTVI9/3yb5vLL7e/QoRk/wx07VM87z/ZJ9+62vKZNU0tf1aqp\n/uc/Gef7+99t/L33WvLYt8++26VK2YncU0+pnnWW1RDUq2cJK/R9OOUUK0WDfWd+/NG+F99+a9+z\nrEofs2fb7/Gkk2w9Zcva97RWrdTvLVjiDd/vgwfba8oU24eRlG4OH7ZSZIUKtr//8hc77qQ/+Qk3\nbVrq53L77Udfx1F4wjhWc+datcdpp9kBVtW+6K1aWbVM6MwwdFB/7LHMl3PPPZZkws+Yp061g/41\n16i+9ZbNP3iwjVu3LvUAfeGFqp99Zgf1F1+0gzNYtcSOHfbFLVUq9exuyRIb//zzqet6+GFbf/hB\n79//tun+/DOyfbF7tyWqiRMzjjt4MOsfw+uv23qefTbt8AMHUg9wJ59sB9rws8rFi+0HXr68nXGq\nWvz33WfzPP546rRLllgiCx0YWra0H12dOraPu3e3A1GVKrYPJ07M+Pr8c9uO9H74wZZ53332futW\nW26jRrbO+HiLa9cu1Z490yag1q1VK1Wy/9u2tURzNJ9+atM/9JDt08GD7bM7+WSr+guZMyd1e596\nyqbdvdu+H02b2sF/4ULV00+3acaMSZ23a1dLgjk5y05MtBOef/7TThLSS0hQbdLE1lW8uOr771tM\nHTpYdWf42fLmzXZQL15cdeTItMvZutUOvOedZ+PDq27XrbODaO/eaedJSlJt3Dj1xOqcc+xk66ab\nVC+7TPWqq+zk4vBhi2nMGIsp/QnDbbdl/A788Yft5wYN7CTg99+tZANWLTtrlu3rDh3sd/j995b4\nQ/si/HXSSVYVuGyZ6tKlto/697fkN2SIJdvOnW3a88+34TVr2vu6dVXfeCPzxHHllZZgb73V9llW\ntQUR8oRxPDZvTnu2p2pVEU2b2hfg/ffthxc6601fNN682c5Ibrop47Kff97miYuzs9/ws/BDhzI/\nmB86lLYqZMECW0bobOy+++xLEzrDVbXqFbCDUcg551jJKNpSUlSvvdYO3K+9ZmewY8fausGq6sLP\n6sMlJtqBsmJF1eeeSz1A3n57xiqL11+3A/izz6b+6Ldvt2nj4uxsONL6/fT69rX458yxbSle3A6Q\n//2vLfu88+zAXKyY6gsv2HT//KeV3q65xs5kc+L22+3Ad8kltr2XXZZ59URiYsYkNHmyzdO9u+2P\nmjWtxFKpkh18V6yw8QMHHtu+yM6uXZbIv/02dVhCgm3Lgw/a+08/tYN7qVJ2gMzKmjWWHO64I3XY\ngw/aPl6xIuP0f/5p36ukpMhiTUpSHTbMksfXX9tJFVgJZMcOK7lMmWKfa6VKqosWpZ1/06a0v9fN\nmy1JlC9v29uwoZWeN2ywEuKbb9rJX6imIPSqUMGOD6H3FSuqvv126gnYoUP2PQudQNavn7b6ddUq\n2yePPGJV6aVLW1XicfCEEQ2HDqX9wuzfbwfhsmXTXij95z9tt2Z20fDwYTsYVKkS+Zl+Ztq1sy/r\nnj1Wffa3v6Udv2+ffZEGDLD369alVo/khV27rJQW/kOpUsWK2kezZo0l5vAzuqxkdcacXXE+Etu2\nWbI64QSL45lnUse9/74Nq1rVGi3khp07rQQDqk8/nXV1XlZC9fpdu6quX28lgooV7fv5979bkgvV\nw+eF3r2tyurCC/VIVd6MGUefr18/m+/PP63kUb68Jexoeftt2zd161oNAtg6v/46svmXLbMTyXvu\nybwhgKrt98GDrYHDwoV24pOSYgf7GTNUN2zQ5GT7ir3/fth8KSlWCm7d2n67771nwx94wGIOHT/u\nu88SyHE0NvCEkVfWrbPqqfLlVf/1LzvQ1Kxp1yeycvhw5Be3svLBB3rkIiWofvNNxmkuuMDOllRT\nq8CyavkSDfv2WSINvbZti3ze9eutWi6nB87cNGaMHqlaSp+Yvv32+BJ+ZlatynnJJGTnTjuTD99f\nI0emJusrrsiVECO2fr2dSVesaCXhSBP4H39Ywujf346gkHVrv9zy+ed2nfCuu6y0llXpN0r27rUa\nJrDjfvjlqCMTXHCBJY233rJrq+EniBs2aHLpsrqo9XXHHIMnjLy0cmXqxb5Q/fW0adFd5969qS2s\nTjkl8+sJgwbZ+PXrrbqicePja2JY1KSkqI4aldoMtiAKnVB8/nner3vlysiri8LdfrtVTVWpYqXx\nPHTggJ3079mT/XTbt2f8KaWk2LXyn3+2hmi7d1tN5csvWzuFvn2tkPDbb1YY2bfPdk/79pYLBg2y\nSoMTTkitgd6xw+br/D97dFHtzkdOAJYO+0537bJYO3VSHcQ/dEXxU3XvlmNLdp4wYuGLL6wapnPn\nvDkwh1qPZNayRNXqksEunJUsqXr//dGPyeUv+/fbUSWfnyiErkuPH6+WaEItp0KNH45i797jb106\nY0ZqLWqVKtZ69vff7fLJV1/Zz+iGG1JrDhs3tjYvP/1kl7FCDf0ye9WrZwWuzMaVLJl6GXTePLvU\nc+GFdh29USMrdbRrp9q49m79nK76NecrpByZv3Zt1SH/b7fu23Xs94bkJGGITV84xMfHa8wf0aoK\nItFfz9q18OST8J//QOXKGccfPgw1akCpUrBhA8ycCR06RD8uV+Spwvvvw+rVULeuvZo1g/r1M/40\n/vwT7rjDbuIGeOst6LPyYRsxciSLF9sN/omJ9ipXDm67zTodAPjoI3jgAVizxob17w9XXAGbNsGq\nVXbT+oIF9lq9GipWhGrV7FW1qv1dswZGjIAGDeCRR6zTh/HjM3ZeULOm/YRatoQZM2Dq1NRp2re3\nuGrUsJ/bpk3QsKFNX6+e/Rx/+806Rti82TqYOHTIOlo466zUdbz9tnU8AdCoEXz4IbRrZ+/37IEV\ny1JY/nsxli+3DgpuvhnKlj2+z0tE5qhqfETTesIoxHr2hI8/tm/6unUQFxfriFyMqNpXoE6WDwpI\na/VqePNNOPVUuPxyO7CGlrNpExQvbucp6b9SqvD44/D88xmXWbs2nH22JRAROHjQDtQpKTb9l1/C\n5MmWNK67DgYOhJdesoNtuXI234YNsGMHtGgBFSpYrzQtWsBf/gIffJB5ryblysGZZ8JJJ8Hu3dZL\nypYtsHWrvQD+/nd44gmbFuCPPyxpVK5sB+5GjTImvI0bLeZWreD00yPbr0ejCg89ZHEOGmQJLtpy\nkjBiXo2Um6+YVknlR2+8oUfam7sia+vW1FtGLroobaO+5cutdc60aXbrz+7dqk88YY3sQi1C4+Ks\nrvzss1N7ZwndAlGlit0MHWpP8dRTeqQl9IEDVlX03Xd228ENN1g9fZUqqa/u3VNv89i/39qLhKpa\nQl/ddetSa9V277b7Alu0sPr+t95KbXF9+LBdrnnySZvmyy+tWim7thM56Z2msMKrpBxgZe1WrWDC\nBOjYMdbRuCjbu9f6Fvz8c2jbFrp2teE33WSlixtvtK/C9u1w8cWwbBksX552GaVLw/790KsX/Pvf\nVpr4+GOrFqpSBZo3t1KHqp2lr1kDY8dadclZZ1nflL17wzvvQLFj6Nr0wAErXaxaBYMHp1Y9uejx\nKinn8oF9+6zK5OuvrUrkuutyvoz9+6165NAhq/cuXRpOPtmqhMAO3GvXwrhxVoWxcaMd0FesSO21\nvXFjGDnSksi2bTbdBx9YXfwll8B551lCWbAAVq60OHNyuWvrVnjtNXj1Vau+GjrUaz8LEk8YzuWC\n7dvtwmJO2zCsXm310JMm2QEfbBnjx9sFWbAD/Ztv2kXQli2hTRuoVcsO/omJ9uiRmTMhIcHq+sOV\nKmVn+jVqwLx5VgoA6NLF6v3bt4edO+Hbb+1MvXfvvKkLz6v2Hi53ecJw7jgcOADPPQf/+pc9BmTE\nCChR4ujz7d8PL75o8xYrZq1munWzqppLLoFff7XWNS1aQL9+8O67lpB27Mi4rBIlID7ezvTPOMNK\nFiVKwK5dVhKYPx+SkmxZbdpYkmjdOvf3hSv8cpIwYvmIVufynVmz4JZbYNEiu+zz0UdWFTR6tB2w\nP/rIWtPUqgV33glXXWUlkXfesRLDmjXWOO2ll6w5ZcikSfa8qksvtSam335rrYkGDrSWP3PmWHVR\nqBlq/fqWJJzLTzxhuCJj1y5r3p+YaGfnJ59sZ+ilS8P06fDCC9ass25d+OwzuzA8eDDce69VJR04\nYG3vzzzTqo569bJqoR07rNqoSxcYNgwuuCDjumvVsmW3awfff2/3Kdx4o4078UR7OZffecJwBVYk\ndea7d9u1g//7P/jmG5snXFyc3R+wdq0d/AcOtARRqZKNv+ceK1nceae1yR8yxG40E4EvvoDhw23+\nfv2s5JCd5s3t6beHDlnSca6g8WsYLl/Yvt0u0LZqdfRpU1LsJvcXXrADd9mydiE4OTn1FbJ/v71v\n1MhKBGecYSWIatXs0eZz5tgduBdeCDfcAGXKZL7O2bPtzt0aNXJlc53LN/wahitQVO3i8rffWiJ4\n6im7aKxqVUPff291/+3aWbXS9dfDf/8Lf/2rJYJ9+ywxFC9upYG4uNSSR6lSVrXUvn3G0kizZqmt\nlo4mvPsG54oqTxgu5kaNsmQRHw/PPANz58I//gFPP23XDMDuHTjpJEsGK1dau/877/RmnM7lpWO4\nF9O53LNjB9x/vyWLn36yawSffw7nnmv3GLz6qt0Y9t57ljDA+u/p39+ThXN5zUsYLlekpFjPmcWK\n2Z2+JUva8EOHoG9fu/P4scfsWkH4gf6pp+zu5EmTrPRw5512I9vUqZYUqlSx6W66yV7OudjxhOFy\nxfPPW0sksBLBRx9ZYrj2WuuLqFYtuOgiu5Zwyy12oXr3bitB9OmT9hpBu3apXTo75/IPTxjuuH39\ntV2svu46Swh33mkXsUuWhE8+gZdftmanw4bBs8/Crbemzlu7duZdYTvn8h9PGC4i+/dbAkjfA+na\ntVaKaNbM7nQuX95aK91xh7VyGjLEEghY1dQtt9jNc6EHyNSvn3rPg3Muf/OE4bKVmGjdXAwdav0h\njR6deg3i4EG4+mrrVnvcOEsWALffbiWH5GQraYQrWdLusHbOFTyeMNwRBw5Y1dHKlXYDm4hVN6Wk\nWD9IY8fCOefAgAE2/X332T0So0ZlvMv5ssvyPn7nXHR5s1p3xGOPWVcXycn2cJzERCstLF9uz3W4\n4gp48EHr3mLYMHtYzwMPwDXXxDpy51xe8K5BHABffWVPaOvXzxJBZrZvt6609+61nlU7drQnsRX3\ncqpzBVZOugbxEoYjKcnucWjWzJ7nkJXKla257LZtcMIJdj3Dk4VzRYf/3Iu4ffvshrstW6y0ULZs\n9tO3bg0//2yd8FWrlichOufyCU8YRci+ffbsh1Arp2++seavv/9uN9C1aBHZciKdzjlXuHiVVBGw\nbJmVIipUsGc7t21rd11fcIElj6lT4a67Yh2lcy6/8xJGIbZvn90s9+GHdv9Dnz7W/ffixVaqeOQR\ne9xoVs+AcM65cJ4wCrFBg+CDD+Dvf7fmsLVrxzoi51xB5lVShUBiot0jsWBB6rDff4d//9vukfjP\nfzxZOOeOX1QThoh0E5GlIrJCRB7OZHwVEZkgIgtEZJaInB427l4RWSgii0RkQDTjLOjeecc6+bvo\nIrtLG+y51CVKZN9M1jnnciJqCUNE4oAhQHegOdBLRJqnm+xRYJ6qngncCLwSzHs6cDvQFmgBXCoi\n3gNRJlRhzBg4/XTr26lrV0sgn31mz5qoUyfWETrnCotoljDaAitUdaWqHgRGAz3STdMcmAqgqr8B\nDUWkFtAM+FlV96pqMjAduCqKsRZYv/4Kv/1mDxuaPBk2bLDuPJo1s1KGc87llmgmjDrAmrD3icGw\ncPMJEoGItAUaAHWBhUBHEakmImWBi4F6ma1ERPqISIKIJCQlJeXyJuR/Y8bYk+r+8hfrIHD8eGjY\n0LoaL1Ei1tE55wqTWLeSGgS8IiLzgF+BX4DDqrpERP4NfAnsAeYBhzNbgKoOBYaC9SWVJ1HnE6Hq\nqPPPtzuvwaqkVq2KbVzOucIpmiWMtaQtFdQNhh2hqjtVtbeqtsSuYdQAVgbj3lXVNqp6LrANWBbF\nWAukuXOtNdTVV8c6EudcURDNhDEbaCIijUSkJHANMCl8AhGpHIwDuA2Yoao7g3E1g7/1sWqrkVGM\ntUAaM8Y6/0v/kCLnnIuGqFVJqWqyiNwFfAHEAcNUdZGI9A3Gv4ld3H5fRBRYBIQ97ZmPRaQacAjo\nr6rboxVrQaRqDzTq2hWqVo11NM65oiCq1zBUdTIwOd2wN8P+/xE4JYt5O0YztoJi82YYMcJaPbVp\nY31BTZsGI0fCH3/AM8/EOkLnXFER64veLhspKdCrlz0mNaR0adi/356f3bs3/PWvsYvPOVe0eMLI\nx1580ZJI1wISAAAZ1ElEQVTFK6/YjXlz5sCaNdbLbNeuljyccy6veMLIp2bNsmds9+wJd99t3ZCf\nf36so3LOFWXe+WA+tHMnXHstnHgiDB2a+sAj55yLJS9h5DNr10KPHnbz3fTpUKVKrCNyzjnjJYx8\nJCHBnoa3dClMnAgdOsQ6IuecS+UljHxi2jS45BKoWRN++AHOOCPWETnnXFqeMPKBAwfs8an16sHM\nmZY0nHMuv/GEkQ+89hqsWAFTpniycM7lX34NI8Y2bbK7tS++GLp1i3U0zjmXNU8YMfbEE7B3L7z0\nUqwjcc657HnCiKH58+1xqnfdBaeeGutonHMue54wYuixx6ByZXjyyVhH4pxzR+cJI0Zmz4bPPoMH\nHvCb85xzBYMnjBgZONCeY3HXXbGOxDnnIuMJIwZmzUotXVSoEOtonHMuMp4wYsBLF865gsgTRh6b\nNQsmT/bShXOu4PGEkYdUrWVUtWpeunDOFTzeNUge+uILe4Leyy976cI5V/B4CSOPHD4MDz4IjRtD\nv36xjsY553LOSxh55L33YOFCGDsWSpaMdTTOOZdzXsLIA3v2WJ9RZ59tz+h2zrmCyEsYeeCVV2D9\nehg3zp/P7ZwruLyEEWUHD8Krr0L37tCuXayjcc65Y+cJI8rGjYMNG+Cee2IdiXPOHR9PGFH26qvQ\npAl07RrrSJxz7vh4woii2bPhp5/g7ruhmO9p51wB54exKHr1VShfHm66KdaROOfc8fOEESUbN8KY\nMXDzzVCxYqyjcc654+cJI0refttaSHmfUc65wsITRhSowvDhcP75/qxu51zh4QkjCn7+GVauhOuv\nj3UkzjmXezxhRMGIEVCqFFx1Vawjcc653OMJI5cdOmQXuy+7DCpVinU0zjmXezxh5LKvv4akJLju\nulhH4pxzucsTRi4bMQIqV7a+o5xzrjCJasIQkW4islREVojIw5mMryIiE0RkgYjMEpHTw8bdJyKL\nRGShiIwSkdLRjDU37NkDEyfCX/9q1zCcc64wiVrCEJE4YAjQHWgO9BKR5ukmexSYp6pnAjcCrwTz\n1gHuAeJV9XQgDrgmWrHmlkmTLGl4dZRzrjCKZgmjLbBCVVeq6kFgNNAj3TTNgakAqvob0FBEagXj\nigNlRKQ4UBZYF8VYc8XYsVC3LnTsGOtInHMu90UzYdQB1oS9TwyGhZsPXAUgIm2BBkBdVV0LvAj8\nCawHdqjql5mtRET6iEiCiCQkJSXl8iZELiUFpk+Hbt28o0HnXOEU60PbIKCyiMwD7gZ+AQ6LSBWs\nNNIIOBEoJyKZ3ganqkNVNV5V42vUqJFXcWewYAFs2wbnnRezEJxzLqqi+YjWtUC9sPd1g2FHqOpO\noDeAiAiwClgJXASsUtWkYNx4oB3wYRTjPS7Tp9tfTxjOucIqmiWM2UATEWkkIiWxi9aTwicQkcrB\nOIDbgBlBEvkTOFtEygaJpAuwJIqxHrfp06FRI6hX7+jTOudcQRS1EoaqJovIXcAXWCunYaq6SET6\nBuPfBJoB74uIAouAW4NxP4vIOGAukIxVVQ2NVqzHKyUFZsyAyy+PdSTOORc9ESUMEbkSmKqqO4L3\nlYFOqjoxu/lUdTIwOd2wN8P+/xE4JYt5nwKeiiS+WFu8GLZs8eoo51zhFmmV1FOhZAGgqtspIAfz\nvPDtt/bXE4ZzrjCLNGFkNl00L5gXKNOnQ/360LBhrCNxzrnoiTRhJIjISyLSOHi9BMyJZmAFhapd\nv/DShXOusIs0YdwNHATGYHds7wf6RyuoguS332DTJujUKdaROOdcdEVUraSqe4AMnQc6v37hnCs6\nIiphiMhXQcuo0PsqIvJF9MIqOL79FurUgZNOinUkzjkXXZFWSVUPWkYBoKrbgJrRCang2LcPJk+2\nZ1+IxDoa55yLrkgTRoqI1A+9EZGGgEYjoILk009h92649tpYR+Kcc9EXadPYx4DvRGQ6IEBHoE/U\noiogRo6EE06Ac8+NdSTOORd9EZUwVPVzIB5YCowC7gf2RTGufG/bNquOuuYaiIuLdTTOORd9kXYN\nchtwL9bj7DzgbOBH4PzohZa/jR8PBw96dZRzruiI9BrGvcBZwB+q2hloBWzPfpbCbdQoaNIE2rSJ\ndSTOOZc3Ik0Y+1V1P4CIlAoep3pq9MLK39avh6lTrXThraOcc0VFpBe9E4P7MCYCX4nINuCP6IWV\nv40ZY12C9OoV60iccy7vRHqn95XBv0+LyDSgEvB51KLK58aNg1at4NQiW8ZyzhVFOe5xVlWnRyOQ\nguLQIZgzB+68M9aROOdc3ormI1oLpYULYf9+OOusWEfinHN5yxNGDs2ebX89YTjnihpPGDk0ezZU\nreqdDTrnih5PGDk0ezbEx3tzWudc0eMJIwf27rVrGF4d5Zwrijxh5MC8eXD4sCcM51zR5AkjB/yC\nt3OuKPOEkQOzZ8OJJ9rLOeeKGk8YOTBrlpcunHNFlyeMCG3fDsuXe8JwzhVdnjAilJBgfz1hOOeK\nKk8YEQpd8I6Pj20czjkXK54wIjR7NjRubHd5O+dcUeQJIwJ798K0adC+fawjcc652PGEEYHRo+2i\n9623xjoS55yLHU8YR6EKQ4bAaadBx46xjsY552LHE8ZRzJ4Nc+faA5O8w0HnXFHmCeMoXn8dypeH\n66+PdSTOORdbnjCysWWLXb+44QaoWDHW0TjnXGx5wsjG8OFw4AD06xfrSJxzLvaimjBEpJuILBWR\nFSLycCbjq4jIBBFZICKzROT0YPipIjIv7LVTRAZEM9bMvPcedOgAZ5yR12t2zrn8J2oJQ0TigCFA\nd6A50EtEmqeb7FFgnqqeCdwIvAKgqktVtaWqtgTaAHuBCdGKNTMHD8KSJdCpU16u1Tnn8q9oljDa\nAitUdaWqHgRGAz3STdMcmAqgqr8BDUWkVrppugC/q+ofUYw1g5UrISUFTjklL9fqnHP5VzQTRh1g\nTdj7xGBYuPnAVQAi0hZoANRNN801wKgoxZilZcvsrycM55wzsb7oPQioLCLzgLuBX4DDoZEiUhK4\nHPgoqwWISB8RSRCRhKSkpFwLLJQwmjTJtUU651yBVjyKy14L1At7XzcYdoSq7gR6A4iIAKuAlWGT\ndAfmqurGrFaiqkOBoQDx8fGaK5Fjz76oXt07G3TOuZBoljBmA01EpFFQUrgGmBQ+gYhUDsYB3AbM\nCJJISC9iUB0FVsLw6ijnnEsVtYShqsnAXcAXwBJgrKouEpG+ItI3mKwZsFBElmKliXtD84tIOeBC\nYHy0YsyOJwznnEsrmlVSqOpkYHK6YW+G/f8jkOlhWVX3ANWiGV9Wdu+Gdes8YTjnXLhYX/TOl5Yv\nt7+eMJxzLpUnjEx4k1rnnMvIE0YmQgnj5JNjG4dzzuUnnjAysWwZ1K8PZcrEOhLnnMs/PGFkwltI\nOedcRp4w0lH1hOGcc5nxhJHO5s2wfbsnDOecS88TRjreQso55zLnCSMdTxjOOZc5TxjpLFsGJUpA\ngwaxjsQ55/IXTxjpLFsGjRtD8ah2muKccwWPJ4x0vIWUc85lzhNGOn/+6dVRzjmXGU8YYQ4fhp07\n/aFJzjmXGU8YYXbssL9VqsQ2Duecy488YYTZts3+Vq4c2ziccy4/8oQRZvt2++slDOecy8gTRphQ\nCcMThnPOZeQJI4xXSTnnXNY8YYTxKinnnMuaJ4wwXiXlnHNZ84QRZts26xKkbNlYR+Kcc/mPJ4ww\n27db6UIk1pE451z+4wkjzLZtXh3lnHNZ8YQRZts2byHlnHNZ8YQRJlQl5ZxzLiNPGGG8Sso557Lm\nCSOMV0k551zWPGEEVL1KyjnnsuMJI7BnDyQne8JwzrmseMIIeD9SzjmXveKxDiC/8H6knMs/Dh06\nRGJiIvv37491KIVG6dKlqVu3LiVKlDjmZXjCCHg/Us7lH4mJiVSoUIGGDRsi3vXCcVNVtmzZQmJi\nIo0aNTrm5XiVVMCrpJzLP/bv30+1atU8WeQSEaFatWrHXWLzhBHwKinn8hdPFrkrN/anJ4yAV0k5\n51z2PGEEQgmjYsXYxuGci70tW7bQsmVLWrZsSe3atalTp86R9wcPHoxoGb1792bp0qXZTjNkyBBG\njBiRGyHniahe9BaRbsArQBzwjqoOSje+CjAMaAzsB25R1YXBuMrAO8DpgAbjfoxWrNu3Q6VKEBcX\nrTU45wqKatWqMW/ePACefvppypcvzwMPPJBmGlVFVSlWLPPz7uHDhx91Pf379z/+YPNQ1BKGiMQB\nQ4ALgURgtohMUtXFYZM9CsxT1StFpGkwfZdg3CvA56raU0RKAlF9rJH3I+Vc/jRgAATH7lzTsiW8\n/HLO51uxYgWXX345rVq14pdffuGrr75i4MCBzJ07l3379nH11Vfz5JNPAtChQwdee+01Tj/9dKpX\nr07fvn2ZMmUKZcuW5ZNPPqFmzZo8/vjjVK9enQEDBtChQwc6dOjA1KlT2bFjB8OHD6ddu3bs2bOH\nG2+8kSVLltC8eXNWr17NO++8Q8uWLXN3p0QgmlVSbYEVqrpSVQ8Co4Ee6aZpDkwFUNXfgIYiUktE\nKgHnAu8G4w6q6vYoxur9SDnnIvLbb79x3333sXjxYurUqcOgQYNISEhg/vz5fPXVVyxevDjDPDt2\n7OC8885j/vz5nHPOOQwbNizTZasqs2bN4oUXXuCZZ54B4NVXX6V27dosXryYJ554gl9++SWq25ed\naFZJ1QHWhL1PBP4n3TTzgauAmSLSFmgA1AUOA0nAcBFpAcwB7lXVPdEK1vuRci5/OpaSQDQ1btyY\n+Pj4I+9HjRrFu+++S3JyMuvWrWPx4sU0b948zTxlypShe/fuALRp04aZM2dmuuyrrrrqyDSrV68G\n4LvvvuOhhx4CoEWLFpx22mm5vUkRi/VF70FAZRGZB9wN/IIli+JAa+ANVW0F7AEezmwBItJHRBJE\nJCEpKemYA/EqKedcJMqVK3fk/+XLl/PKK68wdepUFixYQLdu3TK916FkyZJH/o+LiyM5OTnTZZcq\nVeqo08RSNBPGWqBe2Pu6wbAjVHWnqvZW1ZbAjUANYCVWGklU1Z+DScdhCSQDVR2qqvGqGl+jRo1j\nDtarpJxzObVz504qVKhAxYoVWb9+PV988UWur6N9+/aMHTsWgF9//TXTKq+8Es0qqdlAExFphCWK\na4BrwycIWkLtDa5x3AbMUNWdwE4RWSMip6rqUuxCeFT3kldJOedyqnXr1jRv3pymTZvSoEED2rdv\nn+vruPvuu7nxxhtp3rz5kVelSpVyfT2REFWN3sJFLgZexprVDlPV50SkL4Cqviki5wDvY81mFwG3\nquq2YN6WWLPaklipo3doXFbi4+M1ISEhx3EePAilSsGzz8Jjj+V4dudcLluyZAnNmjWLdRj5QnJy\nMsnJyZQuXZrly5fTtWtXli9fTvHiOT/fz2y/isgcVY3PYpY0onofhqpOBianG/Zm2P8/AqdkMe88\nIKKNOF7ej5RzLr/avXs3Xbp0ITk5GVXlrbfeOqZkkRu8t1q8HynnXP5VuXJl5syZE+swgNi3ksoX\nvB8p55w7Ok8YeJWUc85FwhMGXiXlnHOR8ISBV0k551wkPGHgVVLOubQ6d+6c4Sa8l19+mX79+mU5\nT/ny5QFYt24dPXv2zHSaTp06cbSm/y+//DJ79+498v7iiy9m+/aodqUXMU8YWJVUmTJ2L4ZzzvXq\n1YvRo0enGTZ69Gh69ep11HlPPPFExo0bd8zrTp8wJk+eTOV8cjbrzWrxfqScy9di0L95z549efzx\nxzl48CAlS5Zk9erVrFu3jlatWtGlSxe2bdvGoUOHePbZZ+nRI20n3KtXr+bSSy9l4cKF7Nu3j969\nezN//nyaNm3Kvn37jkzXr18/Zs+ezb59++jZsycDBw5k8ODBrFu3js6dO1O9enWmTZtGw4YNSUhI\noHr16rz00ktHerq97bbbGDBgAKtXr6Z79+506NCBH374gTp16vDJJ59QpkyZ3N1neAkD8H6knHNp\nVa1albZt2zJlyhTAShd/+9vfKFOmDBMmTGDu3LlMmzaN+++/n+x6y3jjjTcoW7YsS5YsYeDAgWnu\np3juuedISEhgwYIFTJ8+nQULFnDPPfdw4oknMm3aNKZNm5ZmWXPmzGH48OH8/PPP/PTTT7z99ttH\nujpfvnw5/fv3Z9GiRVSuXJmPP/44CnvFSxiA9yPlXL4Wo/7NQ9VSPXr0YPTo0bz77ruoKo8++igz\nZsygWLFirF27lo0bN1K7du1MlzFjxgzuueceAM4880zOPPPMI+PGjh3L0KFDSU5OZv369SxevDjN\n+PS+++47rrzyyiO95V511VXMnDmTyy+/nEaNGh15oFJ41+i5zUsYeJWUcy6jHj168M033zB37lz2\n7t1LmzZtGDFiBElJScyZM4d58+ZRq1atTLszP5pVq1bx4osv8s0337BgwQIuueSSY1pOSKmwC7DR\n7BrdEwZeJeWcy6h8+fJ07tyZW2655cjF7h07dlCzZk1KlCjBtGnT+OOPP7JdxrnnnsvIkSMBWLhw\nIQsWLACsW/Ry5cpRqVIlNm7ceKTqC6BChQrs2rUrw7I6duzIxIkT2bt3L3v27GHChAl07NgxtzY3\nIl4lhVdJOecy16tXL6688sojLaauu+46LrvsMs444wzi4+Np2rRptvP369eP3r1706xZM5o1a0ab\nNm0Ae3Jeq1ataNq0KfXq1UvTLXqfPn3o1q3bkWsZIa1bt+bmm2+mbdu2gF30btWqVdSqnzIT1e7N\n89qxdG+uCjfcAN26wfXXRykw51yOePfm0ZGvuzcvCETgww9jHYVzzuV/fg3DOedcRDxhOOfypcJU\nXZ4f5Mb+9IThnMt3SpcuzZYtWzxp5BJVZcuWLZQuXfq4llPkr2E45/KfunXrkpiYSFJSUqxDKTRK\nly5N3bp1j2sZnjCcc/lOiRIlaNSoUazDcOl4lZRzzrmIeMJwzjkXEU8YzjnnIlKo7vQWkSQg+85d\nslYd2JyL4RQEvs2FX1HbXvBtzqkGqlojkgkLVcI4HiKSEOnt8YWFb3PhV9S2F3ybo8mrpJxzzkXE\nE4ZzzrmIeMJINTTWAcSAb3PhV9S2F3ybo8avYTjnnIuIlzCcc85FxBOGc865iBT5hCEi3URkqYis\nEJGHYx1PNIhIPRGZJiKLRWSRiNwbDK8qIl+JyPLgb6F7UK2IxInILyLyafC+UG+ziFQWkXEi8puI\nLBGRc4rANt8XfK8XisgoESld2LZZRIaJyCYRWRg2LMttFJFHgmPaUhG5KLfiKNIJQ0TigCFAd6A5\n0EtEmsc2qqhIBu5X1ebA2UD/YDsfBr5R1SbAN8H7wuZeYEnY+8K+za8An6tqU6AFtu2FdptFpA5w\nDxCvqqcDccA1FL5tfg/olm5YptsY/LavAU4L5nk9ONYdtyKdMIC2wApVXamqB4HRQI8Yx5TrVHW9\nqs4N/t+FHUTqYNv6fjDZ+8AVsYkwOkSkLnAJ8E7Y4EK7zSJSCTgXeBdAVQ+q6nYK8TYHigNlRKQ4\nUBZYRyHbZlWdAWxNNzirbewBjFbVA6q6CliBHeuOW1FPGHWANWHvE4NhhZaINARaAT8DtVR1fTBq\nA1ArRmFFy8vAP4CUsGGFeZsbAUnA8KAa7h0RKUch3mZVXQu8CPwJrAd2qOqXFOJtDpPVNkbtuFbU\nE0aRIiLlgY+BAaq6M3ycWvvqQtPGWkQuBTap6pyspils24ydabcG3lDVVsAe0lXFFLZtDurte2DJ\n8kSgnIhcHz5NYdvmzOTVNhb1hLEWqBf2vm4wrNARkRJYshihquODwRtF5IRg/AnApljFFwXtgctF\nZDVW1Xi+iHxI4d7mRCBRVX8O3o/DEkhh3uYLgFWqmqSqh4DxQDsK9zaHZLWNUTuuFfWEMRtoIiKN\nRKQkdqFoUoxjynUiIli99hJVfSls1CTgpuD/m4BP8jq2aFHVR1S1rqo2xD7Xqap6PYV7mzcAa0Tk\n1GBQF2AxhXibsaqos0WkbPA974JdoyvM2xyS1TZOAq4RkVIi0ghoAszKjRUW+Tu9ReRirK47Dhim\nqs/FOKRcJyIdgJnAr6TW5z+KXccYC9THuoX/m6qmv7BW4IlIJ+ABVb1URKpRiLdZRFpiF/lLAiuB\n3tiJYWHe5oHA1VhrwF+A24DyFKJtFpFRQCesG/ONwFPARLLYRhF5DLgF2ycDVHVKrsRR1BOGc865\nyBT1KinnnHMR8oThnHMuIp4wnHPORcQThnPOuYh4wnDOORcRTxjO5QMi0inUo65z+ZUnDOeccxHx\nhOFcDojI9SIyS0TmichbwfM2dovI/wbPZPhGRGoE07YUkZ9EZIGITAg9r0BEThaRr0VkvojMFZHG\nweLLhz3LYkRw57Jz+YYnDOciJCLNsDuK26tqS+AwcB1QDkhQ1dOA6dhduAAfAA+p6pnYXfah4SOA\nIaraAuv3KNTjaCtgAPZslpOw/rCcyzeKxzoA5wqQLkAbYHZw8l8G6/AtBRgTTPMhMD54NkVlVZ0e\nDH8f+EhEKgB1VHUCgKruBwiWN0tVE4P384CGwHfR3yznIuMJw7nICfC+qj6SZqDIE+mmO9b+dg6E\n/X8Y/326fMarpJyL3DdATxGpCUeeqdwA+x31DKa5FvhOVXcA20SkYzD8BmB68MTDRBG5IlhGKREp\nm6db4dwx8jMY5yKkqotF5HHgSxEpBhwC+mMPKmobjNuEXecA63L6zSAhhHqOBUseb4nIM8Ey/pqH\nm+HcMfPeap07TiKyW1XLxzoO56LNq6Scc85FxEsYzjnnIuIlDOeccxHxhOGccy4injCcc85FxBOG\nc865iHjCcM45F5H/Dyx/4B4u0XC1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb6242ee400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOOeci8v/B3SYbdQr32keAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb724863c50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de7A7huePm_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score,precision_recall_curve\n",
        "from sklearn.utils.fixes import signature\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezsu4H3XPm_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdfyKDQoPm_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'e-res/best_model.hdf5'\n",
        "criticality_network_load = load_model(path) #<----- The Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToHgXK2dPm_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_target_test_y = np.load('e-res/target_test_y.npy')\n",
        "np_corpora_test_x = np.load('e-res/corpora_test_x.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnZiM2L1Pm_a",
        "colab_type": "code",
        "colab": {},
        "outputId": "16c1965d-eb8a-450d-e7cb-7b70ef24cf16"
      },
      "source": [
        "score = criticality_network_load.evaluate(np_corpora_test_x, np_target_test_y, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 3s 247us/sample - loss: 0.1313 - accuracy: 0.9736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDyfzjdUPm_f",
        "colab_type": "code",
        "colab": {},
        "outputId": "120b5fd8-ca7b-4215-acce-41afd32c6bf6"
      },
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.13130904127952253\n",
            "Test accuracy: 0.9735679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn8p7tZrPm_h",
        "colab_type": "code",
        "colab": {},
        "outputId": "fa18f5c2-9cf5-4ec5-9685-c5ea78e3a802"
      },
      "source": [
        "history_predict = criticality_network_load.predict(x=np_corpora_test_x)\n",
        "history_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 9.7539722e-17],\n",
              "       [9.3283859e-07, 9.9999905e-01],\n",
              "       [1.0000000e+00, 2.0519539e-29],\n",
              "       ...,\n",
              "       [2.1023639e-04, 9.9978977e-01],\n",
              "       [9.9999917e-01, 7.8283227e-07],\n",
              "       [5.1913088e-07, 9.9999952e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANDvy-SGPm_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inferred_data = pd.DataFrame(history_predict,columns=list('AB'))\n",
        "target_data = pd.DataFrame(np_target_test_y,columns=list('LN'))\n",
        "data = target_data.join(inferred_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOm2BcLvPm_n",
        "colab_type": "code",
        "colab": {},
        "outputId": "cdb86d26-9b8a-46d5-8365-1d17ae605bd6"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>L</th>\n",
              "      <th>N</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.753972e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.328386e-07</td>\n",
              "      <td>9.999990e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.051954e-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.231208e-04</td>\n",
              "      <td>9.998769e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.948549e-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   L  N             A             B\n",
              "0  1  0  1.000000e+00  9.753972e-17\n",
              "1  0  1  9.328386e-07  9.999990e-01\n",
              "2  1  0  1.000000e+00  2.051954e-29\n",
              "3  0  1  1.231208e-04  9.998769e-01\n",
              "4  1  0  1.000000e+00  3.948549e-15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUC2y8_iPm_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = list(data['L'])\n",
        "y_score= list(data['A'])\n",
        "average_precision = average_precision_score(y_true, y_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xpv2lrdPm_t",
        "colab_type": "code",
        "colab": {},
        "outputId": "ceb25fad-32e8-4d3b-8be6-f92a736bf553"
      },
      "source": [
        "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average precision-recall score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJgJykCkPm_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_true, y_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rppc6pmrPm_y",
        "colab_type": "code",
        "colab": {},
        "outputId": "50660c68-a5ab-46c7-ae59-47cc4d4259b0"
      },
      "source": [
        "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.text.Text at 0x7fb5b4192208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHcVJREFUeJzt3XucXGWd5/HPN93pXEggSLiGQCIXCQyXgQg64yCKAmFV\nHAYVRBRGjawyg6+Xjri7swI6jDqOMzKLGLPAooJmABmNGkAUBV1kTFi5BQQjtySgQCBALiTp5Ld/\nPE/RRaX7VHV1ne7qyvf9etWrq845depXp7vrW+d5znmOIgIzM7OBjBnpAszMrL05KMzMrJCDwszM\nCjkozMyskIPCzMwKOSjMzKyQg2KUk3SmpF+OdB2tJmmppGPqLLOXpDWSuoaprNJJelTSW/L9CyRd\nNdI1mTkoRoCkcZIul/SYpBcl3SVpzkjX1Yj8QbY+f0D/UdKVkia1+nUi4qCI+HmdZR6PiEkRsbnV\nr58/pDfl97la0u2SXt/q19lW5L+TXkm710wf8naWtLukhZKekBSSZtRZfoakn0laJ+m3lWCumv/e\n/L+5VtL3JL1qMPV0IgfFyOgGlgNvBHYA/h64pt4feBt5e0RMAg4HZpPqfwUlo/3v69/z+5wK/Ay4\ndoTraTlJ3cPwGtsBfwU8D7yvn0Uq23ln4JfA9ZI0iJfYAtyYX6MR3wF+A+wE/A/gOkk751oPAr4O\nnAHsCqwDLh1ELR1ptP8jj0oRsTYiLoiIRyNiS0T8EHgEOGKg50iaLul6SU9LWiXpkgGWu1jSckkv\nSLpT0l9UzTtS0pI874+S/iVPHy/pqrze1ZIWS9q1gfexErgB+JO8np9LukjS/yX9g71a0g557+lJ\nSSsl/UN1U5GkD0t6IO9Z3S/p8Dy9uglmoLpn5G+Q3fnxHvmb5bOSlkn6cNXrXCDpGknfzK+1VNLs\neu8xv89e4GpgWuUDJa/zbXlvsPJN+JCqef3+viTtI+mWPO0ZSVdLmtJIHbUknZRf/wVJv5d0Qu22\nq3rvV9Vssw9Kehy4RdINks6pWffdkk7O9w+QdHPerg9KevcgS/0rYDXwWeADAy0UEZuAbwC7kT7E\nGxIRf4yIS4HF9ZaVtD/pC875EbE+Ir4L3ENfyJwO/CAibouINcD/BE6WNLnRejqRg6IN5A/l/YGl\nA8zvAn4IPAbMAKYBCwZY3WLgMOBVwLeBayWNz/MuBi6OiO2BfYBr8vQPkPZsppP+Qc8G1jdQ93Tg\nRNK3s4ozgLnA5FzvlUAvsC/wp8BxwIfy898FXAC8H9geeAewqp+XGqjuWguAFcAewCnAP0p6c9X8\nd+RlpgALgX7Dtp/32ZNrXAU8l6f9KXAF8BHSNvs6sFCpWbHo9yXg87nGWaRtfkEjddTUdCTwTeDv\n8vs5Gnh0EKt4Y37940nfsE+rWveBwN7Aj/LewM2kv6VdgFOBS/MylWaae+q81gfyaywADpDU7xci\nSeOAM4HlEfGMpDfkEB7o9oZBvN+Kg4CHI+LFqml35+mV+XdXZkTE74ENpP/PbVdE+DaCN2As8BPg\n6wXLvB54GujuZ96ZwC8LnvsccGi+fxtwITC1Zpm/Bm4HDmmg3keBNaRviI+Rdssn5Hk/Bz5bteyu\npH+yCVXTTgN+lu/fBJxb8DpvqVP3DCBITXnTgc3A5Kr5nweuzPcvAH5SNe9AYH3B+7wA2Jjf52ZS\nSBxTNf9rwOdqnvMg6QN4wN9XP6/zTuA3A7zvC4CrBnje14F/rbftatdTtc1eXTV/MrAW2Ds/vgi4\nIt9/D/CLfl77/Ab/vvciNQ0dVvU7v3iA7fwUcAtwRJP/S935vc0oWOYM4I6aaRdV/Z38FDi7Zv7K\n6t/9tnjzHsUIUmrD/xbpH+Wcquk3KHXurZF0OulD8LFITSD11vnJ3JTzvKTVpD2FqXn2B0nfjH6b\nm5felqd/i/QPvECpQ/CfJI0teJl3RsSUiNg7Ij4aEdV7H8ur7u9NCsInK98CSR8yu+T504Hf13tP\nBXVX2wN4Nl75TfEx0rf5ij9U3V8HjJfULen0qu19Q9Uy10TEFFLg3ccrmwb3Bj5R/Q03v589KPh9\nSdpV0oLcDPcCcBV9v5/BaHTbDeTl31PeZj8i7S1ACvOr8/29gaNq3ufppOahRpwBPBARd+XHVwPv\nrfn7uib/Pe0SEW+OiDubfE+NWEPae622A/Big/O3SaV3ZFn/JAm4nPQhdGKk9lkAImJOzbKvB/aS\n1F0UFkr9EZ8CjgWWRsQWSc+RmjuIiN8Bp+WAOpnUibdTRKwlfWO/UKlDfRHp2/HlTby16uGIl5P2\nKKYOUPdyUlNS8QoHqLtmsSeAV0maXBUWe5G+DdZb/9X0fTD2N/8ZSXOBJZK+HRFP5tovioiLapev\n8/v6R9I2OjginpX0ThpsAqtRtO3WAhOrHvf3oV47bPR3gPMl3QaMJ3XeV17n1oh4axM1Qmqy20tS\nJaS7SU11JwLfL3pi/nu+oWCRORHxi0HWs5TUd1b9d3Iofb//pflxpYZ9gB7goUG+TkfxHsXI+Rqp\njfjtNd/I+/Nr4EngC5K2U+p8/vN+lptM6g94GuiW9Bmqvh1Jep+knSNiC2lXH2CLpDdJOji3rb8A\nbCI1FwxJ/kD9MfBlSdtLGpM7c9+YF7kM+KSkI5TsK2nv2vUMVHfNay0nNZ99Pm+fQ0h7Ii05DyEi\nHiTtdX0qT/rfwNmSjsq1byfpv+ROz6Lf12TSt9bnJU0j9TE043LgLEnH5u06TdIBed5dwKmSxip1\n2J/SwPoWkfYePks6CqmyfX8I7C/pjLy+sZJeK2lWvRXmwNwHOJLUb3YY6cCHb5MCpFBE/CLS4c8D\n3V4OCaV+uHH54Tj19cvVrvMh0vY5P/9eTgYOBr6bF7kaeLukv8j9M58Drq/ZU93mOChGQP4w/Ajp\nH+cPNc1MW4l0nsDbSR3Cj5M6bN/Tz6I3kQ4TfIjU7PISr2wKOgFYKmkNqYP41BxSuwHXkULiAeBW\nUnNUK7yf9I3sflJ/yXXA7vl9XUtqH/42adf+e6RO+FoD1V3rNFIb/BPAf5Da0X/SovcB8CVgrqRd\nImIJ8GHS3sBzwDJSf1G939eFpKNunic191zfTCER8WvgLOBf87puJX3QQzpSZ59c14Wk7VtvfRty\nLW+pXj5/QB5HapZ6gtR890Xyh3Jutuv3IAxSJ/b3I+LeiPhD5Ub6Hb5NrT0/YT0pgAF+S9XBGJLm\nSZpXteyppMO6nyP1Y50SEU8DRMRS0sEcV5P6TLYDPtrCOkclRfjCRWZmNjDvUZiZWSEHhZmZFXJQ\nmJlZIQeFmZkVGnXnUUydOjVmzJgx0mWYmY0qd9555zMRsXP9Jbc26oJixowZLFmyZKTLMDMbVSQ9\n1uxz3fRkZmaFHBRmZlbIQWFmZoUcFGZmVshBYWZmhRwUZmZWqLSgkHSFpKck3TfAfEn6N6VrG9+j\nfK1kMzNrL2XuUVxJGh56IHOA/fJtLun6DGZm1mZKO+EuIm7LV0sbyEnANyONc36HpCmSds8XuxnQ\niy/CXXeB1MJi29y29F5t+Pjvqlxj8tfwjRth0qRXbm8Jenth/HjYvBnGjYMtW2CHHfqeN348dLfJ\nKdEjWcY0XnlRnRV52lZBkS9DORdg6tSZ3Hln38a0cvgyJWbN27wZurpgU77AcVfXK/+nNm6Enp4U\nFmPGpODo7k7LVR5X7L47bL99mj5tGkyZkkJkOLVJXhWLiPnAfIBZs2bHAQcM/4YyM2vWln4uLLx5\nc7qtXw9r18JTT6XlNm+Gl15KIbJlCzz9dAqJsWPTnkdPD0ycCIcfDjNnDk/9IxkUK4HpVY/3zNPM\nzDpKfy0glQ//8eNhxx1hzz2L1/Hcc/DII/DHP6bnPvssTJgABx8MBx1UbjPVSAbFQuAcSQuAo4Dn\n6/VPmJltq3bcMd0g7WncfHPaw1izBu65B04+GbbbrpzXLi0oJH0HOAaYKmkFcD4wFiAi5gGLgBNJ\nF6VfR7pQvJmZ1TFmDBx/fGqmuummdJDPddfBu9+d9jJarcyjnk6rMz+Aj5X1+mZmna6rC048EX73\nO3j00RQWZ5zR+tfxsUNmZqPcvvumI6zWrUud4q3moDAzG+UkOPpoWLUKbryx9et3UJiZdYBJk9Jh\ns6tXpz6LVnJQmJl1iFmz0nkZt9/e2vU6KMzMOsROO6WzvlvdT+GgMDPrEBLssUc6t+Kll1q3XgeF\nmVkH2W03eOEFuOWW1q3TQWFm1kF22SU1P/3hD61bp4PCzKyDVEaZXbcuDTbYknW2ZjVmZtYudt89\nhcTdd7dmfQ4KM7MOM2lSOlN7ZYvG43ZQmJl1mIkT0xDmGze2Zn0OCjOzDrTrrqmfohUcFGZmHWj8\n+HT51VZc1thBYWbWgSZMSCHR32VYB8tBYWbWgaTWnZ3toDAz60CVPYkNG4a+LgeFmVkH6umB3t50\nGyoHhZlZB4pI19RuxZFPDgozsw40bhx0d7dmXQ4KM7MONGZM6sxetqwF6xr6KszMrN10d0NXVzpD\ne6gcFGZmHairq3XDjTsozMw60Lhx6WcrxntyUJiZdSAJZs50UJiZWR2tOPLJQWFm1qEi4Nlnh74e\nB4WZWYfq6UlNT0MdxsNBYWbWocaPT2dnOyjMzKxfPT3p1tU1tPU4KMzMOpSU9iaGOjCgg8LMrENt\n3pxuq1YNbT2lBoWkEyQ9KGmZpE/3M38HST+QdLekpZLOKrMeM7NtSaWPQhraekoLCkldwFeBOcCB\nwGmSDqxZ7GPA/RFxKHAM8GVJPWXVZGa2rZk4MQ0QOBRl7lEcCSyLiIcjYiOwADipZpkAJksSMAl4\nFmjBZTbMzEyCNWtg9eqhrafMoJgGLK96vCJPq3YJMAt4ArgXODcitroUuKS5kpZIWrJ69dNl1Wtm\n1lG6utJJd23dR9GA44G7gD2Aw4BLJG1fu1BEzI+I2RExe8qUnYe7RjOzUam7u++SqENRZlCsBKZX\nPd4zT6t2FnB9JMuAR4ADSqzJzGybMWZM6qNo5/MoFgP7SZqZO6hPBRbWLPM4cCyApF2B1wAPl1iT\nmdk2Y8yYdM3s9euHtp4WXVF1axHRK+kc4CagC7giIpZKOjvPnwd8DrhS0r2AgPMi4pmyajIz25ZI\nMGVKOkx2KEoLCoCIWAQsqpk2r+r+E8BxZdZgZratGur5ExUj3ZltZmYlqQSFBwU0M7N+SbBp09D7\nKBwUZmYdbMKEofdROCjMzKyQg8LMrIO1okPbQWFmZoUcFGZmVshBYWbWwaQ0MOBQOCjMzKyQg8LM\nrINFwPPPD20dDgozsw62aRNs2eoqP4PjoDAz62CTJ8NLLw1tHQ4KM7MONnFi2qtIA3Q3x0FhZtbB\nxox5+Qp3TSeFg8LMrINt2VLpo+hq+vPeQWFm1sHGjq2cR9H82RQOCjOzDjdu3NCe76AwM7NCDgoz\nsw7m0WPNzKwuj/VkZmalclCYmVkhB4WZWQdzH4WZmZXOQWFm1uHyoIAewsPMzLYmVcZ6Gtvd7Doc\nFGZmHay7uzLW0xiP9WRmZlurCgo3PZmZ2da6u9PAgEPhoDAz63CTJgH0bm72+Q4KM7MOl8+laHog\nj4Z7wSVNA/aufk5E3NbsC5uZ2ejQUFBI+iLwHuB+oLL7EkBhUEg6AbgY6AIui4gv9LPMMcBXgLHA\nMxHxxkaLNzOzYlJlUMDmz9FudI/incBrImJDoyuW1AV8FXgrsAJYLGlhRNxftcwU4FLghIh4XNIu\njZduZmb1dHXBhg2QurWb02gfxcOkb/yDcSSwLCIejoiNwALgpJpl3gtcHxGPA0TEU4N8DTMzKzBm\nDPT0DG0djSbMOuAuST8FXt6riIi/LXjONGB51eMVwFE1y+wPjJX0c2AycHFEfLPBmszMrI4xY2Dz\nZhiOpqeF+dZq3cARwLHABOBXku6IiIeqF5I0F5gLsNtue5VQhplZ50rXzG5+GNmGgiIiviGph7QH\nAPBgRGyq87SVwPSqx3vmadVWAKsiYi2wVtJtwKHAK4IiIuYD8wFmzZo9xGs1mZltW1JQlDwoYD4y\n6XekzulLgYckHV3naYuB/STNzCFzKlvvlXwfeIOkbkkTSU1TDwyifjMzqyP1UTR/QdRGm56+DBwX\nEQ8CSNof+A6p2ahfEdEr6RzgJtLhsVdExFJJZ+f58yLiAUk3AvcAW0iH0N7X7JsxM7OtDfXiRY0G\nxdhKSABExEOS6h4FFRGLgEU10+bVPP4S8KUG6zAzs6aU35m9RNJlwFX58enAkmZf1MzMhk+KiJI7\ns4H/CnwMqBwO+wtSX4WZmbW5jRuBISRFo0c9bQD+Jd/MzGwU2WuIZxUUBoWkayLi3ZLupZ+RByPi\nkKG9vJmZlW377Yf2/Hp7FOfmn28b2suYmdloVXgeRUQ8me8+AyyPiMeAcaST4p4ouTYzM2sDjQ4K\neBswPl+T4sfAGcCVZRVlZmbto9GgUESsA04GLo2IdwEHlVeWmZm1i4aDQtLrSedP/ChP6yqnJDMz\nayeNBsXHgf8G/EcehuPVwM/KK8vMzNpFo+dR3ArcWvX4YfpOvjMzsw5W7zyKr0TExyX9gP7Po3hH\naZWZmVlbqLdH8a3885/LLsTMzNpTYVBExJ357hJgfURsAZDURTqfwszMOlyjndk/BSZWPZ4A/KT1\n5ZiZWbtpNCjGR8SayoN8f2LB8mZm1iEaDYq1kg6vPJB0BLC+nJLMzKydNHo9io8D10p6gjSm+W7A\ne0qryszM2kaj51EslnQA8Jo86cGI2FReWWZm1i4aanqSNBE4Dzg3Iu4DZkjy0ONmZtuARvso/g+w\nEXh9frwS+IdSKjIzs7bSaFDsExH/BGwCyCPJNn+lbjMzGzUaDYqNkiaQh/GQtA+wobSqzMysbTR6\n1NP5wI3AdElXA38OnFlWUWZm1j7qBoUkAb8lXbTodaQmp3Mj4pmSazMzszZQNygiIiQtioiD6bto\nkZmZbSMa7aP4f5JeW2olZmbWlhrtozgKeJ+kR4G1pOaniIhDyirMzMzaQ6NBcXypVZiZWduqd4W7\n8cDZwL7AvcDlEdE7HIWZmVl7qNdH8Q1gNikk5gBfLr0iMzNrK/Wang7MRzsh6XLg1+WXZGZm7aTe\nHsXLI8S6ycnMbNtULygOlfRCvr0IHFK5L+mFeiuXdIKkByUtk/TpguVeK6lX0imDfQNmZlauwqan\niOhqdsWSuoCvAm8FVgCLJS2MiPv7We6LwI+bfS0zMytPoyfcNeNIYFlEPBwRG4EFwEn9LPc3wHeB\np0qsxczMmlRmUEwDllc9XpGnvUzSNOAvga8VrUjSXElLJC1ZvfrplhdqZmYDKzMoGvEV4LyI2FK0\nUETMj4jZETF7ypSdh6k0MzODxs/MbsZKYHrV4z3ztGqzgQVpgFqmAidK6o2I75VYl5mZDUKZQbEY\n2E/STFJAnAq8t3qBiJhZuS/pSuCHDgkzs/ZSWlBERK+kc4CbgC7giohYKunsPH9eWa9tZmatU+Ye\nBRGxCFhUM63fgIiIM8usxczMmjPSndlmZtbmHBRmZlbIQWFmZoUcFGZmVshBYWZmhRwUZmZWyEFh\nZmaFHBRmZlbIQWFmZoUcFGZmVshBYWZmhRwUZmZWyEFhZmaFHBRmZlbIQWFmZoUcFGZmVshBYWZm\nhRwUZmZWyEFhZmaFHBRmZlbIQWFmZoUcFGZmVshBYWZmhRwUZmZWyEFhZmaFHBRmZlbIQWFmZoUc\nFGZmVshBYWZmhRwUZmZWyEFhZmaFHBRmZlao1KCQdIKkByUtk/TpfuafLukeSfdKul3SoWXWY2Zm\ng1daUEjqAr4KzAEOBE6TdGDNYo8Ab4yIg4HPAfPLqsfMzJpT5h7FkcCyiHg4IjYCC4CTqheIiNsj\n4rn88A5gzxLrMTOzJpQZFNOA5VWPV+RpA/kgcEN/MyTNlbRE0pLVq59uYYlmZlZPW3RmS3oTKSjO\n629+RMyPiNkRMXvKlJ2Htzgzs21cd4nrXglMr3q8Z572CpIOAS4D5kTEqhLrMTOzJpS5R7EY2E/S\nTEk9wKnAwuoFJO0FXA+cEREPlViLmZk1qbQ9iojolXQOcBPQBVwREUslnZ3nzwM+A+wEXCoJoDci\nZpdVk5mZDV6ZTU9ExCJgUc20eVX3PwR8qMwazMxsaNqiM9vMzNqXg8LMzAo5KMzMrJCDwszMCjko\nzMyskIPCzMwKOSjMzKyQg8LMzAo5KMzMrJCDwszMCjkozMyskIPCzMwKOSjMzKyQg8LMzAo5KMzM\nrJCDwszMCjkozMyskIPCzMwKOSjMzKyQg8LMzAo5KMzMrJCDwszMCjkozMyskIPCzMwKOSjMzKyQ\ng8LMzAo5KMzMrJCDwszMCjkozMyskIPCzMwKOSjMzKyQg8LMzAo5KMzMrFCpQSHpBEkPSlom6dP9\nzJekf8vz75F0eJn1mJnZ4JUWFJK6gK8Cc4ADgdMkHViz2Bxgv3ybC3ytrHrMzKw53SWu+0hgWUQ8\nDCBpAXAScH/VMicB34yIAO6QNEXS7hHxZNGKN2woq2QzM6tVZlBMA5ZXPV4BHNXAMtOAVwSFpLmk\nPQ6AjcceO/n3rS11tNq0I4x9bqSraA/eFn28Lfp4W/RZt3ezzywzKFomIuYD8wEkLYl4cfYIl9QW\n0rZ4ydsCb4tq3hZ9vC36SFrS7HPL7MxeCUyverxnnjbYZczMbASVGRSLgf0kzZTUA5wKLKxZZiHw\n/nz00+uA5+v1T5iZ2fAqrekpInolnQPcBHQBV0TEUkln5/nzgEXAicAyYB1wVgOrnl9SyaORt0Uf\nb4s+3hZ9vC36NL0tlA44MjMz65/PzDYzs0IOCjMzK9S2QeHhP/o0sC1Oz9vgXkm3Szp0JOocDvW2\nRdVyr5XUK+mU4axvODWyLSQdI+kuSUsl3TrcNQ6XBv5HdpD0A0l3523RSH/oqCPpCklPSbpvgPnN\nfW5GRNvdSJ3fvwdeDfQAdwMH1ixzInADIOB1wH+OdN0juC3+DNgx35+zLW+LquVuIR0sccpI1z2C\nfxdTSCMh7JUf7zLSdY/gtvjvwBfz/Z2BZ4Geka69hG1xNHA4cN8A85v63GzXPYqXh/+IiI1AZfiP\nai8P/xERdwBTJO0+3IUOg7rbIiJuj4jK2ad3kM5H6USN/F0A/A3wXeCp4SxumDWyLd4LXB8RjwNE\nRKduj0a2RQCTJQmYRAqK3uEts3wRcRvpvQ2kqc/Ndg2KgYb2GOwynWCw7/ODpG8MnajutpA0DfhL\nOn+AyUb+LvYHdpT0c0l3Snr/sFU3vBrZFpcAs4AngHuBcyNiy/CU11aa+twcFUN4WGMkvYkUFG8Y\n6VpG0FeA8yJiS/ryuE3rBo4AjgUmAL+SdEdEPDSyZY2I44G7gDcD+wA3S/pFRLwwsmWNDu0aFB7+\no09D71PSIcBlwJyIWDVMtQ23RrbFbGBBDompwImSeiPie8NT4rBpZFusAFZFxFpgraTbgEOBTguK\nRrbFWcAXIjXUL5P0CHAA8OvhKbFtNPW52a5NTx7+o0/dbSFpL+B64IwO/7ZYd1tExMyImBERM4Dr\ngI92YEhAY/8j3wfeIKlb0kTS6M0PDHOdw6GRbfE4ac8KSbsCrwEeHtYq20NTn5ttuUcR5Q3/Meo0\nuC0+A+wEXJq/SfdGRMeNmNngttgmNLItIuIBSTcC9wBbgMsiot/DJkezBv8uPgdcKele0hE/50XE\nMyNWdEkkfQc4BpgqaQVwPjAWhva56SE8zMysULs2PZmZWZtwUJiZWSEHhZmZFXJQmJlZIQeFmZkV\nclCY1ZC0OY+4el8ecXRKi9d/pqRL8v0LJH2yles3azUHhdnW1kfEYRHxJ6QB1j420gWZjSQHhVmx\nX1E1aJqkv5O0OI/lf2HV9PfnaXdL+lae9nZJ/ynpN5J+ks8INht12vLMbLN2IKmLNOzD5fnxccB+\npGGtBSyUdDSwCvh74M8i4hlJr8qr+CXwuogISR8CPgV8YpjfhtmQOSjMtjZB0l2kPYkHgJvz9OPy\n7Tf58SRScBwKXFsZEiIiKtcD2BP49zzefw/wyPCUb9Zabnoy29r6iDgM2Ju051DpoxDw+dx/cVhE\n7BsRlxes538Bl0TEwcBHgPGlVm1WEgeF2QAiYh3wt8AnJHWTBp37a0mTIF0kSdIupMuuvkvSTnl6\npelpB/qGcP7AsBZv1kJuejIrEBG/kXQPcFpEfEvSLNIFgADWAO/LI5VeBNwqaTOpaepM4ALgWknP\nkcJk5ki8B7Oh8uixZmZWyE1PZmZWyEFhZmaFHBRmZlbIQWFmZoUcFGZmVshBYWZmhRwUZmZW6P8D\nzQlU9hazkEYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb5b41db5f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SINX99F5Pm_1",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef4a19eb-ace0-41ba-9540-e52922c297f6"
      },
      "source": [
        "#ROC Curve (all our samples are balanced)\n",
        "auc = roc_auc_score(y_true, y_score)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr8BQPAYPm_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}