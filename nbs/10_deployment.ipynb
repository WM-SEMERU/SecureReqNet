{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *\n",
    "# default_exp deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import flask\n",
    "from flask import Flask\n",
    "import requests\n",
    "import json\n",
    "from flask import request, jsonify\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "from securereqnet.preprocessing import vectorize_sentences\n",
    "import numpy as np\n",
    "from waitress import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend Service\n",
    "These methods ping the TFX serving endpoint and get predictions from the model.  The input of the served model would be vectorized sentences in tensor form and the output is the output of the final FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def __get_predictions(sentences, endpoint_uri):\n",
    "    payload = {\n",
    "            \"instances\": vectorize_sentences(sentences).tolist()\n",
    "        }\n",
    "        \n",
    "    print(payload)\n",
    "    r = requests.post(endpoint_uri, json = payload)\n",
    "    model_preds = json.loads(r.content.decode('utf-8'))\n",
    "\n",
    "    \n",
    "    preds = []\n",
    "\n",
    "    # decode predictions\n",
    "    for pred in model_preds['predictions']:\n",
    "        preds.append(__decode(pred))\n",
    "\n",
    "    output = {\n",
    "        \"predictions\": preds\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def __decode(input):\n",
    "    return float(input[0])>float(input[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask Backend\n",
    "Defines a factory for our app.  Serving is packaged nicely inside a serve method, and is ready to deploy with waitress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def create_app(test_config=None):\n",
    "    app = Flask(__name__, instance_relative_config=True)\n",
    "    app.config.from_mapping(\n",
    "        SECRET_KEY='dev',\n",
    "        TFX_ENDPOINT='http://localhost:8503/v1/models/alpha:predict'\n",
    "    )\n",
    "\n",
    "    if test_config:\n",
    "        app.config.from_mapping(test_config)\n",
    "    else:\n",
    "        app.config.from_pyfile('config.py', silent=True)\n",
    "\n",
    "    # default route, we probably will get rid of this\n",
    "    @app.route('/', methods=['GET'])\n",
    "    def home():\n",
    "        return '<h1>SecureReqNet</h1><p>Flask backend</p>'\n",
    "\n",
    "    # alpha model\n",
    "    @app.route('/models/alpha', methods=['POST'])\n",
    "    def alpha():\n",
    "        content = request.get_json()\n",
    "        print(content['instances'])\n",
    "        sentences = content['instances']\n",
    "        return __get_predictions(sentences, app.config['TFX_ENDPOINT'])\n",
    "\n",
    "    return app\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def serve(host, port):\n",
    "    serve(create_app(), host = host, port = port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing âœ…\n",
    "## Flask Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'preprocessing',\n",
       " 'utils']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import securereqnet\n",
    "dir(securereqnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest.mock\n",
    "from unittest import mock\n",
    "from unittest.mock import patch\n",
    "from securereqnet.deployment import create_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test client\n",
    "app = create_app({'TESTING': True, \"TFX_ENDPOINT\": \"MockMockMock\"})\n",
    "test_client = app.test_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tests to see if our app successfully deploys with a homepage\n",
    "# Succeeds if the response code for default path is 200\n",
    "def test_app_homepage():\n",
    "    response = test_client.get('/')\n",
    "    assert response.status_code==200\n",
    "\n",
    "test_app_homepage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test test test test']\n"
     ]
    }
   ],
   "source": [
    "# This test checks if we are able to successfully post a sentence to the server and get a response back\n",
    "# Mock the backend request to TFX serving\n",
    "# Succeeds if data returns successfully in correct form\n",
    "@patch('securereqnet.deployment.__get_predictions')\n",
    "def test_get_prediction_single(mock_predictions):\n",
    "    test_payload = {\"instances\": [\"test test test test\"]}\n",
    "    expected_pred = {\"predictions\": [True]}\n",
    "    mock_predictions.return_value = expected_pred\n",
    "    response = test_client.post('/models/alpha', json=test_payload)\n",
    "    r_data = json.loads(response.data.decode('utf-8'))\n",
    "    assert r_data == expected_pred\n",
    "\n",
    "test_get_prediction_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test test test test', 'more testing', 'super duper testing']\n"
     ]
    }
   ],
   "source": [
    "# This test checks if we are able to successfully post multiple sentences to the server and get a response back\n",
    "# Mock the backend request to TFX serving\n",
    "# Succeeds if data returns successfully in correct form\n",
    "@patch('securereqnet.deployment.__get_predictions')\n",
    "def test_get_prediction_multi(mock_predictions):\n",
    "    test_payload = {\"instances\": [\"test test test test\", \"more testing\", \"super duper testing\"]}\n",
    "    expected_pred = {\"predictions\": [True, False, True]}\n",
    "    mock_predictions.return_value = expected_pred\n",
    "    response = test_client.post('/models/alpha', json=test_payload)\n",
    "    r_data = json.loads(response.data.decode('utf-8'))\n",
    "    assert r_data == expected_pred\n",
    "\n",
    "test_get_prediction_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend Service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
