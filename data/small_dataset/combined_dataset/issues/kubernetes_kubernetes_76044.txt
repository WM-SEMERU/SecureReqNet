Block PV may be mounted if kubelet feature gate disabled


@msau42 you may remember you had a concern that if we made BlockVolume default in 1.13 there could be issues with version skewed clusters where kubelets with the feature gate still off could format block volumes if a pod was started/restarted, potentially deleting data that was there. (see #65829 (comment)). I concluded it wasn't possible but I'm convinced now that's wrong.
It's true that kubelet won't mount volumeDevices volumes into the pod, which is what the downgrade test I added checked, but the issue is:

If the feature gate is off kubelet will add everything in spec.volumes to desired state of world* regardless of whether it is in volumeDevices/volumeMounts/neither. This means it will call MountVolume on a block volume! 


kubernetes/pkg/volume/util/operationexecutor/operation_executor.go


         Line 726
      in
      b1829df






 fsVolume, err := util.CheckVolumeModeFilesystem(volumeToMount.VolumeSpec) 






Only if the feature gate is on will kubelet check spec.volumes against volumeMounts/volumeDevices. It will add every volume in spec.volumes desired state of world* unless either a) it is a BlockVolume and present in volumeMounts or b) it is a Filesystem volume and present in volumeDevices, i.e. there is a mismatch. So it will still mount/map things even if there is no respective volumeMount/volumeDevice but it will error if there is a mismatch.
TODO:


Update the downgrade test to not only check that nothing is mounted in the pod but also that nothing is mounted to the node at all, i.e. to the pod volume directory under /var/lib/kubelet (how to do that is TBD)


Whether the feature gate is on/off, don't add volumes desired state of world* that are not in any volumeDevices/volumeMounts at all. So if the feature gate is off, kubelet won't add any block volumes in volume.spec because it won't check volumeDevices and the block volume won't be present in volumeMounts. This is what I thought happened. It should happen anyway because what's the point of mounting a volume if it is not going to be consumed by the pod?


- Add a safeguard to MountVolume even if feature gate is off. I've heard feature gate off is supposed to mean 'don't run any code related to the feature' but I think an exception to read the VolumeMode field would be okay here? not reliable, pod may not have field at all
The fix should be cherry-picked to 1.11 & 1.12
